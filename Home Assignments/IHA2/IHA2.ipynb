{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHA2 - Catching Pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://tibetanitech.com/wp-content/uploads/2016/09/Pokemon-GO.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this home assignment, you'll apply roughly the same principles we used when doing logistic regression on the Iris dataset, but on a new and very interesting dataset. We'll use the [Predict'em All](https://www.kaggle.com/semioniy/predictemall) dataset from Kaggle (download the dataset directly from them). This dataset consists of roughly 293,000 [pokemon](http://www.pokemongo.com/) sightings (historical appearances of Pokemon in the Pokemon Go game), having coordinates, time, weather, population density, distance to pokestops/ gyms etc. as features. A comprehensive list of all the features is available at [the dataset's homepage](https://www.kaggle.com/semioniy/predictemall)\n",
    "\n",
    "The context is simple: you are a Pokemon hunter, and there are only three Pokemon left for you to complete your collection. You'll do anything to capture them, including changing where you'll spend your next holidays! You know that some Pokemon only spawn in certain places of the world. Since you like machine learning so much, you figure it would be a great idea to train a classifier that, based on a location's latitude and longitude, can tell us which Pokemon is more likely to appear there.\n",
    "\n",
    "The assignment is broken down into six steps.\n",
    "\n",
    "1. Loading the data and extracting the desired subset of it\n",
    "2. Visualization of the dataset\n",
    "3. Preprocessing\n",
    "4. Training\n",
    "5. Evaluation\n",
    "6. Exploration\n",
    "\n",
    "\n",
    "Feel free to add cells wherever you see fit, and play around with this notebook as much as you want when developing the solutions. However, the solution you upload to ping-pong must have the exact format shown here, with only the cells present here.\n",
    "\n",
    "Don't restrict yourself only to what was taught so far. Some of the tasks might require you to search for new information. [The python docs](https://docs.python.org/3/), [keras docs](https://keras.io/), [stackoverflow](https://stackoverflow.com/), and Google are your friends!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import any necessary modules here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and extracting subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `'300k.csv'` file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('300k.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new `DataFrame` with only the columns `latitude`, `longitude`, and `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.525745</td>\n",
       "      <td>-97.460829</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.523695</td>\n",
       "      <td>-97.461167</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.903590</td>\n",
       "      <td>-77.199780</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.665903</td>\n",
       "      <td>-122.312561</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.666454</td>\n",
       "      <td>-122.311628</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude  class\n",
       "0  20.525745  -97.460829     16\n",
       "1  20.523695  -97.461167    133\n",
       "2  38.903590  -77.199780     16\n",
       "3  47.665903 -122.312561     13\n",
       "4  47.666454 -122.311628    133"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew = df[['latitude','longitude','class']]\n",
    "dfnew.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `class` column specifies which pokemon it is. However, it only has the numerical id of the pokemon. For convenience, use the following dictionary to convert between ids and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict={1: 'Bulbasaur', 2: 'Ivysaur', 3: 'Venusaur', 4: 'Charmander', 5: 'Charmeleon', 6: 'Charizard', 7: 'Squirtle', 8: \n",
    "          'Wartortle', 9: 'Blastoise', 10: 'Caterpie', 11: 'Metapod', 12: 'Butterfree', 13: 'Weedle', 14: 'Kakuna', \n",
    "          15: 'Beedrill', 16: 'Pidgey', 17: 'Pidgeotto', 18: 'Pidgeot', 19: 'Rattata', 20: 'Raticate', 21: 'Spearow',\n",
    "          22: 'Fearow', 23: 'Ekans', 24: 'Arbok', 25: 'Pikachu', 26: 'Raichu', 27: 'Sandshrew', 28: 'Sandslash', \n",
    "          29: 'Nidoran F', 30: 'Nidorina', 31: 'Nidoqueen',32: 'Nidoran M', 33: 'Nidorino', 34: 'Nidoking', 35: 'Clefairy',\n",
    "          36: 'Clefable', 37: 'Vulpix', 38: 'Ninetales', 39: 'Jigglypuff', 40: 'Wigglytuff', 41: 'Zubat', 42: 'Golbat', \n",
    "          43: 'Oddish', 44: 'Gloom', 45: 'Vileplume', 46: 'Paras', 47: 'Parasect', 48: 'Venonat', 49: 'Venomoth',\n",
    "          50: 'Diglett', 51: 'Dugtrio', 52: 'Meowth', 53: 'Persian', 54: 'Psyduck',55: 'Golduck', 56: 'Mankey', \n",
    "          57: 'Primeape', 58: 'Growlithe', 59: 'Arcanine', 60: 'Poliwag', 61: 'Poliwhirl', 62: 'Poliwrath',\n",
    "          63: 'Abra', 64: 'Kadabra', 65: 'Alakazam', 66: 'Machop', 67: 'Machoke', 68: 'Machamp', 69: 'Bellsprout', \n",
    "          70: 'Weepinbell', 71: 'Victreebel', 72: 'Tentacool', 73: 'Tentacruel', 74: 'Geodude', 75: 'Graveler',\n",
    "          76: 'Golem', 77: 'Ponyta', 78: 'Rapidash', 79: 'Slowpoke', 80: 'Slowbro', 81: 'Magnemite', 82: 'Magneton',\n",
    "          83: \"Farfetch'd\", 84: 'Doduo', 85: 'Dodrio', 86: 'Seel', 87: 'Dewgong', 88: 'Grimer', 89: 'Muk', \n",
    "          90: 'Shellder', 91: 'Cloyster', 92: 'Gastly', 93: 'Haunter', 94: 'Gengar', 95: 'Onix', 96: 'Drowzee',\n",
    "          97: 'Hypno', 98: 'Krabby', 99: 'Kingler', 100: 'Voltorb', 101: 'Electrode', 102: 'Exeggcute', 103: 'Exeggutor', \n",
    "          104: 'Cubone', 105: 'Marowak', 106: 'Hitmonlee', 107: 'Hitmonchan', 108: 'Lickitung', 109: 'Koffing',\n",
    "          110: 'Weezing', 111: 'Rhyhorn', 112: 'Rhydon', 113: 'Chansey', 114: 'Tangela', 115: 'Kangaskhan', 116: 'Horsea', \n",
    "          117: 'Seadra', 118: 'Goldeen', 119: 'Seaking', 120: 'Staryu', 121: 'Starmie', 122: 'Mr. Mime', 123: 'Scyther', \n",
    "          124: 'Jynx', 125: 'Electabuzz', 126: 'Magmar', 127: 'Pinsir', 128: 'Tauros', 129: 'Magikarp', 130: 'Gyarados', \n",
    "          131: 'Lapras', 132: 'Ditto', 133: 'Eevee', 134: 'Vaporeon', 135: 'Jolteon', 136: 'Flareon', 137: 'Porygon', \n",
    "          138: 'Omanyte', 139: 'Omastar', 140: 'Kabuto', 141: 'Kabutops', 142: 'Aerodactyl', 143: 'Snorlax', 144: 'Articuno',\n",
    "          145: 'Zapdos', 146: 'Moltres', 147: 'Dratini', 148: 'Dragonair', 149: 'Dragonite', 150: 'Mewtwo', 'Bulbasaur': 1, 'Ivysaur': 2, 'Venusaur': 3, 'Charmander': 4, 'Charmeleon': 5, 'Charizard': 6, 'Squirtle': 7, 'Wartortle': 8, 'Blastoise': 9, 'Caterpie': 10, 'Metapod': 11, 'Butterfree': 12, 'Weedle': 13, 'Kakuna': 14, 'Beedrill': 15, 'Pidgey': 16, 'Pidgeotto': 17, 'Pidgeot': 18, 'Rattata': 19, 'Raticate': 20, 'Spearow': 21, 'Fearow': 22, 'Ekans': 23, 'Arbok': 24, 'Pikachu': 25, 'Raichu': 26, 'Sandshrew': 27, 'Sandslash': 28, 'Nidoran F': 29, 'Nidorina': 30, 'Nidoqueen': 31, 'Nidoran M': 32, 'Nidorino': 33, 'Nidoking': 34, 'Clefairy': 35, 'Clefable': 36, 'Vulpix': 37, 'Ninetales': 38, 'Jigglypuff': 39, 'Wigglytuff': 40, 'Zubat': 41, 'Golbat': 42, 'Oddish': 43, 'Gloom': 44, 'Vileplume': 45, 'Paras': 46, 'Parasect': 47, 'Venonat': 48, 'Venomoth': 49, 'Diglett': 50, 'Dugtrio': 51, 'Meowth': 52, 'Persian': 53, 'Psyduck': 54, 'Golduck': 55, 'Mankey': 56, 'Primeape': 57, 'Growlithe': 58, 'Arcanine': 59, 'Poliwag': 60, 'Poliwhirl': 61, 'Poliwrath': 62, 'Abra': 63, 'Kadabra': 64, 'Alakazam': 65, 'Machop': 66, 'Machoke': 67, 'Machamp': 68, 'Bellsprout': 69, 'Weepinbell': 70, 'Victreebel': 71, 'Tentacool': 72, 'Tentacruel': 73, 'Geodude': 74, 'Graveler': 75, 'Golem': 76, 'Ponyta': 77, 'Rapidash': 78, 'Slowpoke': 79, 'Slowbro': 80, 'Magnemite': 81, 'Magneton': 82, 'Farfetch\\'d': 83, 'Doduo': 84, 'Dodrio': 85, 'Seel': 86, 'Dewgong': 87, 'Grimer': 88, 'Muk': 89, 'Shellder': 90, 'Cloyster': 91, 'Gastly': 92, 'Haunter': 93, 'Gengar': 94, 'Onix': 95, 'Drowzee': 96, 'Hypno': 97, 'Krabby': 98, 'Kingler': 99, 'Voltorb': 100, 'Electrode': 101, 'Exeggcute': 102, 'Exeggutor': 103, 'Cubone': 104, 'Marowak': 105, 'Hitmonlee': 106, 'Hitmonchan': 107, 'Lickitung': 108, 'Koffing': 109, 'Weezing': 110, 'Rhyhorn': 111, 'Rhydon': 112, 'Chansey': 113, 'Tangela': 114, 'Kangaskhan': 115, 'Horsea': 116, 'Seadra': 117, 'Goldeen': 118, 'Seaking': 119, 'Staryu': 120, 'Starmie': 121, 'Mr. Mime': 122, 'Scyther': 123, 'Jynx': 124, 'Electabuzz': 125, 'Magmar': 126, 'Pinsir': 127, 'Tauros': 128, 'Magikarp': 129, 'Gyarados': 130, 'Lapras': 131, 'Ditto': 132, 'Eevee': 133, 'Vaporeon': 134, 'Jolteon': 135, 'Flareon': 136, 'Porygon': 137, 'Omanyte': 138, 'Omastar': 139, 'Kabuto': 140, 'Kabutops': 141, 'Aerodactyl': 142, 'Snorlax': 143, 'Articuno': 144, 'Zapdos': 145, 'Moltres': 146, 'Dratini': 147, 'Dragonair': 148, 'Dragonite': 149, 'Mewtwo': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "Gengar\n"
     ]
    }
   ],
   "source": [
    "# example usage (you can index either by name or id)\n",
    "print(name_dict['Gengar'])\n",
    "print(name_dict[94])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in three specific pokemon: Diglett, Seel, and Tauros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th> <center>Diglett</center> </th>\n",
    "    <th> <center>Seel</center> </th> \n",
    "    <th> <center>Tauros</center> </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>![Diglett](https://assets.pokemon.com/assets/cms2/img/pokedex/full/050_f2.png)</td>\n",
    "    <td>![Seel](https://pokemon.gamepedia.com/media/pokemon.gamepedia.com/thumb/f/f1/Seel.png/200px-Seel.png?version=2c32fbe0af2d0da707e5dbcb40472fbf)</td>\n",
    "    <td>![Tauros](https://vignette2.wikia.nocookie.net/pokemon/images/0/01/128Tauros_AG_anime.png/revision/latest?cb=20140924030616)</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the dataset to contain only these pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfnewfilterd = dfnew[dfnew['class'].isin([name_dict['Diglett'], name_dict['Seel'], name_dict['Tauros']])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histogram of the number of occurrences of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2f11da91780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dfnewfilterd['class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the dataset balanced?\n",
    "\n",
    "**Your answer**: (Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a scatter plot where the first dimension is latitude, the second is longitude, and each point is a Pokemon. Further, the color of each point should represent which Pokemon it is. Lastly, the marker at each point should be an `'x'`. Make sure to label each axis.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The `scatter` method from `matplotlib` accepts an argument called `c`.\n",
    "- The `scatter` method also accepts an argument called `marker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ec530055f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "tempdf = dfnewfilterd.set_index('class')\n",
    "for classes in ['Diglett', 'Seel', 'Tauros']:\n",
    "    ax.scatter(tempdf.loc[name_dict[classes]]['latitude'],tempdf.loc[name_dict[classes]]['longitude'], label=classes, alpha = 0.3)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any other visualization you think would be useful? If so, insert it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How hard do you think the problem is? Which classes can/cannot be easily separated?\n",
    "\n",
    "**Your answer**: (The problem is not linearly separable with zero loss but both Tauros and Seel are pretty well clusterd as one would expect from those two particular Pok√©mon's. Diglett on the other hand seem to have a much higher variance appering in relatively the same rate in both the Touros nest as well as the Seel nest. Diglett will thus be the hard one to predict, however the large varience for Digglet and the relative low varience for Seel and Tauros might make it much easier to classify Diglett the one might originaly expect   )\n",
    "\n",
    "Which accuracy do you expect to achieve?\n",
    "\n",
    "**Your answer**: (For bot Tauros and Seel I'm confident we will achive a higeh predictive accuracy for simply because of the relatively low varience of these two nests. Digglet on the other hand might be harder but then again the large spread of Diglett relative to the other two might actualy make it much easier to predict then one might expect. For some hard numbers I would estimate us geting around 95% predictive acuracy on Tauros about 80% on Seal and 75% on Diglett. But then again, looking at the requirement for this task it seams that I am way to optemistic in my predictions )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input and output vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vec = dfnewfilterd[['latitude', 'longitude']].as_matrix()[1:]\n",
    "input_vec_scaled = preprocessing.scale(input_vec)\n",
    "\n",
    "class_vec = dfnewfilterd['class'].as_matrix()[1:]\n",
    "class_vec[class_vec == name_dict['Diglett']] = 0\n",
    "class_vec[class_vec == name_dict['Seel']] = 1\n",
    "class_vec[class_vec == name_dict['Tauros']] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate your data into training and test sets. 20% of the data should be in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#np.random.shuffle(input_vec_scaled)\n",
    "#np.random.shuffle(class_vec)\n",
    "index = round(len(class_vec)*0.8)\n",
    "print(index)\n",
    "input_vec_train, input_vec_test = [input_vec_scaled[:index,:], input_vec_scaled[index:,:]]\n",
    "\n",
    "class_vec_train, class_vec_test = [class_vec[:index], class_vec[index:]]\n",
    "print(np.unique(class_vec_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ec1adbd320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(input_vec_train[:,0],input_vec_train[:,1], c=class_vec_train, alpha = 0.3)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2f11da91588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(class_vec_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an architecture for your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Dense(40, input_shape = (2,), activation = 'relu')\n",
    "l2 = Dense(20, activation = 'relu')\n",
    "l3 = Dense(20, activation = 'relu')\n",
    "l4 = Dense(3, activation = 'softmax')\n",
    "model = Sequential([l1, l2, l3, l4])\n",
    "model.compile(SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network. When training, separate 25% of your training data into a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1249 samples, validate on 417 samples\n",
      "Epoch 1/2000\n",
      "1249/1249 [==============================] - 2s 2ms/step - loss: 1.0720 - acc: 0.3891 - val_loss: 1.0844 - val_acc: 0.3237\n",
      "Epoch 2/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 1.0693 - acc: 0.4179 - val_loss: 1.0824 - val_acc: 0.3621\n",
      "Epoch 3/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 1.0667 - acc: 0.4500 - val_loss: 1.0804 - val_acc: 0.3549\n",
      "Epoch 4/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 1.0644 - acc: 0.4492 - val_loss: 1.0786 - val_acc: 0.3525\n",
      "Epoch 5/2000\n",
      "1249/1249 [==============================] - 0s 195us/step - loss: 1.0622 - acc: 0.4468 - val_loss: 1.0769 - val_acc: 0.3645\n",
      "Epoch 6/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 1.0601 - acc: 0.4484 - val_loss: 1.0752 - val_acc: 0.3693\n",
      "Epoch 7/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 1.0582 - acc: 0.4684 - val_loss: 1.0736 - val_acc: 0.3861\n",
      "Epoch 8/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 1.0564 - acc: 0.4740 - val_loss: 1.0721 - val_acc: 0.4053\n",
      "Epoch 9/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 1.0546 - acc: 0.4868 - val_loss: 1.0706 - val_acc: 0.4077\n",
      "Epoch 10/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 1.0529 - acc: 0.4876 - val_loss: 1.0691 - val_acc: 0.4173\n",
      "Epoch 11/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 1.0512 - acc: 0.4868 - val_loss: 1.0676 - val_acc: 0.4173\n",
      "Epoch 12/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 1.0495 - acc: 0.4876 - val_loss: 1.0662 - val_acc: 0.4221\n",
      "Epoch 13/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 1.0480 - acc: 0.4932 - val_loss: 1.0648 - val_acc: 0.4365\n",
      "Epoch 14/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 1.0464 - acc: 0.5036 - val_loss: 1.0634 - val_acc: 0.4388\n",
      "Epoch 15/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 1.0449 - acc: 0.5052 - val_loss: 1.0620 - val_acc: 0.4412\n",
      "Epoch 16/2000\n",
      "1249/1249 [==============================] - 0s 193us/step - loss: 1.0433 - acc: 0.5044 - val_loss: 1.0606 - val_acc: 0.4388\n",
      "Epoch 17/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 1.0418 - acc: 0.5132 - val_loss: 1.0592 - val_acc: 0.4700\n",
      "Epoch 18/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 1.0403 - acc: 0.5140 - val_loss: 1.0578 - val_acc: 0.4724\n",
      "Epoch 19/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 1.0388 - acc: 0.5172 - val_loss: 1.0563 - val_acc: 0.4772\n",
      "Epoch 20/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 1.0373 - acc: 0.5220 - val_loss: 1.0549 - val_acc: 0.4820\n",
      "Epoch 21/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 1.0358 - acc: 0.5252 - val_loss: 1.0534 - val_acc: 0.4988\n",
      "Epoch 22/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 1.0344 - acc: 0.5276 - val_loss: 1.0520 - val_acc: 0.5084\n",
      "Epoch 23/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 1.0329 - acc: 0.5356 - val_loss: 1.0505 - val_acc: 0.5060\n",
      "Epoch 24/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 1.0314 - acc: 0.5364 - val_loss: 1.0491 - val_acc: 0.5324\n",
      "Epoch 25/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 1.0300 - acc: 0.5412 - val_loss: 1.0476 - val_acc: 0.5396\n",
      "Epoch 26/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 1.0285 - acc: 0.5428 - val_loss: 1.0462 - val_acc: 0.5420\n",
      "Epoch 27/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 1.0271 - acc: 0.5436 - val_loss: 1.0447 - val_acc: 0.5372\n",
      "Epoch 28/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 1.0256 - acc: 0.5460 - val_loss: 1.0432 - val_acc: 0.5372\n",
      "Epoch 29/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 1.0242 - acc: 0.5476 - val_loss: 1.0417 - val_acc: 0.5396\n",
      "Epoch 30/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 1.0227 - acc: 0.5468 - val_loss: 1.0402 - val_acc: 0.5396\n",
      "Epoch 31/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 1.0212 - acc: 0.5468 - val_loss: 1.0387 - val_acc: 0.5444\n",
      "Epoch 32/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 1.0198 - acc: 0.5540 - val_loss: 1.0371 - val_acc: 0.5444\n",
      "Epoch 33/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 1.0183 - acc: 0.5556 - val_loss: 1.0356 - val_acc: 0.5444\n",
      "Epoch 34/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 1.0168 - acc: 0.5580 - val_loss: 1.0340 - val_acc: 0.5468\n",
      "Epoch 35/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 1.0153 - acc: 0.5620 - val_loss: 1.0324 - val_acc: 0.5468\n",
      "Epoch 36/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 1.0138 - acc: 0.5693 - val_loss: 1.0307 - val_acc: 0.5540\n",
      "Epoch 37/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 1.0123 - acc: 0.5709 - val_loss: 1.0291 - val_acc: 0.5635\n",
      "Epoch 38/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 1.0108 - acc: 0.5709 - val_loss: 1.0274 - val_acc: 0.5635\n",
      "Epoch 39/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 1.0093 - acc: 0.5717 - val_loss: 1.0257 - val_acc: 0.5683\n",
      "Epoch 40/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 1.0077 - acc: 0.5741 - val_loss: 1.0240 - val_acc: 0.5755\n",
      "Epoch 41/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 1.0061 - acc: 0.5893 - val_loss: 1.0223 - val_acc: 0.5851\n",
      "Epoch 42/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 1.0046 - acc: 0.6005 - val_loss: 1.0206 - val_acc: 0.5899\n",
      "Epoch 43/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 1.0030 - acc: 0.6021 - val_loss: 1.0189 - val_acc: 0.5923\n",
      "Epoch 44/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 1.0015 - acc: 0.6045 - val_loss: 1.0171 - val_acc: 0.5923\n",
      "Epoch 45/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.9999 - acc: 0.6077 - val_loss: 1.0153 - val_acc: 0.5995\n",
      "Epoch 46/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.9983 - acc: 0.6117 - val_loss: 1.0134 - val_acc: 0.6019\n",
      "Epoch 47/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.9966 - acc: 0.6133 - val_loss: 1.0114 - val_acc: 0.6091\n",
      "Epoch 48/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.9950 - acc: 0.6173 - val_loss: 1.0094 - val_acc: 0.6187\n",
      "Epoch 49/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.9933 - acc: 0.6197 - val_loss: 1.0074 - val_acc: 0.6211\n",
      "Epoch 50/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.9917 - acc: 0.6205 - val_loss: 1.0053 - val_acc: 0.6211\n",
      "Epoch 51/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.9900 - acc: 0.6205 - val_loss: 1.0033 - val_acc: 0.6211\n",
      "Epoch 52/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.9883 - acc: 0.6205 - val_loss: 1.0013 - val_acc: 0.6235\n",
      "Epoch 53/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.9866 - acc: 0.6213 - val_loss: 0.9992 - val_acc: 0.6235\n",
      "Epoch 54/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.9849 - acc: 0.6221 - val_loss: 0.9971 - val_acc: 0.6235\n",
      "Epoch 55/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.9832 - acc: 0.6237 - val_loss: 0.9950 - val_acc: 0.6259\n",
      "Epoch 56/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.9815 - acc: 0.6237 - val_loss: 0.9929 - val_acc: 0.6259\n",
      "Epoch 57/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.9798 - acc: 0.6237 - val_loss: 0.9907 - val_acc: 0.6283\n",
      "Epoch 58/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.9781 - acc: 0.6261 - val_loss: 0.9885 - val_acc: 0.6427\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.9763 - acc: 0.6349 - val_loss: 0.9863 - val_acc: 0.6475\n",
      "Epoch 60/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.9746 - acc: 0.6429 - val_loss: 0.9841 - val_acc: 0.6523\n",
      "Epoch 61/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.9728 - acc: 0.6421 - val_loss: 0.9818 - val_acc: 0.6595\n",
      "Epoch 62/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.9710 - acc: 0.6421 - val_loss: 0.9795 - val_acc: 0.6595\n",
      "Epoch 63/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.9692 - acc: 0.6421 - val_loss: 0.9772 - val_acc: 0.6595\n",
      "Epoch 64/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.9674 - acc: 0.6461 - val_loss: 0.9748 - val_acc: 0.6643\n",
      "Epoch 65/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.9656 - acc: 0.6501 - val_loss: 0.9725 - val_acc: 0.6859\n",
      "Epoch 66/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.9638 - acc: 0.6501 - val_loss: 0.9702 - val_acc: 0.6859\n",
      "Epoch 67/2000\n",
      "1249/1249 [==============================] - 0s 147us/step - loss: 0.9620 - acc: 0.6493 - val_loss: 0.9678 - val_acc: 0.6859\n",
      "Epoch 68/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.9602 - acc: 0.6501 - val_loss: 0.9655 - val_acc: 0.6859\n",
      "Epoch 69/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.9584 - acc: 0.6461 - val_loss: 0.9632 - val_acc: 0.6835\n",
      "Epoch 70/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.9566 - acc: 0.6453 - val_loss: 0.9608 - val_acc: 0.6835\n",
      "Epoch 71/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.9548 - acc: 0.6453 - val_loss: 0.9584 - val_acc: 0.6835\n",
      "Epoch 72/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.9530 - acc: 0.6445 - val_loss: 0.9561 - val_acc: 0.6835\n",
      "Epoch 73/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.9513 - acc: 0.6453 - val_loss: 0.9537 - val_acc: 0.6835\n",
      "Epoch 74/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.9494 - acc: 0.6437 - val_loss: 0.9514 - val_acc: 0.6763\n",
      "Epoch 75/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.9476 - acc: 0.6437 - val_loss: 0.9489 - val_acc: 0.6763\n",
      "Epoch 76/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.9458 - acc: 0.6437 - val_loss: 0.9465 - val_acc: 0.6763\n",
      "Epoch 77/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.9440 - acc: 0.6437 - val_loss: 0.9441 - val_acc: 0.6763\n",
      "Epoch 78/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.9422 - acc: 0.6437 - val_loss: 0.9417 - val_acc: 0.6763\n",
      "Epoch 79/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.9404 - acc: 0.6437 - val_loss: 0.9393 - val_acc: 0.6763\n",
      "Epoch 80/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.9386 - acc: 0.6437 - val_loss: 0.9369 - val_acc: 0.6763\n",
      "Epoch 81/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.9368 - acc: 0.6445 - val_loss: 0.9344 - val_acc: 0.6763\n",
      "Epoch 82/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.9350 - acc: 0.6445 - val_loss: 0.9320 - val_acc: 0.6763\n",
      "Epoch 83/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.9332 - acc: 0.6445 - val_loss: 0.9296 - val_acc: 0.6763\n",
      "Epoch 84/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.9314 - acc: 0.6445 - val_loss: 0.9272 - val_acc: 0.6763\n",
      "Epoch 85/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.9296 - acc: 0.6445 - val_loss: 0.9248 - val_acc: 0.6739\n",
      "Epoch 86/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.9279 - acc: 0.6445 - val_loss: 0.9223 - val_acc: 0.6739\n",
      "Epoch 87/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.9261 - acc: 0.6445 - val_loss: 0.9199 - val_acc: 0.6739\n",
      "Epoch 88/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.9243 - acc: 0.6445 - val_loss: 0.9174 - val_acc: 0.6739\n",
      "Epoch 89/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.9226 - acc: 0.6445 - val_loss: 0.9150 - val_acc: 0.6739\n",
      "Epoch 90/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.9209 - acc: 0.6413 - val_loss: 0.9126 - val_acc: 0.6739\n",
      "Epoch 91/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.9192 - acc: 0.6437 - val_loss: 0.9102 - val_acc: 0.6643\n",
      "Epoch 92/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.9175 - acc: 0.6429 - val_loss: 0.9078 - val_acc: 0.6643\n",
      "Epoch 93/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.9158 - acc: 0.6405 - val_loss: 0.9054 - val_acc: 0.6595\n",
      "Epoch 94/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.9141 - acc: 0.6405 - val_loss: 0.9030 - val_acc: 0.6619\n",
      "Epoch 95/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.9124 - acc: 0.6429 - val_loss: 0.9005 - val_acc: 0.6619\n",
      "Epoch 96/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.9107 - acc: 0.6429 - val_loss: 0.8981 - val_acc: 0.6619\n",
      "Epoch 97/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.9090 - acc: 0.6421 - val_loss: 0.8956 - val_acc: 0.6667\n",
      "Epoch 98/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.9073 - acc: 0.6429 - val_loss: 0.8932 - val_acc: 0.6667\n",
      "Epoch 99/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.9056 - acc: 0.6429 - val_loss: 0.8908 - val_acc: 0.6643\n",
      "Epoch 100/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.9039 - acc: 0.6429 - val_loss: 0.8884 - val_acc: 0.6643\n",
      "Epoch 101/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.9022 - acc: 0.6429 - val_loss: 0.8860 - val_acc: 0.6643\n",
      "Epoch 102/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.9006 - acc: 0.6421 - val_loss: 0.8835 - val_acc: 0.6643\n",
      "Epoch 103/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.8989 - acc: 0.6333 - val_loss: 0.8811 - val_acc: 0.6643\n",
      "Epoch 104/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.8973 - acc: 0.6333 - val_loss: 0.8788 - val_acc: 0.6643\n",
      "Epoch 105/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.8956 - acc: 0.6357 - val_loss: 0.8764 - val_acc: 0.6691\n",
      "Epoch 106/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.8941 - acc: 0.6277 - val_loss: 0.8741 - val_acc: 0.6643\n",
      "Epoch 107/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.8925 - acc: 0.6293 - val_loss: 0.8718 - val_acc: 0.6403\n",
      "Epoch 108/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.8910 - acc: 0.6269 - val_loss: 0.8696 - val_acc: 0.6403\n",
      "Epoch 109/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.8894 - acc: 0.6245 - val_loss: 0.8673 - val_acc: 0.6403\n",
      "Epoch 110/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.8879 - acc: 0.6237 - val_loss: 0.8651 - val_acc: 0.6379\n",
      "Epoch 111/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.8864 - acc: 0.6221 - val_loss: 0.8629 - val_acc: 0.6379\n",
      "Epoch 112/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.8849 - acc: 0.6229 - val_loss: 0.8608 - val_acc: 0.6379\n",
      "Epoch 113/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.8834 - acc: 0.6229 - val_loss: 0.8587 - val_acc: 0.6379\n",
      "Epoch 114/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.8820 - acc: 0.6221 - val_loss: 0.8566 - val_acc: 0.6379\n",
      "Epoch 115/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.8806 - acc: 0.6237 - val_loss: 0.8545 - val_acc: 0.6379\n",
      "Epoch 116/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.8792 - acc: 0.6229 - val_loss: 0.8524 - val_acc: 0.6379\n",
      "Epoch 117/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.8777 - acc: 0.6237 - val_loss: 0.8503 - val_acc: 0.6379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.8764 - acc: 0.6229 - val_loss: 0.8483 - val_acc: 0.6379\n",
      "Epoch 119/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.8750 - acc: 0.6237 - val_loss: 0.8463 - val_acc: 0.6379\n",
      "Epoch 120/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.8737 - acc: 0.6245 - val_loss: 0.8443 - val_acc: 0.6379\n",
      "Epoch 121/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.8724 - acc: 0.6237 - val_loss: 0.8423 - val_acc: 0.6379\n",
      "Epoch 122/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.8711 - acc: 0.6237 - val_loss: 0.8404 - val_acc: 0.6379\n",
      "Epoch 123/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.8698 - acc: 0.6237 - val_loss: 0.8384 - val_acc: 0.6379\n",
      "Epoch 124/2000\n",
      "1249/1249 [==============================] - 0s 204us/step - loss: 0.8685 - acc: 0.6221 - val_loss: 0.8365 - val_acc: 0.6403\n",
      "Epoch 125/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.8673 - acc: 0.6229 - val_loss: 0.8347 - val_acc: 0.6403\n",
      "Epoch 126/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.8660 - acc: 0.6213 - val_loss: 0.8329 - val_acc: 0.6403\n",
      "Epoch 127/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.8648 - acc: 0.6221 - val_loss: 0.8310 - val_acc: 0.6403\n",
      "Epoch 128/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.8636 - acc: 0.6213 - val_loss: 0.8292 - val_acc: 0.6403\n",
      "Epoch 129/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.8624 - acc: 0.6197 - val_loss: 0.8274 - val_acc: 0.6403\n",
      "Epoch 130/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.8612 - acc: 0.6213 - val_loss: 0.8256 - val_acc: 0.6427\n",
      "Epoch 131/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.8601 - acc: 0.6197 - val_loss: 0.8239 - val_acc: 0.6427\n",
      "Epoch 132/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.8589 - acc: 0.6205 - val_loss: 0.8223 - val_acc: 0.6427\n",
      "Epoch 133/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.8578 - acc: 0.6213 - val_loss: 0.8206 - val_acc: 0.6427\n",
      "Epoch 134/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.8567 - acc: 0.6213 - val_loss: 0.8189 - val_acc: 0.6427\n",
      "Epoch 135/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.8556 - acc: 0.6221 - val_loss: 0.8173 - val_acc: 0.6427\n",
      "Epoch 136/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.8545 - acc: 0.6245 - val_loss: 0.8157 - val_acc: 0.6427\n",
      "Epoch 137/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.8535 - acc: 0.6229 - val_loss: 0.8141 - val_acc: 0.6427\n",
      "Epoch 138/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.8524 - acc: 0.6269 - val_loss: 0.8126 - val_acc: 0.6523\n",
      "Epoch 139/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.8514 - acc: 0.6253 - val_loss: 0.8111 - val_acc: 0.6523\n",
      "Epoch 140/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.8504 - acc: 0.6301 - val_loss: 0.8097 - val_acc: 0.6523\n",
      "Epoch 141/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.8494 - acc: 0.6269 - val_loss: 0.8082 - val_acc: 0.6547\n",
      "Epoch 142/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.8484 - acc: 0.6293 - val_loss: 0.8068 - val_acc: 0.6547\n",
      "Epoch 143/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.8474 - acc: 0.6309 - val_loss: 0.8054 - val_acc: 0.6547\n",
      "Epoch 144/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.8464 - acc: 0.6285 - val_loss: 0.8040 - val_acc: 0.6571\n",
      "Epoch 145/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.8455 - acc: 0.6357 - val_loss: 0.8027 - val_acc: 0.6595\n",
      "Epoch 146/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.8445 - acc: 0.6421 - val_loss: 0.8014 - val_acc: 0.6643\n",
      "Epoch 147/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.8437 - acc: 0.6405 - val_loss: 0.8001 - val_acc: 0.6643\n",
      "Epoch 148/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.8427 - acc: 0.6437 - val_loss: 0.7987 - val_acc: 0.6643\n",
      "Epoch 149/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.8419 - acc: 0.6421 - val_loss: 0.7975 - val_acc: 0.6643\n",
      "Epoch 150/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.8410 - acc: 0.6437 - val_loss: 0.7962 - val_acc: 0.6643\n",
      "Epoch 151/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.8401 - acc: 0.6437 - val_loss: 0.7950 - val_acc: 0.6643\n",
      "Epoch 152/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.8392 - acc: 0.6445 - val_loss: 0.7939 - val_acc: 0.6643\n",
      "Epoch 153/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.8384 - acc: 0.6437 - val_loss: 0.7927 - val_acc: 0.6643\n",
      "Epoch 154/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.8375 - acc: 0.6453 - val_loss: 0.7914 - val_acc: 0.6643\n",
      "Epoch 155/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.8366 - acc: 0.6485 - val_loss: 0.7903 - val_acc: 0.6643\n",
      "Epoch 156/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.8357 - acc: 0.6477 - val_loss: 0.7892 - val_acc: 0.6643\n",
      "Epoch 157/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.8349 - acc: 0.6469 - val_loss: 0.7881 - val_acc: 0.6643\n",
      "Epoch 158/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.8340 - acc: 0.6477 - val_loss: 0.7870 - val_acc: 0.6643\n",
      "Epoch 159/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.8332 - acc: 0.6501 - val_loss: 0.7859 - val_acc: 0.6643\n",
      "Epoch 160/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.8324 - acc: 0.6477 - val_loss: 0.7849 - val_acc: 0.6643\n",
      "Epoch 161/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.8315 - acc: 0.6517 - val_loss: 0.7839 - val_acc: 0.6643\n",
      "Epoch 162/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.8308 - acc: 0.6485 - val_loss: 0.7829 - val_acc: 0.6643\n",
      "Epoch 163/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.8300 - acc: 0.6501 - val_loss: 0.7819 - val_acc: 0.6643\n",
      "Epoch 164/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.8291 - acc: 0.6485 - val_loss: 0.7810 - val_acc: 0.6643\n",
      "Epoch 165/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.8284 - acc: 0.6501 - val_loss: 0.7801 - val_acc: 0.6643\n",
      "Epoch 166/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.8276 - acc: 0.6509 - val_loss: 0.7792 - val_acc: 0.6643\n",
      "Epoch 167/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.8268 - acc: 0.6533 - val_loss: 0.7783 - val_acc: 0.6643\n",
      "Epoch 168/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.8260 - acc: 0.6533 - val_loss: 0.7774 - val_acc: 0.6643\n",
      "Epoch 169/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.8252 - acc: 0.6533 - val_loss: 0.7764 - val_acc: 0.6643\n",
      "Epoch 170/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.8244 - acc: 0.6541 - val_loss: 0.7755 - val_acc: 0.6643\n",
      "Epoch 171/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.8237 - acc: 0.6557 - val_loss: 0.7747 - val_acc: 0.6643\n",
      "Epoch 172/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.8229 - acc: 0.6557 - val_loss: 0.7738 - val_acc: 0.6643\n",
      "Epoch 173/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.8222 - acc: 0.6557 - val_loss: 0.7730 - val_acc: 0.6643\n",
      "Epoch 174/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.8215 - acc: 0.6557 - val_loss: 0.7722 - val_acc: 0.6643\n",
      "Epoch 175/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.8207 - acc: 0.6557 - val_loss: 0.7715 - val_acc: 0.6643\n",
      "Epoch 176/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.8200 - acc: 0.6557 - val_loss: 0.7708 - val_acc: 0.6643\n",
      "Epoch 177/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.8193 - acc: 0.6565 - val_loss: 0.7700 - val_acc: 0.6643\n",
      "Epoch 178/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.8186 - acc: 0.6565 - val_loss: 0.7693 - val_acc: 0.6619\n",
      "Epoch 179/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.8179 - acc: 0.6557 - val_loss: 0.7686 - val_acc: 0.6619\n",
      "Epoch 180/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.8172 - acc: 0.6565 - val_loss: 0.7679 - val_acc: 0.6619\n",
      "Epoch 181/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.8165 - acc: 0.6573 - val_loss: 0.7672 - val_acc: 0.6619\n",
      "Epoch 182/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.8158 - acc: 0.6573 - val_loss: 0.7665 - val_acc: 0.6619\n",
      "Epoch 183/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.8151 - acc: 0.6573 - val_loss: 0.7659 - val_acc: 0.6619\n",
      "Epoch 184/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.8144 - acc: 0.6573 - val_loss: 0.7652 - val_acc: 0.6619\n",
      "Epoch 185/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.8137 - acc: 0.6573 - val_loss: 0.7645 - val_acc: 0.6619\n",
      "Epoch 186/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.8131 - acc: 0.6573 - val_loss: 0.7639 - val_acc: 0.6619\n",
      "Epoch 187/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.8124 - acc: 0.6565 - val_loss: 0.7632 - val_acc: 0.6619\n",
      "Epoch 188/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.8118 - acc: 0.6573 - val_loss: 0.7626 - val_acc: 0.6619\n",
      "Epoch 189/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.8111 - acc: 0.6573 - val_loss: 0.7619 - val_acc: 0.6619\n",
      "Epoch 190/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.8104 - acc: 0.6581 - val_loss: 0.7613 - val_acc: 0.6619\n",
      "Epoch 191/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.8098 - acc: 0.6581 - val_loss: 0.7608 - val_acc: 0.6619\n",
      "Epoch 192/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.8091 - acc: 0.6581 - val_loss: 0.7602 - val_acc: 0.6619\n",
      "Epoch 193/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.8085 - acc: 0.6581 - val_loss: 0.7597 - val_acc: 0.6619\n",
      "Epoch 194/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.8078 - acc: 0.6581 - val_loss: 0.7591 - val_acc: 0.6619\n",
      "Epoch 195/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.8072 - acc: 0.6581 - val_loss: 0.7585 - val_acc: 0.6619\n",
      "Epoch 196/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.8066 - acc: 0.6581 - val_loss: 0.7580 - val_acc: 0.6619\n",
      "Epoch 197/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.8059 - acc: 0.6581 - val_loss: 0.7575 - val_acc: 0.6619\n",
      "Epoch 198/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.8053 - acc: 0.6581 - val_loss: 0.7569 - val_acc: 0.6619\n",
      "Epoch 199/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.8047 - acc: 0.6581 - val_loss: 0.7564 - val_acc: 0.6619\n",
      "Epoch 200/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.8041 - acc: 0.6581 - val_loss: 0.7559 - val_acc: 0.6619\n",
      "Epoch 201/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.8035 - acc: 0.6581 - val_loss: 0.7554 - val_acc: 0.6619\n",
      "Epoch 202/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.8029 - acc: 0.6581 - val_loss: 0.7548 - val_acc: 0.6619\n",
      "Epoch 203/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.8023 - acc: 0.6581 - val_loss: 0.7543 - val_acc: 0.6619\n",
      "Epoch 204/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.8017 - acc: 0.6581 - val_loss: 0.7538 - val_acc: 0.6619\n",
      "Epoch 205/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.8010 - acc: 0.6581 - val_loss: 0.7533 - val_acc: 0.6619\n",
      "Epoch 206/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.8005 - acc: 0.6581 - val_loss: 0.7528 - val_acc: 0.6619\n",
      "Epoch 207/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7999 - acc: 0.6581 - val_loss: 0.7523 - val_acc: 0.6619\n",
      "Epoch 208/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7993 - acc: 0.6581 - val_loss: 0.7519 - val_acc: 0.6619\n",
      "Epoch 209/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7987 - acc: 0.6581 - val_loss: 0.7514 - val_acc: 0.6619\n",
      "Epoch 210/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7981 - acc: 0.6581 - val_loss: 0.7510 - val_acc: 0.6619\n",
      "Epoch 211/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.7975 - acc: 0.6581 - val_loss: 0.7506 - val_acc: 0.6619\n",
      "Epoch 212/2000\n",
      "1249/1249 [==============================] - 0s 211us/step - loss: 0.7969 - acc: 0.6581 - val_loss: 0.7501 - val_acc: 0.6619\n",
      "Epoch 213/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7964 - acc: 0.6581 - val_loss: 0.7497 - val_acc: 0.6619\n",
      "Epoch 214/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7957 - acc: 0.6581 - val_loss: 0.7493 - val_acc: 0.6619\n",
      "Epoch 215/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7952 - acc: 0.6581 - val_loss: 0.7489 - val_acc: 0.6619\n",
      "Epoch 216/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7946 - acc: 0.6581 - val_loss: 0.7484 - val_acc: 0.6619\n",
      "Epoch 217/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7941 - acc: 0.6581 - val_loss: 0.7480 - val_acc: 0.6619\n",
      "Epoch 218/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.7935 - acc: 0.6581 - val_loss: 0.7476 - val_acc: 0.6619\n",
      "Epoch 219/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7930 - acc: 0.6581 - val_loss: 0.7473 - val_acc: 0.6619\n",
      "Epoch 220/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7925 - acc: 0.6581 - val_loss: 0.7468 - val_acc: 0.6619\n",
      "Epoch 221/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7919 - acc: 0.6597 - val_loss: 0.7464 - val_acc: 0.6619\n",
      "Epoch 222/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7913 - acc: 0.6581 - val_loss: 0.7460 - val_acc: 0.6619\n",
      "Epoch 223/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7908 - acc: 0.6581 - val_loss: 0.7456 - val_acc: 0.6619\n",
      "Epoch 224/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7903 - acc: 0.6581 - val_loss: 0.7452 - val_acc: 0.6619\n",
      "Epoch 225/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7897 - acc: 0.6581 - val_loss: 0.7448 - val_acc: 0.6619\n",
      "Epoch 226/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7892 - acc: 0.6581 - val_loss: 0.7445 - val_acc: 0.6595\n",
      "Epoch 227/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7887 - acc: 0.6605 - val_loss: 0.7441 - val_acc: 0.6595\n",
      "Epoch 228/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7881 - acc: 0.6597 - val_loss: 0.7438 - val_acc: 0.6595\n",
      "Epoch 229/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7876 - acc: 0.6621 - val_loss: 0.7434 - val_acc: 0.6595\n",
      "Epoch 230/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7871 - acc: 0.6605 - val_loss: 0.7431 - val_acc: 0.6595\n",
      "Epoch 231/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7866 - acc: 0.6597 - val_loss: 0.7427 - val_acc: 0.6811\n",
      "Epoch 232/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7861 - acc: 0.6605 - val_loss: 0.7423 - val_acc: 0.6835\n",
      "Epoch 233/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7856 - acc: 0.6605 - val_loss: 0.7419 - val_acc: 0.6835\n",
      "Epoch 234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7851 - acc: 0.6621 - val_loss: 0.7416 - val_acc: 0.6835\n",
      "Epoch 235/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7846 - acc: 0.6653 - val_loss: 0.7412 - val_acc: 0.6835\n",
      "Epoch 236/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7841 - acc: 0.6693 - val_loss: 0.7409 - val_acc: 0.6811\n",
      "Epoch 237/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7837 - acc: 0.6725 - val_loss: 0.7405 - val_acc: 0.6595\n",
      "Epoch 238/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7832 - acc: 0.6605 - val_loss: 0.7401 - val_acc: 0.6595\n",
      "Epoch 239/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.7827 - acc: 0.6645 - val_loss: 0.7399 - val_acc: 0.6595\n",
      "Epoch 240/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7822 - acc: 0.6597 - val_loss: 0.7396 - val_acc: 0.6595\n",
      "Epoch 241/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7817 - acc: 0.6581 - val_loss: 0.7392 - val_acc: 0.6595\n",
      "Epoch 242/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7812 - acc: 0.6605 - val_loss: 0.7389 - val_acc: 0.6595\n",
      "Epoch 243/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7808 - acc: 0.6685 - val_loss: 0.7386 - val_acc: 0.6595\n",
      "Epoch 244/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7803 - acc: 0.6645 - val_loss: 0.7383 - val_acc: 0.6595\n",
      "Epoch 245/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7798 - acc: 0.6637 - val_loss: 0.7379 - val_acc: 0.6595\n",
      "Epoch 246/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7794 - acc: 0.6629 - val_loss: 0.7376 - val_acc: 0.6619\n",
      "Epoch 247/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7789 - acc: 0.6597 - val_loss: 0.7373 - val_acc: 0.6835\n",
      "Epoch 248/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7784 - acc: 0.6693 - val_loss: 0.7371 - val_acc: 0.6811\n",
      "Epoch 249/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7780 - acc: 0.6693 - val_loss: 0.7368 - val_acc: 0.6811\n",
      "Epoch 250/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7775 - acc: 0.6701 - val_loss: 0.7365 - val_acc: 0.6811\n",
      "Epoch 251/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7771 - acc: 0.6677 - val_loss: 0.7362 - val_acc: 0.6906\n",
      "Epoch 252/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7766 - acc: 0.6725 - val_loss: 0.7359 - val_acc: 0.6906\n",
      "Epoch 253/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7762 - acc: 0.6701 - val_loss: 0.7357 - val_acc: 0.6906\n",
      "Epoch 254/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.7757 - acc: 0.6613 - val_loss: 0.7354 - val_acc: 0.6906\n",
      "Epoch 255/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7753 - acc: 0.6749 - val_loss: 0.7351 - val_acc: 0.6882\n",
      "Epoch 256/2000\n",
      "1249/1249 [==============================] - 0s 200us/step - loss: 0.7748 - acc: 0.6797 - val_loss: 0.7349 - val_acc: 0.6906\n",
      "Epoch 257/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7744 - acc: 0.6669 - val_loss: 0.7346 - val_acc: 0.6906\n",
      "Epoch 258/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7740 - acc: 0.6749 - val_loss: 0.7343 - val_acc: 0.6906\n",
      "Epoch 259/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7735 - acc: 0.6765 - val_loss: 0.7341 - val_acc: 0.6906\n",
      "Epoch 260/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7731 - acc: 0.6693 - val_loss: 0.7339 - val_acc: 0.6906\n",
      "Epoch 261/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7727 - acc: 0.6717 - val_loss: 0.7337 - val_acc: 0.6906\n",
      "Epoch 262/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7722 - acc: 0.6749 - val_loss: 0.7335 - val_acc: 0.6882\n",
      "Epoch 263/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.7718 - acc: 0.6773 - val_loss: 0.7333 - val_acc: 0.6882\n",
      "Epoch 264/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.7714 - acc: 0.6709 - val_loss: 0.7331 - val_acc: 0.6835\n",
      "Epoch 265/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.7709 - acc: 0.6773 - val_loss: 0.7328 - val_acc: 0.6835\n",
      "Epoch 266/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7705 - acc: 0.6765 - val_loss: 0.7327 - val_acc: 0.6835\n",
      "Epoch 267/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7701 - acc: 0.6749 - val_loss: 0.7325 - val_acc: 0.6835\n",
      "Epoch 268/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7696 - acc: 0.6781 - val_loss: 0.7322 - val_acc: 0.6859\n",
      "Epoch 269/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.7693 - acc: 0.6765 - val_loss: 0.7320 - val_acc: 0.6882\n",
      "Epoch 270/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7688 - acc: 0.6645 - val_loss: 0.7317 - val_acc: 0.6882\n",
      "Epoch 271/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7684 - acc: 0.6765 - val_loss: 0.7315 - val_acc: 0.6882\n",
      "Epoch 272/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7680 - acc: 0.6797 - val_loss: 0.7313 - val_acc: 0.6882\n",
      "Epoch 273/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7676 - acc: 0.6709 - val_loss: 0.7311 - val_acc: 0.6859\n",
      "Epoch 274/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7672 - acc: 0.6765 - val_loss: 0.7309 - val_acc: 0.6859\n",
      "Epoch 275/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7668 - acc: 0.6805 - val_loss: 0.7308 - val_acc: 0.6859\n",
      "Epoch 276/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7664 - acc: 0.6926 - val_loss: 0.7306 - val_acc: 0.6906\n",
      "Epoch 277/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7660 - acc: 0.6869 - val_loss: 0.7303 - val_acc: 0.6835\n",
      "Epoch 278/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7656 - acc: 0.6821 - val_loss: 0.7300 - val_acc: 0.6930\n",
      "Epoch 279/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7652 - acc: 0.6845 - val_loss: 0.7298 - val_acc: 0.7074\n",
      "Epoch 280/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7647 - acc: 0.6998 - val_loss: 0.7297 - val_acc: 0.7074\n",
      "Epoch 281/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7644 - acc: 0.7086 - val_loss: 0.7294 - val_acc: 0.7074\n",
      "Epoch 282/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7640 - acc: 0.7038 - val_loss: 0.7292 - val_acc: 0.7074\n",
      "Epoch 283/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7637 - acc: 0.7070 - val_loss: 0.7292 - val_acc: 0.7050\n",
      "Epoch 284/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7632 - acc: 0.7030 - val_loss: 0.7290 - val_acc: 0.7050\n",
      "Epoch 285/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7628 - acc: 0.7086 - val_loss: 0.7288 - val_acc: 0.7050\n",
      "Epoch 286/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7625 - acc: 0.7070 - val_loss: 0.7286 - val_acc: 0.7122\n",
      "Epoch 287/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7621 - acc: 0.7046 - val_loss: 0.7284 - val_acc: 0.7194\n",
      "Epoch 288/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.7617 - acc: 0.7054 - val_loss: 0.7282 - val_acc: 0.7242\n",
      "Epoch 289/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7613 - acc: 0.7078 - val_loss: 0.7280 - val_acc: 0.7194\n",
      "Epoch 290/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.7610 - acc: 0.7070 - val_loss: 0.7279 - val_acc: 0.7266\n",
      "Epoch 291/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7606 - acc: 0.7078 - val_loss: 0.7277 - val_acc: 0.7194\n",
      "Epoch 292/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7603 - acc: 0.7102 - val_loss: 0.7275 - val_acc: 0.7266\n",
      "Epoch 293/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7599 - acc: 0.7086 - val_loss: 0.7273 - val_acc: 0.7290\n",
      "Epoch 294/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7595 - acc: 0.7086 - val_loss: 0.7271 - val_acc: 0.7290\n",
      "Epoch 295/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7592 - acc: 0.7086 - val_loss: 0.7269 - val_acc: 0.7290\n",
      "Epoch 296/2000\n",
      "1249/1249 [==============================] - 0s 205us/step - loss: 0.7588 - acc: 0.7038 - val_loss: 0.7267 - val_acc: 0.7290\n",
      "Epoch 297/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7584 - acc: 0.7078 - val_loss: 0.7265 - val_acc: 0.7290\n",
      "Epoch 298/2000\n",
      "1249/1249 [==============================] - 0s 141us/step - loss: 0.7581 - acc: 0.7086 - val_loss: 0.7263 - val_acc: 0.7290\n",
      "Epoch 299/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7578 - acc: 0.7102 - val_loss: 0.7262 - val_acc: 0.7290\n",
      "Epoch 300/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7574 - acc: 0.7102 - val_loss: 0.7260 - val_acc: 0.7290\n",
      "Epoch 301/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7571 - acc: 0.7110 - val_loss: 0.7258 - val_acc: 0.7290\n",
      "Epoch 302/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.7567 - acc: 0.7102 - val_loss: 0.7257 - val_acc: 0.7290\n",
      "Epoch 303/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.7564 - acc: 0.7086 - val_loss: 0.7257 - val_acc: 0.7290\n",
      "Epoch 304/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7561 - acc: 0.7110 - val_loss: 0.7256 - val_acc: 0.7290\n",
      "Epoch 305/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7558 - acc: 0.7110 - val_loss: 0.7255 - val_acc: 0.7290\n",
      "Epoch 306/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.7554 - acc: 0.7102 - val_loss: 0.7254 - val_acc: 0.7290\n",
      "Epoch 307/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7551 - acc: 0.7110 - val_loss: 0.7253 - val_acc: 0.7290\n",
      "Epoch 308/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.7548 - acc: 0.7118 - val_loss: 0.7251 - val_acc: 0.7290\n",
      "Epoch 309/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7544 - acc: 0.7118 - val_loss: 0.7249 - val_acc: 0.7290\n",
      "Epoch 310/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7541 - acc: 0.7118 - val_loss: 0.7249 - val_acc: 0.7290\n",
      "Epoch 311/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7538 - acc: 0.7126 - val_loss: 0.7247 - val_acc: 0.7290\n",
      "Epoch 312/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7535 - acc: 0.7118 - val_loss: 0.7245 - val_acc: 0.7290\n",
      "Epoch 313/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7531 - acc: 0.7118 - val_loss: 0.7244 - val_acc: 0.7290\n",
      "Epoch 314/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7529 - acc: 0.7118 - val_loss: 0.7242 - val_acc: 0.7290\n",
      "Epoch 315/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7525 - acc: 0.7118 - val_loss: 0.7242 - val_acc: 0.7290\n",
      "Epoch 316/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7522 - acc: 0.7118 - val_loss: 0.7241 - val_acc: 0.7290\n",
      "Epoch 317/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7519 - acc: 0.7118 - val_loss: 0.7239 - val_acc: 0.7290\n",
      "Epoch 318/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7516 - acc: 0.7118 - val_loss: 0.7239 - val_acc: 0.7290\n",
      "Epoch 319/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7513 - acc: 0.7118 - val_loss: 0.7237 - val_acc: 0.7290\n",
      "Epoch 320/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7510 - acc: 0.7118 - val_loss: 0.7236 - val_acc: 0.7290\n",
      "Epoch 321/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7507 - acc: 0.7118 - val_loss: 0.7235 - val_acc: 0.7290\n",
      "Epoch 322/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.7504 - acc: 0.7126 - val_loss: 0.7235 - val_acc: 0.7290\n",
      "Epoch 323/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7501 - acc: 0.7118 - val_loss: 0.7234 - val_acc: 0.7290\n",
      "Epoch 324/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7498 - acc: 0.7118 - val_loss: 0.7233 - val_acc: 0.7290\n",
      "Epoch 325/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7496 - acc: 0.7118 - val_loss: 0.7232 - val_acc: 0.7290\n",
      "Epoch 326/2000\n",
      "1249/1249 [==============================] - 0s 142us/step - loss: 0.7492 - acc: 0.7118 - val_loss: 0.7230 - val_acc: 0.7290\n",
      "Epoch 327/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.7489 - acc: 0.7118 - val_loss: 0.7230 - val_acc: 0.7290\n",
      "Epoch 328/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7487 - acc: 0.7126 - val_loss: 0.7229 - val_acc: 0.7290\n",
      "Epoch 329/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7484 - acc: 0.7126 - val_loss: 0.7227 - val_acc: 0.7290\n",
      "Epoch 330/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7481 - acc: 0.7134 - val_loss: 0.7227 - val_acc: 0.7290\n",
      "Epoch 331/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7478 - acc: 0.7134 - val_loss: 0.7226 - val_acc: 0.7290\n",
      "Epoch 332/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7476 - acc: 0.7134 - val_loss: 0.7226 - val_acc: 0.7290\n",
      "Epoch 333/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7473 - acc: 0.7118 - val_loss: 0.7224 - val_acc: 0.7290\n",
      "Epoch 334/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7470 - acc: 0.7126 - val_loss: 0.7223 - val_acc: 0.7290\n",
      "Epoch 335/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7468 - acc: 0.7134 - val_loss: 0.7223 - val_acc: 0.7290\n",
      "Epoch 336/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7466 - acc: 0.7134 - val_loss: 0.7221 - val_acc: 0.7290\n",
      "Epoch 337/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7462 - acc: 0.7126 - val_loss: 0.7220 - val_acc: 0.7290\n",
      "Epoch 338/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.7460 - acc: 0.7134 - val_loss: 0.7220 - val_acc: 0.7290\n",
      "Epoch 339/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7457 - acc: 0.7118 - val_loss: 0.7219 - val_acc: 0.7290\n",
      "Epoch 340/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7455 - acc: 0.7118 - val_loss: 0.7217 - val_acc: 0.7290\n",
      "Epoch 341/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7452 - acc: 0.7126 - val_loss: 0.7215 - val_acc: 0.7290\n",
      "Epoch 342/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.7450 - acc: 0.7126 - val_loss: 0.7215 - val_acc: 0.7290\n",
      "Epoch 343/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.7447 - acc: 0.7126 - val_loss: 0.7214 - val_acc: 0.7290\n",
      "Epoch 344/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7445 - acc: 0.7110 - val_loss: 0.7212 - val_acc: 0.7290\n",
      "Epoch 345/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7442 - acc: 0.7118 - val_loss: 0.7210 - val_acc: 0.7290\n",
      "Epoch 346/2000\n",
      "1249/1249 [==============================] - 0s 200us/step - loss: 0.7440 - acc: 0.7078 - val_loss: 0.7209 - val_acc: 0.7314\n",
      "Epoch 347/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7439 - acc: 0.7086 - val_loss: 0.7208 - val_acc: 0.7218\n",
      "Epoch 348/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7435 - acc: 0.7070 - val_loss: 0.7207 - val_acc: 0.7242\n",
      "Epoch 349/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7433 - acc: 0.7126 - val_loss: 0.7207 - val_acc: 0.7218\n",
      "Epoch 350/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7430 - acc: 0.7070 - val_loss: 0.7206 - val_acc: 0.7218\n",
      "Epoch 351/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7428 - acc: 0.7054 - val_loss: 0.7205 - val_acc: 0.7242\n",
      "Epoch 352/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.7425 - acc: 0.7110 - val_loss: 0.7203 - val_acc: 0.7170\n",
      "Epoch 353/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.7423 - acc: 0.7070 - val_loss: 0.7203 - val_acc: 0.7170\n",
      "Epoch 354/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7421 - acc: 0.7054 - val_loss: 0.7203 - val_acc: 0.7170\n",
      "Epoch 355/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7419 - acc: 0.7046 - val_loss: 0.7202 - val_acc: 0.7170\n",
      "Epoch 356/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7416 - acc: 0.7046 - val_loss: 0.7201 - val_acc: 0.7218\n",
      "Epoch 357/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7414 - acc: 0.7046 - val_loss: 0.7199 - val_acc: 0.7218\n",
      "Epoch 358/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7412 - acc: 0.7054 - val_loss: 0.7199 - val_acc: 0.7218\n",
      "Epoch 359/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7410 - acc: 0.7118 - val_loss: 0.7197 - val_acc: 0.7218\n",
      "Epoch 360/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.7407 - acc: 0.7078 - val_loss: 0.7196 - val_acc: 0.7218\n",
      "Epoch 361/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.7405 - acc: 0.7046 - val_loss: 0.7195 - val_acc: 0.7218\n",
      "Epoch 362/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7404 - acc: 0.7070 - val_loss: 0.7194 - val_acc: 0.7218\n",
      "Epoch 363/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7401 - acc: 0.7070 - val_loss: 0.7194 - val_acc: 0.7218\n",
      "Epoch 364/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7399 - acc: 0.7062 - val_loss: 0.7193 - val_acc: 0.7218\n",
      "Epoch 365/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.7397 - acc: 0.7078 - val_loss: 0.7192 - val_acc: 0.7218\n",
      "Epoch 366/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.7395 - acc: 0.7110 - val_loss: 0.7191 - val_acc: 0.7218\n",
      "Epoch 367/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7392 - acc: 0.7070 - val_loss: 0.7191 - val_acc: 0.7218\n",
      "Epoch 368/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7390 - acc: 0.7118 - val_loss: 0.7190 - val_acc: 0.7218\n",
      "Epoch 369/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7388 - acc: 0.7126 - val_loss: 0.7190 - val_acc: 0.7218\n",
      "Epoch 370/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7386 - acc: 0.7086 - val_loss: 0.7188 - val_acc: 0.7218\n",
      "Epoch 371/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7384 - acc: 0.7070 - val_loss: 0.7187 - val_acc: 0.7218\n",
      "Epoch 372/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7382 - acc: 0.7102 - val_loss: 0.7186 - val_acc: 0.7218\n",
      "Epoch 373/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7380 - acc: 0.7118 - val_loss: 0.7187 - val_acc: 0.7218\n",
      "Epoch 374/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7378 - acc: 0.7102 - val_loss: 0.7186 - val_acc: 0.7218\n",
      "Epoch 375/2000\n",
      "1249/1249 [==============================] - 0s 147us/step - loss: 0.7376 - acc: 0.7118 - val_loss: 0.7185 - val_acc: 0.7218\n",
      "Epoch 376/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7374 - acc: 0.7126 - val_loss: 0.7185 - val_acc: 0.7218\n",
      "Epoch 377/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7372 - acc: 0.7118 - val_loss: 0.7184 - val_acc: 0.7218\n",
      "Epoch 378/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7370 - acc: 0.7126 - val_loss: 0.7183 - val_acc: 0.7218\n",
      "Epoch 379/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7368 - acc: 0.7110 - val_loss: 0.7183 - val_acc: 0.7218\n",
      "Epoch 380/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7366 - acc: 0.7126 - val_loss: 0.7181 - val_acc: 0.7218\n",
      "Epoch 381/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7364 - acc: 0.7126 - val_loss: 0.7180 - val_acc: 0.7218\n",
      "Epoch 382/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7362 - acc: 0.7126 - val_loss: 0.7180 - val_acc: 0.7218\n",
      "Epoch 383/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7361 - acc: 0.7102 - val_loss: 0.7179 - val_acc: 0.7218\n",
      "Epoch 384/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7358 - acc: 0.7086 - val_loss: 0.7179 - val_acc: 0.7218\n",
      "Epoch 385/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7357 - acc: 0.7110 - val_loss: 0.7179 - val_acc: 0.7218\n",
      "Epoch 386/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7355 - acc: 0.7094 - val_loss: 0.7178 - val_acc: 0.7218\n",
      "Epoch 387/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7353 - acc: 0.7126 - val_loss: 0.7178 - val_acc: 0.7218\n",
      "Epoch 388/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7351 - acc: 0.7142 - val_loss: 0.7177 - val_acc: 0.7218\n",
      "Epoch 389/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7349 - acc: 0.7110 - val_loss: 0.7176 - val_acc: 0.7218\n",
      "Epoch 390/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7348 - acc: 0.7086 - val_loss: 0.7176 - val_acc: 0.7218\n",
      "Epoch 391/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7346 - acc: 0.7078 - val_loss: 0.7175 - val_acc: 0.7218\n",
      "Epoch 392/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7344 - acc: 0.7086 - val_loss: 0.7174 - val_acc: 0.7194\n",
      "Epoch 393/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7343 - acc: 0.7062 - val_loss: 0.7172 - val_acc: 0.7194\n",
      "Epoch 394/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7341 - acc: 0.7062 - val_loss: 0.7172 - val_acc: 0.7218\n",
      "Epoch 395/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7340 - acc: 0.7110 - val_loss: 0.7172 - val_acc: 0.7194\n",
      "Epoch 396/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7338 - acc: 0.7062 - val_loss: 0.7172 - val_acc: 0.7194\n",
      "Epoch 397/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7336 - acc: 0.7054 - val_loss: 0.7172 - val_acc: 0.7194\n",
      "Epoch 398/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7334 - acc: 0.7094 - val_loss: 0.7172 - val_acc: 0.7194\n",
      "Epoch 399/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7332 - acc: 0.7094 - val_loss: 0.7172 - val_acc: 0.7194\n",
      "Epoch 400/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7330 - acc: 0.7054 - val_loss: 0.7171 - val_acc: 0.7194\n",
      "Epoch 401/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7329 - acc: 0.7062 - val_loss: 0.7170 - val_acc: 0.7194\n",
      "Epoch 402/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.7327 - acc: 0.7046 - val_loss: 0.7169 - val_acc: 0.7194\n",
      "Epoch 403/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7325 - acc: 0.7062 - val_loss: 0.7169 - val_acc: 0.7194\n",
      "Epoch 404/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.7324 - acc: 0.7062 - val_loss: 0.7168 - val_acc: 0.7194\n",
      "Epoch 405/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7322 - acc: 0.7062 - val_loss: 0.7168 - val_acc: 0.7194\n",
      "Epoch 406/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7321 - acc: 0.7062 - val_loss: 0.7168 - val_acc: 0.7194\n",
      "Epoch 407/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7319 - acc: 0.7062 - val_loss: 0.7168 - val_acc: 0.7194\n",
      "Epoch 408/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 207us/step - loss: 0.7318 - acc: 0.7062 - val_loss: 0.7167 - val_acc: 0.7194\n",
      "Epoch 409/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7316 - acc: 0.7078 - val_loss: 0.7167 - val_acc: 0.7194\n",
      "Epoch 410/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7314 - acc: 0.7062 - val_loss: 0.7166 - val_acc: 0.7194\n",
      "Epoch 411/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7313 - acc: 0.7062 - val_loss: 0.7166 - val_acc: 0.7194\n",
      "Epoch 412/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7311 - acc: 0.7062 - val_loss: 0.7166 - val_acc: 0.7194\n",
      "Epoch 413/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7309 - acc: 0.7062 - val_loss: 0.7166 - val_acc: 0.7194\n",
      "Epoch 414/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.7308 - acc: 0.7062 - val_loss: 0.7166 - val_acc: 0.7194\n",
      "Epoch 415/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.7306 - acc: 0.7062 - val_loss: 0.7166 - val_acc: 0.7194\n",
      "Epoch 416/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.7305 - acc: 0.7062 - val_loss: 0.7165 - val_acc: 0.7194\n",
      "Epoch 417/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.7303 - acc: 0.7062 - val_loss: 0.7165 - val_acc: 0.7194\n",
      "Epoch 418/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7302 - acc: 0.7062 - val_loss: 0.7164 - val_acc: 0.7194\n",
      "Epoch 419/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7299 - acc: 0.7062 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 420/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7298 - acc: 0.7062 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 421/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7297 - acc: 0.7062 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 422/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7296 - acc: 0.7062 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 423/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7294 - acc: 0.7070 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 424/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7292 - acc: 0.7062 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 425/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7290 - acc: 0.7062 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 426/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7289 - acc: 0.7062 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 427/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.7287 - acc: 0.7062 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 428/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7287 - acc: 0.7062 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 429/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7285 - acc: 0.7062 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 430/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7284 - acc: 0.7062 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 431/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7283 - acc: 0.7062 - val_loss: 0.7164 - val_acc: 0.7194\n",
      "Epoch 432/2000\n",
      "1249/1249 [==============================] - 0s 141us/step - loss: 0.7281 - acc: 0.7062 - val_loss: 0.7164 - val_acc: 0.7194\n",
      "Epoch 433/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.7280 - acc: 0.7062 - val_loss: 0.7164 - val_acc: 0.7194\n",
      "Epoch 434/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7279 - acc: 0.7062 - val_loss: 0.7164 - val_acc: 0.7194\n",
      "Epoch 435/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7277 - acc: 0.7070 - val_loss: 0.7164 - val_acc: 0.7194\n",
      "Epoch 436/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7277 - acc: 0.7062 - val_loss: 0.7164 - val_acc: 0.7194\n",
      "Epoch 437/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7275 - acc: 0.7062 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 438/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7274 - acc: 0.7062 - val_loss: 0.7163 - val_acc: 0.7194\n",
      "Epoch 439/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7272 - acc: 0.7062 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 440/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7271 - acc: 0.7070 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 441/2000\n",
      "1249/1249 [==============================] - 0s 147us/step - loss: 0.7271 - acc: 0.7062 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 442/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7269 - acc: 0.7062 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Epoch 443/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7268 - acc: 0.7062 - val_loss: 0.7161 - val_acc: 0.7194\n",
      "Epoch 444/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7267 - acc: 0.7062 - val_loss: 0.7161 - val_acc: 0.7194\n",
      "Epoch 445/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7266 - acc: 0.7062 - val_loss: 0.7160 - val_acc: 0.7194\n",
      "Epoch 446/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7265 - acc: 0.7062 - val_loss: 0.7160 - val_acc: 0.7194\n",
      "Epoch 447/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.7264 - acc: 0.7062 - val_loss: 0.7160 - val_acc: 0.7194\n",
      "Epoch 448/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7262 - acc: 0.7062 - val_loss: 0.7159 - val_acc: 0.7194\n",
      "Epoch 449/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.7261 - acc: 0.7062 - val_loss: 0.7160 - val_acc: 0.7194\n",
      "Epoch 450/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7261 - acc: 0.7062 - val_loss: 0.7159 - val_acc: 0.7194\n",
      "Epoch 451/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7259 - acc: 0.7070 - val_loss: 0.7160 - val_acc: 0.7194\n",
      "Epoch 452/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7259 - acc: 0.7062 - val_loss: 0.7160 - val_acc: 0.7194\n",
      "Epoch 453/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7257 - acc: 0.7070 - val_loss: 0.7160 - val_acc: 0.7194\n",
      "Epoch 454/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7256 - acc: 0.7062 - val_loss: 0.7159 - val_acc: 0.7194\n",
      "Epoch 455/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7254 - acc: 0.7062 - val_loss: 0.7158 - val_acc: 0.7194\n",
      "Epoch 456/2000\n",
      "1249/1249 [==============================] - 0s 198us/step - loss: 0.7253 - acc: 0.7070 - val_loss: 0.7158 - val_acc: 0.7194\n",
      "Epoch 457/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.7253 - acc: 0.7070 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 458/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7251 - acc: 0.7070 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 459/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7250 - acc: 0.7062 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 460/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7249 - acc: 0.7062 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 461/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7249 - acc: 0.7070 - val_loss: 0.7158 - val_acc: 0.7194\n",
      "Epoch 462/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7247 - acc: 0.7070 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 463/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7246 - acc: 0.7062 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 464/2000\n",
      "1249/1249 [==============================] - 0s 214us/step - loss: 0.7245 - acc: 0.7062 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 465/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7244 - acc: 0.7070 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 466/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7243 - acc: 0.7078 - val_loss: 0.7157 - val_acc: 0.7194\n",
      "Epoch 467/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7242 - acc: 0.7070 - val_loss: 0.7156 - val_acc: 0.7194\n",
      "Epoch 468/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7241 - acc: 0.7070 - val_loss: 0.7155 - val_acc: 0.7194\n",
      "Epoch 469/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7240 - acc: 0.7070 - val_loss: 0.7155 - val_acc: 0.7194\n",
      "Epoch 470/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.7238 - acc: 0.7070 - val_loss: 0.7155 - val_acc: 0.7194\n",
      "Epoch 471/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7238 - acc: 0.7078 - val_loss: 0.7155 - val_acc: 0.7194\n",
      "Epoch 472/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.7236 - acc: 0.7078 - val_loss: 0.7155 - val_acc: 0.7194\n",
      "Epoch 473/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7237 - acc: 0.7070 - val_loss: 0.7154 - val_acc: 0.7194\n",
      "Epoch 474/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.7235 - acc: 0.7078 - val_loss: 0.7153 - val_acc: 0.7194\n",
      "Epoch 475/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7234 - acc: 0.7078 - val_loss: 0.7153 - val_acc: 0.7194\n",
      "Epoch 476/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7233 - acc: 0.7078 - val_loss: 0.7153 - val_acc: 0.7194\n",
      "Epoch 477/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7231 - acc: 0.7078 - val_loss: 0.7152 - val_acc: 0.7194\n",
      "Epoch 478/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7231 - acc: 0.7070 - val_loss: 0.7152 - val_acc: 0.7194\n",
      "Epoch 479/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.7229 - acc: 0.7078 - val_loss: 0.7151 - val_acc: 0.7194\n",
      "Epoch 480/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7228 - acc: 0.7078 - val_loss: 0.7151 - val_acc: 0.7194\n",
      "Epoch 481/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7227 - acc: 0.7070 - val_loss: 0.7152 - val_acc: 0.7194\n",
      "Epoch 482/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7227 - acc: 0.7070 - val_loss: 0.7150 - val_acc: 0.7194\n",
      "Epoch 483/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7226 - acc: 0.7070 - val_loss: 0.7149 - val_acc: 0.7194\n",
      "Epoch 484/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7224 - acc: 0.7086 - val_loss: 0.7148 - val_acc: 0.7194\n",
      "Epoch 485/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7223 - acc: 0.7062 - val_loss: 0.7149 - val_acc: 0.7194\n",
      "Epoch 486/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7222 - acc: 0.7070 - val_loss: 0.7148 - val_acc: 0.7194\n",
      "Epoch 487/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7221 - acc: 0.7062 - val_loss: 0.7148 - val_acc: 0.7194\n",
      "Epoch 488/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.7220 - acc: 0.7062 - val_loss: 0.7148 - val_acc: 0.7194\n",
      "Epoch 489/2000\n",
      "1249/1249 [==============================] - 0s 198us/step - loss: 0.7219 - acc: 0.7070 - val_loss: 0.7146 - val_acc: 0.7194\n",
      "Epoch 490/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.7218 - acc: 0.7046 - val_loss: 0.7145 - val_acc: 0.7194\n",
      "Epoch 491/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7218 - acc: 0.7070 - val_loss: 0.7145 - val_acc: 0.7194\n",
      "Epoch 492/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7216 - acc: 0.7070 - val_loss: 0.7145 - val_acc: 0.7194\n",
      "Epoch 493/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7215 - acc: 0.7062 - val_loss: 0.7145 - val_acc: 0.7170\n",
      "Epoch 494/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.7214 - acc: 0.7054 - val_loss: 0.7145 - val_acc: 0.7194\n",
      "Epoch 495/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.7213 - acc: 0.7062 - val_loss: 0.7146 - val_acc: 0.7170\n",
      "Epoch 496/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7213 - acc: 0.7062 - val_loss: 0.7146 - val_acc: 0.7170\n",
      "Epoch 497/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7211 - acc: 0.7070 - val_loss: 0.7144 - val_acc: 0.7170\n",
      "Epoch 498/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7211 - acc: 0.7070 - val_loss: 0.7145 - val_acc: 0.7194\n",
      "Epoch 499/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7210 - acc: 0.7062 - val_loss: 0.7145 - val_acc: 0.7170\n",
      "Epoch 500/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7208 - acc: 0.7046 - val_loss: 0.7145 - val_acc: 0.7170\n",
      "Epoch 501/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.7207 - acc: 0.7062 - val_loss: 0.7144 - val_acc: 0.7170\n",
      "Epoch 502/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7206 - acc: 0.7062 - val_loss: 0.7143 - val_acc: 0.7170\n",
      "Epoch 503/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7206 - acc: 0.7062 - val_loss: 0.7144 - val_acc: 0.7170\n",
      "Epoch 504/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7206 - acc: 0.7078 - val_loss: 0.7144 - val_acc: 0.7170\n",
      "Epoch 505/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7204 - acc: 0.7054 - val_loss: 0.7145 - val_acc: 0.7170\n",
      "Epoch 506/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7203 - acc: 0.7062 - val_loss: 0.7145 - val_acc: 0.7170\n",
      "Epoch 507/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7203 - acc: 0.7062 - val_loss: 0.7145 - val_acc: 0.7170\n",
      "Epoch 508/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7202 - acc: 0.7070 - val_loss: 0.7144 - val_acc: 0.7194\n",
      "Epoch 509/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7201 - acc: 0.7070 - val_loss: 0.7144 - val_acc: 0.7194\n",
      "Epoch 510/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.7200 - acc: 0.7062 - val_loss: 0.7143 - val_acc: 0.7194\n",
      "Epoch 511/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.7199 - acc: 0.7062 - val_loss: 0.7143 - val_acc: 0.7170\n",
      "Epoch 512/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7197 - acc: 0.7062 - val_loss: 0.7142 - val_acc: 0.7194\n",
      "Epoch 513/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7196 - acc: 0.7086 - val_loss: 0.7142 - val_acc: 0.7194\n",
      "Epoch 514/2000\n",
      "1249/1249 [==============================] - 0s 207us/step - loss: 0.7197 - acc: 0.7062 - val_loss: 0.7142 - val_acc: 0.7194\n",
      "Epoch 515/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7195 - acc: 0.7062 - val_loss: 0.7143 - val_acc: 0.7194\n",
      "Epoch 516/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.7194 - acc: 0.7078 - val_loss: 0.7142 - val_acc: 0.7194\n",
      "Epoch 517/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7194 - acc: 0.7078 - val_loss: 0.7141 - val_acc: 0.7194\n",
      "Epoch 518/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7192 - acc: 0.7070 - val_loss: 0.7140 - val_acc: 0.7194\n",
      "Epoch 519/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7192 - acc: 0.7062 - val_loss: 0.7140 - val_acc: 0.7194\n",
      "Epoch 520/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7191 - acc: 0.7062 - val_loss: 0.7139 - val_acc: 0.7194\n",
      "Epoch 521/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7190 - acc: 0.7062 - val_loss: 0.7140 - val_acc: 0.7194\n",
      "Epoch 522/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7189 - acc: 0.7110 - val_loss: 0.7139 - val_acc: 0.7194\n",
      "Epoch 523/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7188 - acc: 0.7078 - val_loss: 0.7137 - val_acc: 0.7194\n",
      "Epoch 524/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7187 - acc: 0.7062 - val_loss: 0.7136 - val_acc: 0.7194\n",
      "Epoch 525/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7186 - acc: 0.7086 - val_loss: 0.7136 - val_acc: 0.7218\n",
      "Epoch 526/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7185 - acc: 0.7070 - val_loss: 0.7136 - val_acc: 0.7194\n",
      "Epoch 527/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7184 - acc: 0.7102 - val_loss: 0.7135 - val_acc: 0.7194\n",
      "Epoch 528/2000\n",
      "1249/1249 [==============================] - 0s 193us/step - loss: 0.7184 - acc: 0.7062 - val_loss: 0.7134 - val_acc: 0.7218\n",
      "Epoch 529/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.7183 - acc: 0.7094 - val_loss: 0.7134 - val_acc: 0.7194\n",
      "Epoch 530/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.7182 - acc: 0.7070 - val_loss: 0.7134 - val_acc: 0.7218\n",
      "Epoch 531/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7181 - acc: 0.7102 - val_loss: 0.7134 - val_acc: 0.7194\n",
      "Epoch 532/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.7180 - acc: 0.7094 - val_loss: 0.7134 - val_acc: 0.7218\n",
      "Epoch 533/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7180 - acc: 0.7078 - val_loss: 0.7134 - val_acc: 0.7218\n",
      "Epoch 534/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7178 - acc: 0.7102 - val_loss: 0.7134 - val_acc: 0.7218\n",
      "Epoch 535/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.7177 - acc: 0.7094 - val_loss: 0.7134 - val_acc: 0.7218\n",
      "Epoch 536/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7177 - acc: 0.7118 - val_loss: 0.7133 - val_acc: 0.7218\n",
      "Epoch 537/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7176 - acc: 0.7110 - val_loss: 0.7133 - val_acc: 0.7218\n",
      "Epoch 538/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.7175 - acc: 0.7102 - val_loss: 0.7133 - val_acc: 0.7218\n",
      "Epoch 539/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7174 - acc: 0.7118 - val_loss: 0.7131 - val_acc: 0.7218\n",
      "Epoch 540/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7174 - acc: 0.7094 - val_loss: 0.7130 - val_acc: 0.7218\n",
      "Epoch 541/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7173 - acc: 0.7102 - val_loss: 0.7130 - val_acc: 0.7218\n",
      "Epoch 542/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7173 - acc: 0.7118 - val_loss: 0.7129 - val_acc: 0.7218\n",
      "Epoch 543/2000\n",
      "1249/1249 [==============================] - 0s 151us/step - loss: 0.7171 - acc: 0.7094 - val_loss: 0.7129 - val_acc: 0.7218\n",
      "Epoch 544/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7170 - acc: 0.7118 - val_loss: 0.7129 - val_acc: 0.7218\n",
      "Epoch 545/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7169 - acc: 0.7102 - val_loss: 0.7128 - val_acc: 0.7218\n",
      "Epoch 546/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.7170 - acc: 0.7078 - val_loss: 0.7127 - val_acc: 0.7218\n",
      "Epoch 547/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.7167 - acc: 0.7094 - val_loss: 0.7127 - val_acc: 0.7218\n",
      "Epoch 548/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7167 - acc: 0.7118 - val_loss: 0.7126 - val_acc: 0.7218\n",
      "Epoch 549/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7165 - acc: 0.7118 - val_loss: 0.7126 - val_acc: 0.7218\n",
      "Epoch 550/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7165 - acc: 0.7110 - val_loss: 0.7125 - val_acc: 0.7218\n",
      "Epoch 551/2000\n",
      "1249/1249 [==============================] - 0s 198us/step - loss: 0.7163 - acc: 0.7078 - val_loss: 0.7124 - val_acc: 0.7218\n",
      "Epoch 552/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7163 - acc: 0.7118 - val_loss: 0.7123 - val_acc: 0.7218\n",
      "Epoch 553/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7162 - acc: 0.7078 - val_loss: 0.7122 - val_acc: 0.7218\n",
      "Epoch 554/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.7161 - acc: 0.7118 - val_loss: 0.7121 - val_acc: 0.7218\n",
      "Epoch 555/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.7161 - acc: 0.7094 - val_loss: 0.7120 - val_acc: 0.7218\n",
      "Epoch 556/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7160 - acc: 0.7102 - val_loss: 0.7120 - val_acc: 0.7218\n",
      "Epoch 557/2000\n",
      "1249/1249 [==============================] - 0s 150us/step - loss: 0.7159 - acc: 0.7086 - val_loss: 0.7120 - val_acc: 0.7218\n",
      "Epoch 558/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7158 - acc: 0.7110 - val_loss: 0.7120 - val_acc: 0.7218\n",
      "Epoch 559/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7157 - acc: 0.7102 - val_loss: 0.7119 - val_acc: 0.7218\n",
      "Epoch 560/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7156 - acc: 0.7118 - val_loss: 0.7118 - val_acc: 0.7218\n",
      "Epoch 561/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7155 - acc: 0.7118 - val_loss: 0.7118 - val_acc: 0.7218\n",
      "Epoch 562/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7154 - acc: 0.7094 - val_loss: 0.7118 - val_acc: 0.7218\n",
      "Epoch 563/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.7154 - acc: 0.7094 - val_loss: 0.7117 - val_acc: 0.7218\n",
      "Epoch 564/2000\n",
      "1249/1249 [==============================] - 0s 198us/step - loss: 0.7153 - acc: 0.7086 - val_loss: 0.7116 - val_acc: 0.7218\n",
      "Epoch 565/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.7152 - acc: 0.7118 - val_loss: 0.7116 - val_acc: 0.7218\n",
      "Epoch 566/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7151 - acc: 0.7118 - val_loss: 0.7115 - val_acc: 0.7218\n",
      "Epoch 567/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.7150 - acc: 0.7086 - val_loss: 0.7115 - val_acc: 0.7218\n",
      "Epoch 568/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7149 - acc: 0.7118 - val_loss: 0.7115 - val_acc: 0.7218\n",
      "Epoch 569/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7149 - acc: 0.7118 - val_loss: 0.7116 - val_acc: 0.7218\n",
      "Epoch 570/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7147 - acc: 0.7118 - val_loss: 0.7115 - val_acc: 0.7218\n",
      "Epoch 571/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7147 - acc: 0.7118 - val_loss: 0.7114 - val_acc: 0.7218\n",
      "Epoch 572/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7146 - acc: 0.7118 - val_loss: 0.7113 - val_acc: 0.7218\n",
      "Epoch 573/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7145 - acc: 0.7118 - val_loss: 0.7112 - val_acc: 0.7218\n",
      "Epoch 574/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7144 - acc: 0.7118 - val_loss: 0.7112 - val_acc: 0.7218\n",
      "Epoch 575/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.7144 - acc: 0.7118 - val_loss: 0.7113 - val_acc: 0.7218\n",
      "Epoch 576/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.7143 - acc: 0.7102 - val_loss: 0.7112 - val_acc: 0.7218\n",
      "Epoch 577/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.7142 - acc: 0.7110 - val_loss: 0.7112 - val_acc: 0.7218\n",
      "Epoch 578/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7141 - acc: 0.7078 - val_loss: 0.7112 - val_acc: 0.7218\n",
      "Epoch 579/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7140 - acc: 0.7118 - val_loss: 0.7111 - val_acc: 0.7218\n",
      "Epoch 580/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7139 - acc: 0.7118 - val_loss: 0.7112 - val_acc: 0.7218\n",
      "Epoch 581/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7139 - acc: 0.7110 - val_loss: 0.7111 - val_acc: 0.7218\n",
      "Epoch 582/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7138 - acc: 0.7102 - val_loss: 0.7111 - val_acc: 0.7218\n",
      "Epoch 583/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7137 - acc: 0.7118 - val_loss: 0.7111 - val_acc: 0.7218\n",
      "Epoch 584/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7136 - acc: 0.7118 - val_loss: 0.7110 - val_acc: 0.7218\n",
      "Epoch 585/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7136 - acc: 0.7110 - val_loss: 0.7110 - val_acc: 0.7218\n",
      "Epoch 586/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7134 - acc: 0.7118 - val_loss: 0.7109 - val_acc: 0.7218\n",
      "Epoch 587/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.7134 - acc: 0.7118 - val_loss: 0.7107 - val_acc: 0.7218\n",
      "Epoch 588/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.7133 - acc: 0.7118 - val_loss: 0.7108 - val_acc: 0.7218\n",
      "Epoch 589/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7132 - acc: 0.7118 - val_loss: 0.7108 - val_acc: 0.7218\n",
      "Epoch 590/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7131 - acc: 0.7118 - val_loss: 0.7107 - val_acc: 0.7218\n",
      "Epoch 591/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7131 - acc: 0.7118 - val_loss: 0.7107 - val_acc: 0.7218\n",
      "Epoch 592/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7130 - acc: 0.7118 - val_loss: 0.7107 - val_acc: 0.7218\n",
      "Epoch 593/2000\n",
      "1249/1249 [==============================] - 0s 146us/step - loss: 0.7129 - acc: 0.7118 - val_loss: 0.7108 - val_acc: 0.7218\n",
      "Epoch 594/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.7129 - acc: 0.7110 - val_loss: 0.7107 - val_acc: 0.7218\n",
      "Epoch 595/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7128 - acc: 0.7118 - val_loss: 0.7108 - val_acc: 0.7218\n",
      "Epoch 596/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7128 - acc: 0.7110 - val_loss: 0.7108 - val_acc: 0.7218\n",
      "Epoch 597/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7127 - acc: 0.7102 - val_loss: 0.7108 - val_acc: 0.7218\n",
      "Epoch 598/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.7126 - acc: 0.7110 - val_loss: 0.7107 - val_acc: 0.7218\n",
      "Epoch 599/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.7124 - acc: 0.7118 - val_loss: 0.7107 - val_acc: 0.7218\n",
      "Epoch 600/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7124 - acc: 0.7110 - val_loss: 0.7106 - val_acc: 0.7218\n",
      "Epoch 601/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.7123 - acc: 0.7126 - val_loss: 0.7106 - val_acc: 0.7218\n",
      "Epoch 602/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7123 - acc: 0.7118 - val_loss: 0.7106 - val_acc: 0.7218\n",
      "Epoch 603/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7121 - acc: 0.7118 - val_loss: 0.7106 - val_acc: 0.7218\n",
      "Epoch 604/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7121 - acc: 0.7118 - val_loss: 0.7105 - val_acc: 0.7218\n",
      "Epoch 605/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7122 - acc: 0.7118 - val_loss: 0.7105 - val_acc: 0.7218\n",
      "Epoch 606/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7120 - acc: 0.7118 - val_loss: 0.7105 - val_acc: 0.7218\n",
      "Epoch 607/2000\n",
      "1249/1249 [==============================] - 0s 151us/step - loss: 0.7119 - acc: 0.7110 - val_loss: 0.7104 - val_acc: 0.7218\n",
      "Epoch 608/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7118 - acc: 0.7126 - val_loss: 0.7105 - val_acc: 0.7218\n",
      "Epoch 609/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.7118 - acc: 0.7118 - val_loss: 0.7103 - val_acc: 0.7218\n",
      "Epoch 610/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7117 - acc: 0.7118 - val_loss: 0.7102 - val_acc: 0.7218\n",
      "Epoch 611/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7116 - acc: 0.7118 - val_loss: 0.7102 - val_acc: 0.7218\n",
      "Epoch 612/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7115 - acc: 0.7118 - val_loss: 0.7101 - val_acc: 0.7218\n",
      "Epoch 613/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7115 - acc: 0.7110 - val_loss: 0.7101 - val_acc: 0.7218\n",
      "Epoch 614/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7115 - acc: 0.7118 - val_loss: 0.7102 - val_acc: 0.7218\n",
      "Epoch 615/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7114 - acc: 0.7118 - val_loss: 0.7101 - val_acc: 0.7218\n",
      "Epoch 616/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7113 - acc: 0.7118 - val_loss: 0.7101 - val_acc: 0.7218\n",
      "Epoch 617/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7113 - acc: 0.7118 - val_loss: 0.7102 - val_acc: 0.7218\n",
      "Epoch 618/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.7112 - acc: 0.7118 - val_loss: 0.7102 - val_acc: 0.7218\n",
      "Epoch 619/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.7110 - acc: 0.7118 - val_loss: 0.7100 - val_acc: 0.7218\n",
      "Epoch 620/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7110 - acc: 0.7118 - val_loss: 0.7100 - val_acc: 0.7218\n",
      "Epoch 621/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7110 - acc: 0.7118 - val_loss: 0.7098 - val_acc: 0.7218\n",
      "Epoch 622/2000\n",
      "1249/1249 [==============================] - 0s 146us/step - loss: 0.7109 - acc: 0.7118 - val_loss: 0.7098 - val_acc: 0.7218\n",
      "Epoch 623/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7108 - acc: 0.7118 - val_loss: 0.7097 - val_acc: 0.7218\n",
      "Epoch 624/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7108 - acc: 0.7126 - val_loss: 0.7096 - val_acc: 0.7218\n",
      "Epoch 625/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7107 - acc: 0.7134 - val_loss: 0.7097 - val_acc: 0.7218\n",
      "Epoch 626/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.7106 - acc: 0.7142 - val_loss: 0.7096 - val_acc: 0.7218\n",
      "Epoch 627/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7106 - acc: 0.7118 - val_loss: 0.7095 - val_acc: 0.7218\n",
      "Epoch 628/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7105 - acc: 0.7134 - val_loss: 0.7093 - val_acc: 0.7218\n",
      "Epoch 629/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7104 - acc: 0.7134 - val_loss: 0.7092 - val_acc: 0.7218\n",
      "Epoch 630/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7104 - acc: 0.7118 - val_loss: 0.7091 - val_acc: 0.7218\n",
      "Epoch 631/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7103 - acc: 0.7118 - val_loss: 0.7090 - val_acc: 0.7218\n",
      "Epoch 632/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7103 - acc: 0.7118 - val_loss: 0.7091 - val_acc: 0.7218\n",
      "Epoch 633/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7102 - acc: 0.7118 - val_loss: 0.7090 - val_acc: 0.7218\n",
      "Epoch 634/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7100 - acc: 0.7118 - val_loss: 0.7091 - val_acc: 0.7218\n",
      "Epoch 635/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7100 - acc: 0.7166 - val_loss: 0.7089 - val_acc: 0.7218\n",
      "Epoch 636/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7099 - acc: 0.7142 - val_loss: 0.7089 - val_acc: 0.7218\n",
      "Epoch 637/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7098 - acc: 0.7118 - val_loss: 0.7088 - val_acc: 0.7218\n",
      "Epoch 638/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7098 - acc: 0.7158 - val_loss: 0.7087 - val_acc: 0.7218\n",
      "Epoch 639/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7097 - acc: 0.7134 - val_loss: 0.7086 - val_acc: 0.7218\n",
      "Epoch 640/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.7097 - acc: 0.7118 - val_loss: 0.7086 - val_acc: 0.7242\n",
      "Epoch 641/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.7095 - acc: 0.7142 - val_loss: 0.7086 - val_acc: 0.7218\n",
      "Epoch 642/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7096 - acc: 0.7126 - val_loss: 0.7086 - val_acc: 0.7242\n",
      "Epoch 643/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7094 - acc: 0.7158 - val_loss: 0.7086 - val_acc: 0.7218\n",
      "Epoch 644/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.7094 - acc: 0.7142 - val_loss: 0.7086 - val_acc: 0.7242\n",
      "Epoch 645/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7093 - acc: 0.7158 - val_loss: 0.7085 - val_acc: 0.7242\n",
      "Epoch 646/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7092 - acc: 0.7166 - val_loss: 0.7085 - val_acc: 0.7242\n",
      "Epoch 647/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.7092 - acc: 0.7134 - val_loss: 0.7085 - val_acc: 0.7242\n",
      "Epoch 648/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7091 - acc: 0.7150 - val_loss: 0.7085 - val_acc: 0.7242\n",
      "Epoch 649/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.7091 - acc: 0.7118 - val_loss: 0.7086 - val_acc: 0.7242\n",
      "Epoch 650/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7091 - acc: 0.7150 - val_loss: 0.7086 - val_acc: 0.7242\n",
      "Epoch 651/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7090 - acc: 0.7150 - val_loss: 0.7085 - val_acc: 0.7242\n",
      "Epoch 652/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7089 - acc: 0.7166 - val_loss: 0.7085 - val_acc: 0.7242\n",
      "Epoch 653/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7088 - acc: 0.7150 - val_loss: 0.7084 - val_acc: 0.7242\n",
      "Epoch 654/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7088 - acc: 0.7134 - val_loss: 0.7084 - val_acc: 0.7242\n",
      "Epoch 655/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7087 - acc: 0.7158 - val_loss: 0.7084 - val_acc: 0.7242\n",
      "Epoch 656/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7086 - acc: 0.7142 - val_loss: 0.7083 - val_acc: 0.7242\n",
      "Epoch 657/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7086 - acc: 0.7174 - val_loss: 0.7083 - val_acc: 0.7242\n",
      "Epoch 658/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.7085 - acc: 0.7118 - val_loss: 0.7082 - val_acc: 0.7242\n",
      "Epoch 659/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7084 - acc: 0.7174 - val_loss: 0.7082 - val_acc: 0.7242\n",
      "Epoch 660/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7084 - acc: 0.7174 - val_loss: 0.7081 - val_acc: 0.7242\n",
      "Epoch 661/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7083 - acc: 0.7166 - val_loss: 0.7080 - val_acc: 0.7242\n",
      "Epoch 662/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7082 - acc: 0.7142 - val_loss: 0.7080 - val_acc: 0.7242\n",
      "Epoch 663/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.7081 - acc: 0.7126 - val_loss: 0.7080 - val_acc: 0.7242\n",
      "Epoch 664/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7081 - acc: 0.7166 - val_loss: 0.7079 - val_acc: 0.7242\n",
      "Epoch 665/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.7081 - acc: 0.7158 - val_loss: 0.7079 - val_acc: 0.7242\n",
      "Epoch 666/2000\n",
      "1249/1249 [==============================] - 0s 148us/step - loss: 0.7081 - acc: 0.7094 - val_loss: 0.7079 - val_acc: 0.7242\n",
      "Epoch 667/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7080 - acc: 0.7134 - val_loss: 0.7078 - val_acc: 0.7242\n",
      "Epoch 668/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7079 - acc: 0.7158 - val_loss: 0.7078 - val_acc: 0.7242\n",
      "Epoch 669/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7079 - acc: 0.7166 - val_loss: 0.7078 - val_acc: 0.7242\n",
      "Epoch 670/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7078 - acc: 0.7142 - val_loss: 0.7078 - val_acc: 0.7242\n",
      "Epoch 671/2000\n",
      "1249/1249 [==============================] - 0s 147us/step - loss: 0.7076 - acc: 0.7158 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 672/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7077 - acc: 0.7158 - val_loss: 0.7076 - val_acc: 0.7242\n",
      "Epoch 673/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7076 - acc: 0.7134 - val_loss: 0.7076 - val_acc: 0.7242\n",
      "Epoch 674/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7075 - acc: 0.7166 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 675/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7075 - acc: 0.7166 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 676/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7074 - acc: 0.7158 - val_loss: 0.7078 - val_acc: 0.7242\n",
      "Epoch 677/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7074 - acc: 0.7142 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 678/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7073 - acc: 0.7158 - val_loss: 0.7078 - val_acc: 0.7242\n",
      "Epoch 679/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7072 - acc: 0.7166 - val_loss: 0.7078 - val_acc: 0.7242\n",
      "Epoch 680/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7072 - acc: 0.7134 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 681/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.7072 - acc: 0.7150 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 682/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7071 - acc: 0.7150 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 683/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.7070 - acc: 0.7150 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 684/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.7070 - acc: 0.7150 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 685/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7070 - acc: 0.7158 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 686/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7069 - acc: 0.7142 - val_loss: 0.7076 - val_acc: 0.7242\n",
      "Epoch 687/2000\n",
      "1249/1249 [==============================] - 0s 204us/step - loss: 0.7068 - acc: 0.7150 - val_loss: 0.7076 - val_acc: 0.7242\n",
      "Epoch 688/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7067 - acc: 0.7158 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 689/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7068 - acc: 0.7150 - val_loss: 0.7077 - val_acc: 0.7242\n",
      "Epoch 690/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.7066 - acc: 0.7166 - val_loss: 0.7076 - val_acc: 0.7242\n",
      "Epoch 691/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7066 - acc: 0.7158 - val_loss: 0.7075 - val_acc: 0.7242\n",
      "Epoch 692/2000\n",
      "1249/1249 [==============================] - 0s 148us/step - loss: 0.7065 - acc: 0.7166 - val_loss: 0.7076 - val_acc: 0.7242\n",
      "Epoch 693/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7065 - acc: 0.7142 - val_loss: 0.7076 - val_acc: 0.7242\n",
      "Epoch 694/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7065 - acc: 0.7158 - val_loss: 0.7076 - val_acc: 0.7242\n",
      "Epoch 695/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7064 - acc: 0.7142 - val_loss: 0.7075 - val_acc: 0.7242\n",
      "Epoch 696/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7063 - acc: 0.7158 - val_loss: 0.7073 - val_acc: 0.7242\n",
      "Epoch 697/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7063 - acc: 0.7150 - val_loss: 0.7073 - val_acc: 0.7242\n",
      "Epoch 698/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7063 - acc: 0.7126 - val_loss: 0.7072 - val_acc: 0.7242\n",
      "Epoch 699/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7062 - acc: 0.7150 - val_loss: 0.7072 - val_acc: 0.7242\n",
      "Epoch 700/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7061 - acc: 0.7142 - val_loss: 0.7071 - val_acc: 0.7242\n",
      "Epoch 701/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7060 - acc: 0.7158 - val_loss: 0.7071 - val_acc: 0.7242\n",
      "Epoch 702/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7060 - acc: 0.7126 - val_loss: 0.7070 - val_acc: 0.7242\n",
      "Epoch 703/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7060 - acc: 0.7150 - val_loss: 0.7073 - val_acc: 0.7242\n",
      "Epoch 704/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7059 - acc: 0.7150 - val_loss: 0.7072 - val_acc: 0.7242\n",
      "Epoch 705/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7060 - acc: 0.7150 - val_loss: 0.7073 - val_acc: 0.7242\n",
      "Epoch 706/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7058 - acc: 0.7158 - val_loss: 0.7072 - val_acc: 0.7242\n",
      "Epoch 707/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7057 - acc: 0.7158 - val_loss: 0.7070 - val_acc: 0.7242\n",
      "Epoch 708/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.7057 - acc: 0.7150 - val_loss: 0.7070 - val_acc: 0.7242\n",
      "Epoch 709/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7056 - acc: 0.7150 - val_loss: 0.7070 - val_acc: 0.7242\n",
      "Epoch 710/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7056 - acc: 0.7134 - val_loss: 0.7070 - val_acc: 0.7242\n",
      "Epoch 711/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.7055 - acc: 0.7118 - val_loss: 0.7070 - val_acc: 0.7242\n",
      "Epoch 712/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7055 - acc: 0.7150 - val_loss: 0.7070 - val_acc: 0.7242\n",
      "Epoch 713/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.7055 - acc: 0.7150 - val_loss: 0.7069 - val_acc: 0.7242\n",
      "Epoch 714/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7054 - acc: 0.7142 - val_loss: 0.7069 - val_acc: 0.7242\n",
      "Epoch 715/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7052 - acc: 0.7118 - val_loss: 0.7068 - val_acc: 0.7242\n",
      "Epoch 716/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7053 - acc: 0.7142 - val_loss: 0.7068 - val_acc: 0.7242\n",
      "Epoch 717/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.7052 - acc: 0.7166 - val_loss: 0.7067 - val_acc: 0.7242\n",
      "Epoch 718/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7052 - acc: 0.7142 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 719/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7051 - acc: 0.7134 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 720/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7051 - acc: 0.7126 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 721/2000\n",
      "1249/1249 [==============================] - 0s 148us/step - loss: 0.7051 - acc: 0.7126 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 722/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7051 - acc: 0.7150 - val_loss: 0.7065 - val_acc: 0.7242\n",
      "Epoch 723/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7050 - acc: 0.7166 - val_loss: 0.7065 - val_acc: 0.7242\n",
      "Epoch 724/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7049 - acc: 0.7150 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 725/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7048 - acc: 0.7166 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 726/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.7049 - acc: 0.7110 - val_loss: 0.7067 - val_acc: 0.7242\n",
      "Epoch 727/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7047 - acc: 0.7134 - val_loss: 0.7067 - val_acc: 0.7242\n",
      "Epoch 728/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.7047 - acc: 0.7134 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 729/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7046 - acc: 0.7126 - val_loss: 0.7065 - val_acc: 0.7242\n",
      "Epoch 730/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7047 - acc: 0.7118 - val_loss: 0.7065 - val_acc: 0.7242\n",
      "Epoch 731/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7046 - acc: 0.7134 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 732/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7045 - acc: 0.7126 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 733/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.7045 - acc: 0.7134 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 734/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7043 - acc: 0.7158 - val_loss: 0.7066 - val_acc: 0.7242\n",
      "Epoch 735/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7043 - acc: 0.7126 - val_loss: 0.7064 - val_acc: 0.7242\n",
      "Epoch 736/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7044 - acc: 0.7134 - val_loss: 0.7063 - val_acc: 0.7242\n",
      "Epoch 737/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7042 - acc: 0.7118 - val_loss: 0.7063 - val_acc: 0.7242\n",
      "Epoch 738/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7043 - acc: 0.7166 - val_loss: 0.7062 - val_acc: 0.7242\n",
      "Epoch 739/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.7041 - acc: 0.7126 - val_loss: 0.7062 - val_acc: 0.7242\n",
      "Epoch 740/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7040 - acc: 0.7142 - val_loss: 0.7064 - val_acc: 0.7242\n",
      "Epoch 741/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7039 - acc: 0.7150 - val_loss: 0.7063 - val_acc: 0.7242\n",
      "Epoch 742/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7041 - acc: 0.7150 - val_loss: 0.7063 - val_acc: 0.7242\n",
      "Epoch 743/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7040 - acc: 0.7126 - val_loss: 0.7062 - val_acc: 0.7242\n",
      "Epoch 744/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7039 - acc: 0.7134 - val_loss: 0.7063 - val_acc: 0.7242\n",
      "Epoch 745/2000\n",
      "1249/1249 [==============================] - 0s 146us/step - loss: 0.7039 - acc: 0.7134 - val_loss: 0.7062 - val_acc: 0.7242\n",
      "Epoch 746/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7038 - acc: 0.7134 - val_loss: 0.7061 - val_acc: 0.7242\n",
      "Epoch 747/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7038 - acc: 0.7118 - val_loss: 0.7061 - val_acc: 0.7242\n",
      "Epoch 748/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7036 - acc: 0.7158 - val_loss: 0.7062 - val_acc: 0.7242\n",
      "Epoch 749/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7036 - acc: 0.7118 - val_loss: 0.7063 - val_acc: 0.7242\n",
      "Epoch 750/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7036 - acc: 0.7142 - val_loss: 0.7064 - val_acc: 0.7242\n",
      "Epoch 751/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7035 - acc: 0.7142 - val_loss: 0.7063 - val_acc: 0.7242\n",
      "Epoch 752/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7035 - acc: 0.7134 - val_loss: 0.7062 - val_acc: 0.7242\n",
      "Epoch 753/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7034 - acc: 0.7118 - val_loss: 0.7063 - val_acc: 0.7242\n",
      "Epoch 754/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7034 - acc: 0.7126 - val_loss: 0.7062 - val_acc: 0.7242\n",
      "Epoch 755/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7033 - acc: 0.7134 - val_loss: 0.7061 - val_acc: 0.7242\n",
      "Epoch 756/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7033 - acc: 0.7110 - val_loss: 0.7061 - val_acc: 0.7242\n",
      "Epoch 757/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7033 - acc: 0.7126 - val_loss: 0.7060 - val_acc: 0.7242\n",
      "Epoch 758/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7032 - acc: 0.7150 - val_loss: 0.7059 - val_acc: 0.7242\n",
      "Epoch 759/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7032 - acc: 0.7134 - val_loss: 0.7059 - val_acc: 0.7242\n",
      "Epoch 760/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7031 - acc: 0.7118 - val_loss: 0.7058 - val_acc: 0.7242\n",
      "Epoch 761/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7030 - acc: 0.7118 - val_loss: 0.7057 - val_acc: 0.7242\n",
      "Epoch 762/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7030 - acc: 0.7142 - val_loss: 0.7056 - val_acc: 0.7242\n",
      "Epoch 763/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7029 - acc: 0.7126 - val_loss: 0.7055 - val_acc: 0.7242\n",
      "Epoch 764/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7029 - acc: 0.7118 - val_loss: 0.7054 - val_acc: 0.7242\n",
      "Epoch 765/2000\n",
      "1249/1249 [==============================] - 0s 202us/step - loss: 0.7029 - acc: 0.7118 - val_loss: 0.7053 - val_acc: 0.7242\n",
      "Epoch 766/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.7028 - acc: 0.7118 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 767/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7028 - acc: 0.7118 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 768/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7027 - acc: 0.7118 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 769/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7026 - acc: 0.7134 - val_loss: 0.7051 - val_acc: 0.7242\n",
      "Epoch 770/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7027 - acc: 0.7126 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 771/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.7025 - acc: 0.7126 - val_loss: 0.7051 - val_acc: 0.7242\n",
      "Epoch 772/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7026 - acc: 0.7150 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 773/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.7025 - acc: 0.7118 - val_loss: 0.7050 - val_acc: 0.7242\n",
      "Epoch 774/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.7024 - acc: 0.7118 - val_loss: 0.7051 - val_acc: 0.7242\n",
      "Epoch 775/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7024 - acc: 0.7126 - val_loss: 0.7051 - val_acc: 0.7242\n",
      "Epoch 776/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7023 - acc: 0.7126 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 777/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7023 - acc: 0.7118 - val_loss: 0.7053 - val_acc: 0.7242\n",
      "Epoch 778/2000\n",
      "1249/1249 [==============================] - 0s 201us/step - loss: 0.7022 - acc: 0.7118 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 779/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7022 - acc: 0.7126 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 780/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7021 - acc: 0.7118 - val_loss: 0.7051 - val_acc: 0.7242\n",
      "Epoch 781/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7020 - acc: 0.7142 - val_loss: 0.7052 - val_acc: 0.7242\n",
      "Epoch 782/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.7020 - acc: 0.7118 - val_loss: 0.7051 - val_acc: 0.7242\n",
      "Epoch 783/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7020 - acc: 0.7118 - val_loss: 0.7049 - val_acc: 0.7242\n",
      "Epoch 784/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7020 - acc: 0.7150 - val_loss: 0.7049 - val_acc: 0.7242\n",
      "Epoch 785/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7020 - acc: 0.7182 - val_loss: 0.7049 - val_acc: 0.7242\n",
      "Epoch 786/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7018 - acc: 0.7134 - val_loss: 0.7049 - val_acc: 0.7242\n",
      "Epoch 787/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.7018 - acc: 0.7134 - val_loss: 0.7049 - val_acc: 0.7242\n",
      "Epoch 788/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.7017 - acc: 0.7150 - val_loss: 0.7049 - val_acc: 0.7242\n",
      "Epoch 789/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.7018 - acc: 0.7118 - val_loss: 0.7049 - val_acc: 0.7242\n",
      "Epoch 790/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.7018 - acc: 0.7126 - val_loss: 0.7048 - val_acc: 0.7242\n",
      "Epoch 791/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.7016 - acc: 0.7142 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 792/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.7017 - acc: 0.7118 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 793/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7016 - acc: 0.7126 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 794/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.7016 - acc: 0.7134 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 795/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.7014 - acc: 0.7118 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 796/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7014 - acc: 0.7134 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 797/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.7015 - acc: 0.7126 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 798/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.7013 - acc: 0.7126 - val_loss: 0.7045 - val_acc: 0.7242\n",
      "Epoch 799/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7013 - acc: 0.7118 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 800/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7013 - acc: 0.7118 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 801/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.7011 - acc: 0.7134 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 802/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7011 - acc: 0.7110 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 803/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.7012 - acc: 0.7126 - val_loss: 0.7045 - val_acc: 0.7242\n",
      "Epoch 804/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7010 - acc: 0.7166 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 805/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.7010 - acc: 0.7166 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 806/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7011 - acc: 0.7134 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 807/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.7009 - acc: 0.7118 - val_loss: 0.7045 - val_acc: 0.7242\n",
      "Epoch 808/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.7009 - acc: 0.7134 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 809/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.7009 - acc: 0.7118 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 810/2000\n",
      "1249/1249 [==============================] - 0s 148us/step - loss: 0.7008 - acc: 0.7142 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 811/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.7007 - acc: 0.7134 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 812/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.7007 - acc: 0.7134 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 813/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.7008 - acc: 0.7134 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 814/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7006 - acc: 0.7142 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 815/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7006 - acc: 0.7118 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 816/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.7005 - acc: 0.7142 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 817/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.7005 - acc: 0.7142 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 818/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.7004 - acc: 0.7118 - val_loss: 0.7047 - val_acc: 0.7242\n",
      "Epoch 819/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7004 - acc: 0.7134 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 820/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7005 - acc: 0.7126 - val_loss: 0.7045 - val_acc: 0.7242\n",
      "Epoch 821/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.7003 - acc: 0.7126 - val_loss: 0.7046 - val_acc: 0.7242\n",
      "Epoch 822/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7002 - acc: 0.7118 - val_loss: 0.7045 - val_acc: 0.7242\n",
      "Epoch 823/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.7002 - acc: 0.7118 - val_loss: 0.7044 - val_acc: 0.7242\n",
      "Epoch 824/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7002 - acc: 0.7134 - val_loss: 0.7045 - val_acc: 0.7242\n",
      "Epoch 825/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.7002 - acc: 0.7118 - val_loss: 0.7045 - val_acc: 0.7242\n",
      "Epoch 826/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.7002 - acc: 0.7142 - val_loss: 0.7044 - val_acc: 0.7242\n",
      "Epoch 827/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.7000 - acc: 0.7126 - val_loss: 0.7044 - val_acc: 0.7242\n",
      "Epoch 828/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.7001 - acc: 0.7166 - val_loss: 0.7044 - val_acc: 0.7242\n",
      "Epoch 829/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6999 - acc: 0.7166 - val_loss: 0.7042 - val_acc: 0.7242\n",
      "Epoch 830/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6999 - acc: 0.7134 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 831/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6999 - acc: 0.7142 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 832/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6998 - acc: 0.7126 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 833/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6999 - acc: 0.7110 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 834/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6998 - acc: 0.7150 - val_loss: 0.7040 - val_acc: 0.7242\n",
      "Epoch 835/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6997 - acc: 0.7142 - val_loss: 0.7040 - val_acc: 0.7242\n",
      "Epoch 836/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.6997 - acc: 0.7118 - val_loss: 0.7040 - val_acc: 0.7242\n",
      "Epoch 837/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6997 - acc: 0.7150 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 838/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6996 - acc: 0.7182 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 839/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6997 - acc: 0.7118 - val_loss: 0.7040 - val_acc: 0.7242\n",
      "Epoch 840/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6996 - acc: 0.7150 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 841/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6994 - acc: 0.7142 - val_loss: 0.7040 - val_acc: 0.7242\n",
      "Epoch 842/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6995 - acc: 0.7142 - val_loss: 0.7040 - val_acc: 0.7242\n",
      "Epoch 843/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6994 - acc: 0.7126 - val_loss: 0.7039 - val_acc: 0.7242\n",
      "Epoch 844/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6993 - acc: 0.7166 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 845/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6993 - acc: 0.7118 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 846/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6993 - acc: 0.7134 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 847/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6992 - acc: 0.7126 - val_loss: 0.7040 - val_acc: 0.7314\n",
      "Epoch 848/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6992 - acc: 0.7198 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 849/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6991 - acc: 0.7142 - val_loss: 0.7041 - val_acc: 0.7242\n",
      "Epoch 850/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6991 - acc: 0.7158 - val_loss: 0.7042 - val_acc: 0.7242\n",
      "Epoch 851/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6991 - acc: 0.7142 - val_loss: 0.7041 - val_acc: 0.7314\n",
      "Epoch 852/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6990 - acc: 0.7182 - val_loss: 0.7039 - val_acc: 0.7242\n",
      "Epoch 853/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6990 - acc: 0.7150 - val_loss: 0.7039 - val_acc: 0.7242\n",
      "Epoch 854/2000\n",
      "1249/1249 [==============================] - 0s 199us/step - loss: 0.6989 - acc: 0.7150 - val_loss: 0.7039 - val_acc: 0.7314\n",
      "Epoch 855/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6989 - acc: 0.7166 - val_loss: 0.7038 - val_acc: 0.7242\n",
      "Epoch 856/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6988 - acc: 0.7174 - val_loss: 0.7037 - val_acc: 0.7242\n",
      "Epoch 857/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6988 - acc: 0.7142 - val_loss: 0.7036 - val_acc: 0.7242\n",
      "Epoch 858/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6987 - acc: 0.7182 - val_loss: 0.7036 - val_acc: 0.7242\n",
      "Epoch 859/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6987 - acc: 0.7134 - val_loss: 0.7036 - val_acc: 0.7242\n",
      "Epoch 860/2000\n",
      "1249/1249 [==============================] - 0s 194us/step - loss: 0.6987 - acc: 0.7126 - val_loss: 0.7036 - val_acc: 0.7242\n",
      "Epoch 861/2000\n",
      "1249/1249 [==============================] - 0s 200us/step - loss: 0.6986 - acc: 0.7150 - val_loss: 0.7035 - val_acc: 0.7242\n",
      "Epoch 862/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6986 - acc: 0.7150 - val_loss: 0.7035 - val_acc: 0.7242\n",
      "Epoch 863/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6985 - acc: 0.7190 - val_loss: 0.7035 - val_acc: 0.7242\n",
      "Epoch 864/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6985 - acc: 0.7134 - val_loss: 0.7036 - val_acc: 0.7242\n",
      "Epoch 865/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6984 - acc: 0.7142 - val_loss: 0.7037 - val_acc: 0.7386\n",
      "Epoch 866/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6984 - acc: 0.7158 - val_loss: 0.7036 - val_acc: 0.7386\n",
      "Epoch 867/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6983 - acc: 0.7142 - val_loss: 0.7035 - val_acc: 0.7386\n",
      "Epoch 868/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6983 - acc: 0.7126 - val_loss: 0.7034 - val_acc: 0.7386\n",
      "Epoch 869/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6983 - acc: 0.7182 - val_loss: 0.7034 - val_acc: 0.7386\n",
      "Epoch 870/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6982 - acc: 0.7190 - val_loss: 0.7035 - val_acc: 0.7242\n",
      "Epoch 871/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6982 - acc: 0.7190 - val_loss: 0.7036 - val_acc: 0.7242\n",
      "Epoch 872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6982 - acc: 0.7118 - val_loss: 0.7036 - val_acc: 0.7362\n",
      "Epoch 873/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6981 - acc: 0.7158 - val_loss: 0.7036 - val_acc: 0.7386\n",
      "Epoch 874/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6981 - acc: 0.7174 - val_loss: 0.7037 - val_acc: 0.7386\n",
      "Epoch 875/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6980 - acc: 0.7190 - val_loss: 0.7034 - val_acc: 0.7386\n",
      "Epoch 876/2000\n",
      "1249/1249 [==============================] - 0s 208us/step - loss: 0.6979 - acc: 0.7190 - val_loss: 0.7033 - val_acc: 0.7242\n",
      "Epoch 877/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6980 - acc: 0.7166 - val_loss: 0.7033 - val_acc: 0.7314\n",
      "Epoch 878/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6979 - acc: 0.7174 - val_loss: 0.7033 - val_acc: 0.7242\n",
      "Epoch 879/2000\n",
      "1249/1249 [==============================] - 0s 150us/step - loss: 0.6978 - acc: 0.7134 - val_loss: 0.7033 - val_acc: 0.7314\n",
      "Epoch 880/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6978 - acc: 0.7134 - val_loss: 0.7033 - val_acc: 0.7386\n",
      "Epoch 881/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6978 - acc: 0.7182 - val_loss: 0.7033 - val_acc: 0.7386\n",
      "Epoch 882/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6978 - acc: 0.7190 - val_loss: 0.7034 - val_acc: 0.7386\n",
      "Epoch 883/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6977 - acc: 0.7182 - val_loss: 0.7035 - val_acc: 0.7362\n",
      "Epoch 884/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6976 - acc: 0.7190 - val_loss: 0.7035 - val_acc: 0.7386\n",
      "Epoch 885/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6976 - acc: 0.7190 - val_loss: 0.7034 - val_acc: 0.7386\n",
      "Epoch 886/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6976 - acc: 0.7166 - val_loss: 0.7035 - val_acc: 0.7386\n",
      "Epoch 887/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6975 - acc: 0.7182 - val_loss: 0.7034 - val_acc: 0.7386\n",
      "Epoch 888/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6976 - acc: 0.7182 - val_loss: 0.7035 - val_acc: 0.7458\n",
      "Epoch 889/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6973 - acc: 0.7174 - val_loss: 0.7034 - val_acc: 0.7386\n",
      "Epoch 890/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6972 - acc: 0.7190 - val_loss: 0.7034 - val_acc: 0.7458\n",
      "Epoch 891/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6973 - acc: 0.7158 - val_loss: 0.7033 - val_acc: 0.7482\n",
      "Epoch 892/2000\n",
      "1249/1249 [==============================] - 0s 194us/step - loss: 0.6973 - acc: 0.7206 - val_loss: 0.7031 - val_acc: 0.7386\n",
      "Epoch 893/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6972 - acc: 0.7206 - val_loss: 0.7030 - val_acc: 0.7386\n",
      "Epoch 894/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6972 - acc: 0.7206 - val_loss: 0.7029 - val_acc: 0.7386\n",
      "Epoch 895/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6973 - acc: 0.7190 - val_loss: 0.7030 - val_acc: 0.7410\n",
      "Epoch 896/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6972 - acc: 0.7190 - val_loss: 0.7031 - val_acc: 0.7482\n",
      "Epoch 897/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6971 - acc: 0.7214 - val_loss: 0.7030 - val_acc: 0.7482\n",
      "Epoch 898/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6970 - acc: 0.7174 - val_loss: 0.7031 - val_acc: 0.7482\n",
      "Epoch 899/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6970 - acc: 0.7206 - val_loss: 0.7031 - val_acc: 0.7482\n",
      "Epoch 900/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6971 - acc: 0.7206 - val_loss: 0.7031 - val_acc: 0.7482\n",
      "Epoch 901/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6968 - acc: 0.7214 - val_loss: 0.7031 - val_acc: 0.7482\n",
      "Epoch 902/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6969 - acc: 0.7206 - val_loss: 0.7029 - val_acc: 0.7482\n",
      "Epoch 903/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6969 - acc: 0.7206 - val_loss: 0.7029 - val_acc: 0.7482\n",
      "Epoch 904/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.6968 - acc: 0.7214 - val_loss: 0.7027 - val_acc: 0.7482\n",
      "Epoch 905/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6968 - acc: 0.7190 - val_loss: 0.7026 - val_acc: 0.7482\n",
      "Epoch 906/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6968 - acc: 0.7182 - val_loss: 0.7025 - val_acc: 0.7482\n",
      "Epoch 907/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6967 - acc: 0.7206 - val_loss: 0.7025 - val_acc: 0.7482\n",
      "Epoch 908/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6967 - acc: 0.7214 - val_loss: 0.7025 - val_acc: 0.7482\n",
      "Epoch 909/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6966 - acc: 0.7206 - val_loss: 0.7025 - val_acc: 0.7482\n",
      "Epoch 910/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6965 - acc: 0.7198 - val_loss: 0.7025 - val_acc: 0.7482\n",
      "Epoch 911/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6966 - acc: 0.7206 - val_loss: 0.7024 - val_acc: 0.7482\n",
      "Epoch 912/2000\n",
      "1249/1249 [==============================] - 0s 151us/step - loss: 0.6965 - acc: 0.7222 - val_loss: 0.7024 - val_acc: 0.7482\n",
      "Epoch 913/2000\n",
      "1249/1249 [==============================] - 0s 144us/step - loss: 0.6965 - acc: 0.7206 - val_loss: 0.7025 - val_acc: 0.7482\n",
      "Epoch 914/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6964 - acc: 0.7222 - val_loss: 0.7025 - val_acc: 0.7482\n",
      "Epoch 915/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6963 - acc: 0.7214 - val_loss: 0.7024 - val_acc: 0.7482\n",
      "Epoch 916/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6963 - acc: 0.7214 - val_loss: 0.7024 - val_acc: 0.7482\n",
      "Epoch 917/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6963 - acc: 0.7214 - val_loss: 0.7023 - val_acc: 0.7482\n",
      "Epoch 918/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.6963 - acc: 0.7206 - val_loss: 0.7023 - val_acc: 0.7482\n",
      "Epoch 919/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6962 - acc: 0.7222 - val_loss: 0.7022 - val_acc: 0.7482\n",
      "Epoch 920/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.6961 - acc: 0.7190 - val_loss: 0.7023 - val_acc: 0.7482\n",
      "Epoch 921/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6961 - acc: 0.7206 - val_loss: 0.7022 - val_acc: 0.7482\n",
      "Epoch 922/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6962 - acc: 0.7222 - val_loss: 0.7022 - val_acc: 0.7482\n",
      "Epoch 923/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6960 - acc: 0.7222 - val_loss: 0.7021 - val_acc: 0.7482\n",
      "Epoch 924/2000\n",
      "1249/1249 [==============================] - 0s 142us/step - loss: 0.6960 - acc: 0.7214 - val_loss: 0.7021 - val_acc: 0.7482\n",
      "Epoch 925/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6959 - acc: 0.7206 - val_loss: 0.7021 - val_acc: 0.7482\n",
      "Epoch 926/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6958 - acc: 0.7214 - val_loss: 0.7020 - val_acc: 0.7482\n",
      "Epoch 927/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6959 - acc: 0.7198 - val_loss: 0.7019 - val_acc: 0.7482\n",
      "Epoch 928/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6958 - acc: 0.7206 - val_loss: 0.7020 - val_acc: 0.7482\n",
      "Epoch 929/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6957 - acc: 0.7206 - val_loss: 0.7019 - val_acc: 0.7482\n",
      "Epoch 930/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6957 - acc: 0.7214 - val_loss: 0.7019 - val_acc: 0.7482\n",
      "Epoch 931/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6958 - acc: 0.7222 - val_loss: 0.7019 - val_acc: 0.7482\n",
      "Epoch 932/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6958 - acc: 0.7214 - val_loss: 0.7019 - val_acc: 0.7482\n",
      "Epoch 933/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6956 - acc: 0.7222 - val_loss: 0.7019 - val_acc: 0.7482\n",
      "Epoch 934/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6955 - acc: 0.7214 - val_loss: 0.7021 - val_acc: 0.7482\n",
      "Epoch 935/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6956 - acc: 0.7214 - val_loss: 0.7020 - val_acc: 0.7482\n",
      "Epoch 936/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6955 - acc: 0.7214 - val_loss: 0.7018 - val_acc: 0.7482\n",
      "Epoch 937/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6955 - acc: 0.7222 - val_loss: 0.7019 - val_acc: 0.7482\n",
      "Epoch 938/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6955 - acc: 0.7214 - val_loss: 0.7018 - val_acc: 0.7482\n",
      "Epoch 939/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6954 - acc: 0.7222 - val_loss: 0.7018 - val_acc: 0.7482\n",
      "Epoch 940/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6954 - acc: 0.7214 - val_loss: 0.7016 - val_acc: 0.7482\n",
      "Epoch 941/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6954 - acc: 0.7222 - val_loss: 0.7016 - val_acc: 0.7482\n",
      "Epoch 942/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6952 - acc: 0.7222 - val_loss: 0.7016 - val_acc: 0.7482\n",
      "Epoch 943/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6952 - acc: 0.7214 - val_loss: 0.7016 - val_acc: 0.7482\n",
      "Epoch 944/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6952 - acc: 0.7206 - val_loss: 0.7015 - val_acc: 0.7482\n",
      "Epoch 945/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6952 - acc: 0.7214 - val_loss: 0.7016 - val_acc: 0.7482\n",
      "Epoch 946/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6951 - acc: 0.7222 - val_loss: 0.7016 - val_acc: 0.7482\n",
      "Epoch 947/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6951 - acc: 0.7222 - val_loss: 0.7016 - val_acc: 0.7482\n",
      "Epoch 948/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6951 - acc: 0.7206 - val_loss: 0.7015 - val_acc: 0.7482\n",
      "Epoch 949/2000\n",
      "1249/1249 [==============================] - 0s 194us/step - loss: 0.6951 - acc: 0.7222 - val_loss: 0.7014 - val_acc: 0.7482\n",
      "Epoch 950/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6950 - acc: 0.7222 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 951/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6950 - acc: 0.7222 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 952/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6948 - acc: 0.7214 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 953/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6949 - acc: 0.7222 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 954/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6948 - acc: 0.7222 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 955/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6947 - acc: 0.7222 - val_loss: 0.7010 - val_acc: 0.7482\n",
      "Epoch 956/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6949 - acc: 0.7222 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 957/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6947 - acc: 0.7222 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 958/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6948 - acc: 0.7222 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 959/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6946 - acc: 0.7222 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 960/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6946 - acc: 0.7222 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 961/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6945 - acc: 0.7222 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 962/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6946 - acc: 0.7214 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 963/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6945 - acc: 0.7214 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 964/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6944 - acc: 0.7222 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 965/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6945 - acc: 0.7214 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 966/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6944 - acc: 0.7222 - val_loss: 0.7010 - val_acc: 0.7482\n",
      "Epoch 967/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6944 - acc: 0.7222 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 968/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6943 - acc: 0.7222 - val_loss: 0.7010 - val_acc: 0.7482\n",
      "Epoch 969/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6942 - acc: 0.7214 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 970/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6944 - acc: 0.7222 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 971/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6942 - acc: 0.7214 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 972/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6942 - acc: 0.7222 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 973/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6941 - acc: 0.7222 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 974/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6941 - acc: 0.7214 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 975/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6940 - acc: 0.7222 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 976/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6940 - acc: 0.7222 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 977/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6940 - acc: 0.7222 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 978/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6940 - acc: 0.7222 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 979/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6940 - acc: 0.7222 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 980/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6939 - acc: 0.7214 - val_loss: 0.7013 - val_acc: 0.7482\n",
      "Epoch 981/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6939 - acc: 0.7222 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 982/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6938 - acc: 0.7214 - val_loss: 0.7012 - val_acc: 0.7482\n",
      "Epoch 983/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6939 - acc: 0.7222 - val_loss: 0.7011 - val_acc: 0.7482\n",
      "Epoch 984/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6938 - acc: 0.7222 - val_loss: 0.7010 - val_acc: 0.7482\n",
      "Epoch 985/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6936 - acc: 0.7214 - val_loss: 0.7009 - val_acc: 0.7482\n",
      "Epoch 986/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6937 - acc: 0.7222 - val_loss: 0.7009 - val_acc: 0.7482\n",
      "Epoch 987/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6937 - acc: 0.7222 - val_loss: 0.7009 - val_acc: 0.7482\n",
      "Epoch 988/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6937 - acc: 0.7214 - val_loss: 0.7009 - val_acc: 0.7482\n",
      "Epoch 989/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6936 - acc: 0.7222 - val_loss: 0.7007 - val_acc: 0.7482\n",
      "Epoch 990/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6935 - acc: 0.7222 - val_loss: 0.7008 - val_acc: 0.7482\n",
      "Epoch 991/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6935 - acc: 0.7222 - val_loss: 0.7008 - val_acc: 0.7482\n",
      "Epoch 992/2000\n",
      "1249/1249 [==============================] - 0s 194us/step - loss: 0.6935 - acc: 0.7222 - val_loss: 0.7008 - val_acc: 0.7482\n",
      "Epoch 993/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6934 - acc: 0.7222 - val_loss: 0.7005 - val_acc: 0.7482\n",
      "Epoch 994/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6934 - acc: 0.7222 - val_loss: 0.7004 - val_acc: 0.7482\n",
      "Epoch 995/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6934 - acc: 0.7214 - val_loss: 0.7002 - val_acc: 0.7482\n",
      "Epoch 996/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6934 - acc: 0.7222 - val_loss: 0.7003 - val_acc: 0.7482\n",
      "Epoch 997/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6933 - acc: 0.7222 - val_loss: 0.7004 - val_acc: 0.7482\n",
      "Epoch 998/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.7222 - val_loss: 0.7005 - val_acc: 0.7482\n",
      "Epoch 999/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6931 - acc: 0.7222 - val_loss: 0.7005 - val_acc: 0.7482\n",
      "Epoch 1000/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6932 - acc: 0.7222 - val_loss: 0.7005 - val_acc: 0.7482\n",
      "Epoch 1001/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6931 - acc: 0.7222 - val_loss: 0.7005 - val_acc: 0.7482\n",
      "Epoch 1002/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6930 - acc: 0.7222 - val_loss: 0.7004 - val_acc: 0.7482\n",
      "Epoch 1003/2000\n",
      "1249/1249 [==============================] - 0s 150us/step - loss: 0.6931 - acc: 0.7222 - val_loss: 0.7004 - val_acc: 0.7482\n",
      "Epoch 1004/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6929 - acc: 0.7222 - val_loss: 0.7002 - val_acc: 0.7482\n",
      "Epoch 1005/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.6928 - acc: 0.7222 - val_loss: 0.7002 - val_acc: 0.7482\n",
      "Epoch 1006/2000\n",
      "1249/1249 [==============================] - 0s 150us/step - loss: 0.6928 - acc: 0.7222 - val_loss: 0.7002 - val_acc: 0.7482\n",
      "Epoch 1007/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6929 - acc: 0.7222 - val_loss: 0.7002 - val_acc: 0.7482\n",
      "Epoch 1008/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6928 - acc: 0.7222 - val_loss: 0.7001 - val_acc: 0.7482\n",
      "Epoch 1009/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6928 - acc: 0.7222 - val_loss: 0.7001 - val_acc: 0.7482\n",
      "Epoch 1010/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6928 - acc: 0.7222 - val_loss: 0.6999 - val_acc: 0.7482\n",
      "Epoch 1011/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6926 - acc: 0.7222 - val_loss: 0.7000 - val_acc: 0.7482\n",
      "Epoch 1012/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6927 - acc: 0.7222 - val_loss: 0.7000 - val_acc: 0.7482\n",
      "Epoch 1013/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6925 - acc: 0.7214 - val_loss: 0.7000 - val_acc: 0.7482\n",
      "Epoch 1014/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6924 - acc: 0.7214 - val_loss: 0.7000 - val_acc: 0.7482\n",
      "Epoch 1015/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6925 - acc: 0.7214 - val_loss: 0.6998 - val_acc: 0.7482\n",
      "Epoch 1016/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6923 - acc: 0.7222 - val_loss: 0.7000 - val_acc: 0.7482\n",
      "Epoch 1017/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6925 - acc: 0.7222 - val_loss: 0.7000 - val_acc: 0.7482\n",
      "Epoch 1018/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6923 - acc: 0.7214 - val_loss: 0.7001 - val_acc: 0.7482\n",
      "Epoch 1019/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6923 - acc: 0.7222 - val_loss: 0.7000 - val_acc: 0.7482\n",
      "Epoch 1020/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6923 - acc: 0.7222 - val_loss: 0.6999 - val_acc: 0.7482\n",
      "Epoch 1021/2000\n",
      "1249/1249 [==============================] - 0s 203us/step - loss: 0.6922 - acc: 0.7222 - val_loss: 0.6999 - val_acc: 0.7482\n",
      "Epoch 1022/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6920 - acc: 0.7222 - val_loss: 0.6999 - val_acc: 0.7482\n",
      "Epoch 1023/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6921 - acc: 0.7214 - val_loss: 0.6999 - val_acc: 0.7482\n",
      "Epoch 1024/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6920 - acc: 0.7222 - val_loss: 0.6997 - val_acc: 0.7482\n",
      "Epoch 1025/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6920 - acc: 0.7222 - val_loss: 0.6997 - val_acc: 0.7482\n",
      "Epoch 1026/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6919 - acc: 0.7222 - val_loss: 0.6997 - val_acc: 0.7482\n",
      "Epoch 1027/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6919 - acc: 0.7222 - val_loss: 0.6998 - val_acc: 0.7482\n",
      "Epoch 1028/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6918 - acc: 0.7214 - val_loss: 0.6998 - val_acc: 0.7482\n",
      "Epoch 1029/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6919 - acc: 0.7222 - val_loss: 0.6995 - val_acc: 0.7482\n",
      "Epoch 1030/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6918 - acc: 0.7214 - val_loss: 0.6994 - val_acc: 0.7482\n",
      "Epoch 1031/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6917 - acc: 0.7214 - val_loss: 0.6993 - val_acc: 0.7482\n",
      "Epoch 1032/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6918 - acc: 0.7222 - val_loss: 0.6993 - val_acc: 0.7482\n",
      "Epoch 1033/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6916 - acc: 0.7222 - val_loss: 0.6994 - val_acc: 0.7482\n",
      "Epoch 1034/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6916 - acc: 0.7222 - val_loss: 0.6994 - val_acc: 0.7482\n",
      "Epoch 1035/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6915 - acc: 0.7222 - val_loss: 0.6993 - val_acc: 0.7482\n",
      "Epoch 1036/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6916 - acc: 0.7214 - val_loss: 0.6993 - val_acc: 0.7482\n",
      "Epoch 1037/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6915 - acc: 0.7222 - val_loss: 0.6994 - val_acc: 0.7482\n",
      "Epoch 1038/2000\n",
      "1249/1249 [==============================] - 0s 204us/step - loss: 0.6914 - acc: 0.7214 - val_loss: 0.6992 - val_acc: 0.7482\n",
      "Epoch 1039/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6915 - acc: 0.7214 - val_loss: 0.6992 - val_acc: 0.7482\n",
      "Epoch 1040/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.6914 - acc: 0.7222 - val_loss: 0.6991 - val_acc: 0.7482\n",
      "Epoch 1041/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6913 - acc: 0.7222 - val_loss: 0.6992 - val_acc: 0.7482\n",
      "Epoch 1042/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6912 - acc: 0.7222 - val_loss: 0.6992 - val_acc: 0.7482\n",
      "Epoch 1043/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6912 - acc: 0.7222 - val_loss: 0.6992 - val_acc: 0.7482\n",
      "Epoch 1044/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6913 - acc: 0.7222 - val_loss: 0.6991 - val_acc: 0.7482\n",
      "Epoch 1045/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6911 - acc: 0.7214 - val_loss: 0.6991 - val_acc: 0.7482\n",
      "Epoch 1046/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6911 - acc: 0.7222 - val_loss: 0.6990 - val_acc: 0.7482\n",
      "Epoch 1047/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6911 - acc: 0.7214 - val_loss: 0.6989 - val_acc: 0.7482\n",
      "Epoch 1048/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6910 - acc: 0.7230 - val_loss: 0.6988 - val_acc: 0.7482\n",
      "Epoch 1049/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6910 - acc: 0.7214 - val_loss: 0.6988 - val_acc: 0.7482\n",
      "Epoch 1050/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6909 - acc: 0.7214 - val_loss: 0.6988 - val_acc: 0.7482\n",
      "Epoch 1051/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6909 - acc: 0.7214 - val_loss: 0.6987 - val_acc: 0.7482\n",
      "Epoch 1052/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6909 - acc: 0.7214 - val_loss: 0.6988 - val_acc: 0.7482\n",
      "Epoch 1053/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6909 - acc: 0.7238 - val_loss: 0.6986 - val_acc: 0.7482\n",
      "Epoch 1054/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6909 - acc: 0.7214 - val_loss: 0.6987 - val_acc: 0.7482\n",
      "Epoch 1055/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6908 - acc: 0.7222 - val_loss: 0.6988 - val_acc: 0.7482\n",
      "Epoch 1056/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6907 - acc: 0.7214 - val_loss: 0.6987 - val_acc: 0.7482\n",
      "Epoch 1057/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6906 - acc: 0.7222 - val_loss: 0.6987 - val_acc: 0.7482\n",
      "Epoch 1058/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6906 - acc: 0.7246 - val_loss: 0.6987 - val_acc: 0.7482\n",
      "Epoch 1059/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6906 - acc: 0.7222 - val_loss: 0.6986 - val_acc: 0.7482\n",
      "Epoch 1060/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6906 - acc: 0.7214 - val_loss: 0.6984 - val_acc: 0.7482\n",
      "Epoch 1061/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6905 - acc: 0.7214 - val_loss: 0.6984 - val_acc: 0.7482\n",
      "Epoch 1062/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6904 - acc: 0.7206 - val_loss: 0.6984 - val_acc: 0.7482\n",
      "Epoch 1063/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6905 - acc: 0.7230 - val_loss: 0.6982 - val_acc: 0.7482\n",
      "Epoch 1064/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6904 - acc: 0.7230 - val_loss: 0.6981 - val_acc: 0.7482\n",
      "Epoch 1065/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6903 - acc: 0.7270 - val_loss: 0.6980 - val_acc: 0.7482\n",
      "Epoch 1066/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6903 - acc: 0.7222 - val_loss: 0.6979 - val_acc: 0.7482\n",
      "Epoch 1067/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.6901 - acc: 0.7262 - val_loss: 0.6979 - val_acc: 0.7482\n",
      "Epoch 1068/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6902 - acc: 0.7222 - val_loss: 0.6978 - val_acc: 0.7482\n",
      "Epoch 1069/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6902 - acc: 0.7238 - val_loss: 0.6979 - val_acc: 0.7482\n",
      "Epoch 1070/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6901 - acc: 0.7254 - val_loss: 0.6981 - val_acc: 0.7482\n",
      "Epoch 1071/2000\n",
      "1249/1249 [==============================] - 0s 205us/step - loss: 0.6899 - acc: 0.7222 - val_loss: 0.6978 - val_acc: 0.7482\n",
      "Epoch 1072/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6900 - acc: 0.7214 - val_loss: 0.6980 - val_acc: 0.7482\n",
      "Epoch 1073/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6900 - acc: 0.7206 - val_loss: 0.6981 - val_acc: 0.7482\n",
      "Epoch 1074/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6899 - acc: 0.7230 - val_loss: 0.6980 - val_acc: 0.7482\n",
      "Epoch 1075/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6899 - acc: 0.7238 - val_loss: 0.6979 - val_acc: 0.7482\n",
      "Epoch 1076/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6899 - acc: 0.7214 - val_loss: 0.6979 - val_acc: 0.7482\n",
      "Epoch 1077/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6898 - acc: 0.7270 - val_loss: 0.6979 - val_acc: 0.7482\n",
      "Epoch 1078/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6897 - acc: 0.7214 - val_loss: 0.6978 - val_acc: 0.7482\n",
      "Epoch 1079/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6897 - acc: 0.7262 - val_loss: 0.6978 - val_acc: 0.7482\n",
      "Epoch 1080/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6897 - acc: 0.7238 - val_loss: 0.6978 - val_acc: 0.7482\n",
      "Epoch 1081/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6896 - acc: 0.7230 - val_loss: 0.6979 - val_acc: 0.7482\n",
      "Epoch 1082/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6896 - acc: 0.7278 - val_loss: 0.6978 - val_acc: 0.7482\n",
      "Epoch 1083/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6897 - acc: 0.7230 - val_loss: 0.6977 - val_acc: 0.7482\n",
      "Epoch 1084/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6895 - acc: 0.7230 - val_loss: 0.6977 - val_acc: 0.7482\n",
      "Epoch 1085/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6895 - acc: 0.7230 - val_loss: 0.6976 - val_acc: 0.7482\n",
      "Epoch 1086/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6895 - acc: 0.7270 - val_loss: 0.6976 - val_acc: 0.7482\n",
      "Epoch 1087/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6894 - acc: 0.7222 - val_loss: 0.6977 - val_acc: 0.7482\n",
      "Epoch 1088/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6895 - acc: 0.7254 - val_loss: 0.6976 - val_acc: 0.7482\n",
      "Epoch 1089/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6894 - acc: 0.7294 - val_loss: 0.6975 - val_acc: 0.7482\n",
      "Epoch 1090/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6893 - acc: 0.7238 - val_loss: 0.6976 - val_acc: 0.7482\n",
      "Epoch 1091/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6894 - acc: 0.7270 - val_loss: 0.6975 - val_acc: 0.7482\n",
      "Epoch 1092/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6892 - acc: 0.7278 - val_loss: 0.6974 - val_acc: 0.7482\n",
      "Epoch 1093/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6891 - acc: 0.7286 - val_loss: 0.6975 - val_acc: 0.7482\n",
      "Epoch 1094/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6891 - acc: 0.7214 - val_loss: 0.6975 - val_acc: 0.7482\n",
      "Epoch 1095/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6892 - acc: 0.7310 - val_loss: 0.6973 - val_acc: 0.7482\n",
      "Epoch 1096/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6891 - acc: 0.7230 - val_loss: 0.6974 - val_acc: 0.7482\n",
      "Epoch 1097/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6891 - acc: 0.7254 - val_loss: 0.6974 - val_acc: 0.7482\n",
      "Epoch 1098/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6891 - acc: 0.7310 - val_loss: 0.6973 - val_acc: 0.7482\n",
      "Epoch 1099/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6890 - acc: 0.7302 - val_loss: 0.6972 - val_acc: 0.7482\n",
      "Epoch 1100/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6890 - acc: 0.7302 - val_loss: 0.6972 - val_acc: 0.7482\n",
      "Epoch 1101/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6888 - acc: 0.7270 - val_loss: 0.6972 - val_acc: 0.7482\n",
      "Epoch 1102/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6889 - acc: 0.7302 - val_loss: 0.6972 - val_acc: 0.7482\n",
      "Epoch 1103/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6888 - acc: 0.7302 - val_loss: 0.6973 - val_acc: 0.7482\n",
      "Epoch 1104/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6888 - acc: 0.7310 - val_loss: 0.6973 - val_acc: 0.7482\n",
      "Epoch 1105/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6887 - acc: 0.7294 - val_loss: 0.6972 - val_acc: 0.7482\n",
      "Epoch 1106/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6887 - acc: 0.7294 - val_loss: 0.6972 - val_acc: 0.7482\n",
      "Epoch 1107/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6887 - acc: 0.7302 - val_loss: 0.6971 - val_acc: 0.7482\n",
      "Epoch 1108/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6886 - acc: 0.7310 - val_loss: 0.6973 - val_acc: 0.7482\n",
      "Epoch 1109/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6886 - acc: 0.7278 - val_loss: 0.6973 - val_acc: 0.7482\n",
      "Epoch 1110/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6885 - acc: 0.7318 - val_loss: 0.6972 - val_acc: 0.7482\n",
      "Epoch 1111/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6884 - acc: 0.7278 - val_loss: 0.6972 - val_acc: 0.7482\n",
      "Epoch 1112/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6886 - acc: 0.7302 - val_loss: 0.6973 - val_acc: 0.7482\n",
      "Epoch 1113/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6884 - acc: 0.7294 - val_loss: 0.6971 - val_acc: 0.7482\n",
      "Epoch 1114/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6883 - acc: 0.7318 - val_loss: 0.6969 - val_acc: 0.7482\n",
      "Epoch 1115/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6883 - acc: 0.7270 - val_loss: 0.6971 - val_acc: 0.7482\n",
      "Epoch 1116/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6883 - acc: 0.7318 - val_loss: 0.6970 - val_acc: 0.7482\n",
      "Epoch 1117/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6883 - acc: 0.7278 - val_loss: 0.6969 - val_acc: 0.7482\n",
      "Epoch 1118/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6883 - acc: 0.7286 - val_loss: 0.6968 - val_acc: 0.7482\n",
      "Epoch 1119/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6883 - acc: 0.7318 - val_loss: 0.6969 - val_acc: 0.7482\n",
      "Epoch 1120/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6883 - acc: 0.7310 - val_loss: 0.6969 - val_acc: 0.7482\n",
      "Epoch 1121/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6883 - acc: 0.7310 - val_loss: 0.6966 - val_acc: 0.7482\n",
      "Epoch 1122/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6882 - acc: 0.7302 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1123/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6882 - acc: 0.7294 - val_loss: 0.6967 - val_acc: 0.7482\n",
      "Epoch 1124/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6881 - acc: 0.7278 - val_loss: 0.6968 - val_acc: 0.7482\n",
      "Epoch 1125/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6881 - acc: 0.7294 - val_loss: 0.6968 - val_acc: 0.7482\n",
      "Epoch 1126/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.6880 - acc: 0.7310 - val_loss: 0.6968 - val_acc: 0.7482\n",
      "Epoch 1127/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6880 - acc: 0.7318 - val_loss: 0.6966 - val_acc: 0.7482\n",
      "Epoch 1128/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6879 - acc: 0.7302 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1129/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6880 - acc: 0.7278 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1130/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6879 - acc: 0.7270 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1131/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6879 - acc: 0.7294 - val_loss: 0.6964 - val_acc: 0.7482\n",
      "Epoch 1132/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6879 - acc: 0.7302 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1133/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6877 - acc: 0.7310 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1134/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6877 - acc: 0.7278 - val_loss: 0.6967 - val_acc: 0.7482\n",
      "Epoch 1135/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6877 - acc: 0.7302 - val_loss: 0.6964 - val_acc: 0.7482\n",
      "Epoch 1136/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6876 - acc: 0.7302 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1137/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6876 - acc: 0.7318 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1138/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6876 - acc: 0.7318 - val_loss: 0.6963 - val_acc: 0.7482\n",
      "Epoch 1139/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6875 - acc: 0.7318 - val_loss: 0.6963 - val_acc: 0.7482\n",
      "Epoch 1140/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6875 - acc: 0.7278 - val_loss: 0.6966 - val_acc: 0.7482\n",
      "Epoch 1141/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6875 - acc: 0.7302 - val_loss: 0.6966 - val_acc: 0.7482\n",
      "Epoch 1142/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6875 - acc: 0.7294 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1143/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6874 - acc: 0.7318 - val_loss: 0.6964 - val_acc: 0.7482\n",
      "Epoch 1144/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6874 - acc: 0.7302 - val_loss: 0.6964 - val_acc: 0.7482\n",
      "Epoch 1145/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6873 - acc: 0.7286 - val_loss: 0.6964 - val_acc: 0.7482\n",
      "Epoch 1146/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6874 - acc: 0.7310 - val_loss: 0.6964 - val_acc: 0.7482\n",
      "Epoch 1147/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6872 - acc: 0.7310 - val_loss: 0.6963 - val_acc: 0.7482\n",
      "Epoch 1148/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6872 - acc: 0.7310 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1149/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6873 - acc: 0.7310 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1150/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6872 - acc: 0.7310 - val_loss: 0.6964 - val_acc: 0.7482\n",
      "Epoch 1151/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6871 - acc: 0.7310 - val_loss: 0.6965 - val_acc: 0.7482\n",
      "Epoch 1152/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6871 - acc: 0.7310 - val_loss: 0.6963 - val_acc: 0.7482\n",
      "Epoch 1153/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6870 - acc: 0.7294 - val_loss: 0.6964 - val_acc: 0.7482\n",
      "Epoch 1154/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6869 - acc: 0.7310 - val_loss: 0.6963 - val_acc: 0.7482\n",
      "Epoch 1155/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6870 - acc: 0.7286 - val_loss: 0.6961 - val_acc: 0.7482\n",
      "Epoch 1156/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6869 - acc: 0.7318 - val_loss: 0.6962 - val_acc: 0.7482\n",
      "Epoch 1157/2000\n",
      "1249/1249 [==============================] - 0s 194us/step - loss: 0.6868 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1158/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6868 - acc: 0.7302 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1159/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6866 - acc: 0.7294 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1160/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6867 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1161/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.6867 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 195us/step - loss: 0.6866 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1163/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6866 - acc: 0.7302 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1164/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6866 - acc: 0.7270 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1165/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6865 - acc: 0.7310 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1166/2000\n",
      "1249/1249 [==============================] - 0s 200us/step - loss: 0.6866 - acc: 0.7294 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1167/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6866 - acc: 0.7302 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1168/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6865 - acc: 0.7310 - val_loss: 0.6960 - val_acc: 0.7482\n",
      "Epoch 1169/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6864 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1170/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6863 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1171/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6863 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1172/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6862 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1173/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.6861 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1174/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6861 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1175/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6862 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1176/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6861 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1177/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6861 - acc: 0.7310 - val_loss: 0.6960 - val_acc: 0.7482\n",
      "Epoch 1178/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6859 - acc: 0.7310 - val_loss: 0.6960 - val_acc: 0.7482\n",
      "Epoch 1179/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6860 - acc: 0.7310 - val_loss: 0.6960 - val_acc: 0.7482\n",
      "Epoch 1180/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6860 - acc: 0.7310 - val_loss: 0.6960 - val_acc: 0.7482\n",
      "Epoch 1181/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.6858 - acc: 0.7302 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1182/2000\n",
      "1249/1249 [==============================] - 0s 220us/step - loss: 0.6858 - acc: 0.7318 - val_loss: 0.6961 - val_acc: 0.7482\n",
      "Epoch 1183/2000\n",
      "1249/1249 [==============================] - 0s 198us/step - loss: 0.6858 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1184/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6858 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1185/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6857 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1186/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6858 - acc: 0.7302 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1187/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6856 - acc: 0.7310 - val_loss: 0.6959 - val_acc: 0.7482\n",
      "Epoch 1188/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6856 - acc: 0.7294 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1189/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6856 - acc: 0.7310 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1190/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6855 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1191/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6854 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1192/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6853 - acc: 0.7302 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1193/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6855 - acc: 0.7310 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1194/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6853 - acc: 0.7310 - val_loss: 0.6955 - val_acc: 0.7482\n",
      "Epoch 1195/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6853 - acc: 0.7310 - val_loss: 0.6955 - val_acc: 0.7482\n",
      "Epoch 1196/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6852 - acc: 0.7318 - val_loss: 0.6956 - val_acc: 0.7482\n",
      "Epoch 1197/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6853 - acc: 0.7310 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1198/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6852 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1199/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6852 - acc: 0.7318 - val_loss: 0.6956 - val_acc: 0.7482\n",
      "Epoch 1200/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6851 - acc: 0.7286 - val_loss: 0.6956 - val_acc: 0.7482\n",
      "Epoch 1201/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6851 - acc: 0.7310 - val_loss: 0.6956 - val_acc: 0.7482\n",
      "Epoch 1202/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6850 - acc: 0.7310 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1203/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6851 - acc: 0.7278 - val_loss: 0.6960 - val_acc: 0.7482\n",
      "Epoch 1204/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6849 - acc: 0.7294 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1205/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6849 - acc: 0.7310 - val_loss: 0.6958 - val_acc: 0.7482\n",
      "Epoch 1206/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6848 - acc: 0.7310 - val_loss: 0.6956 - val_acc: 0.7482\n",
      "Epoch 1207/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.6848 - acc: 0.7326 - val_loss: 0.6956 - val_acc: 0.7482\n",
      "Epoch 1208/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6848 - acc: 0.7310 - val_loss: 0.6955 - val_acc: 0.7482\n",
      "Epoch 1209/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6847 - acc: 0.7278 - val_loss: 0.6957 - val_acc: 0.7482\n",
      "Epoch 1210/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6849 - acc: 0.7294 - val_loss: 0.6954 - val_acc: 0.7482\n",
      "Epoch 1211/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6847 - acc: 0.7310 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1212/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6847 - acc: 0.7310 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1213/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6846 - acc: 0.7310 - val_loss: 0.6952 - val_acc: 0.7482\n",
      "Epoch 1214/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.6846 - acc: 0.7302 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1215/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6847 - acc: 0.7310 - val_loss: 0.6954 - val_acc: 0.7482\n",
      "Epoch 1216/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6845 - acc: 0.7310 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1217/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6845 - acc: 0.7310 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1218/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6844 - acc: 0.7310 - val_loss: 0.6952 - val_acc: 0.7482\n",
      "Epoch 1219/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6845 - acc: 0.7302 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1220/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6845 - acc: 0.7310 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1221/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.6844 - acc: 0.7310 - val_loss: 0.6954 - val_acc: 0.7482\n",
      "Epoch 1222/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6843 - acc: 0.7286 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1223/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6842 - acc: 0.7310 - val_loss: 0.6954 - val_acc: 0.7482\n",
      "Epoch 1224/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6842 - acc: 0.7310 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1225/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6842 - acc: 0.7310 - val_loss: 0.6952 - val_acc: 0.7482\n",
      "Epoch 1226/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6842 - acc: 0.7310 - val_loss: 0.6951 - val_acc: 0.7482\n",
      "Epoch 1227/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6842 - acc: 0.7294 - val_loss: 0.6951 - val_acc: 0.7482\n",
      "Epoch 1228/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6841 - acc: 0.7310 - val_loss: 0.6952 - val_acc: 0.7482\n",
      "Epoch 1229/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6842 - acc: 0.7270 - val_loss: 0.6953 - val_acc: 0.7482\n",
      "Epoch 1230/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6842 - acc: 0.7310 - val_loss: 0.6951 - val_acc: 0.7482\n",
      "Epoch 1231/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6842 - acc: 0.7310 - val_loss: 0.6951 - val_acc: 0.7482\n",
      "Epoch 1232/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6840 - acc: 0.7310 - val_loss: 0.6950 - val_acc: 0.7482\n",
      "Epoch 1233/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6840 - acc: 0.7310 - val_loss: 0.6951 - val_acc: 0.7482\n",
      "Epoch 1234/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6839 - acc: 0.7302 - val_loss: 0.6952 - val_acc: 0.7482\n",
      "Epoch 1235/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6840 - acc: 0.7310 - val_loss: 0.6950 - val_acc: 0.7482\n",
      "Epoch 1236/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6839 - acc: 0.7310 - val_loss: 0.6950 - val_acc: 0.7482\n",
      "Epoch 1237/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6839 - acc: 0.7294 - val_loss: 0.6950 - val_acc: 0.7482\n",
      "Epoch 1238/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6837 - acc: 0.7310 - val_loss: 0.6950 - val_acc: 0.7482\n",
      "Epoch 1239/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6837 - acc: 0.7310 - val_loss: 0.6950 - val_acc: 0.7482\n",
      "Epoch 1240/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6838 - acc: 0.7310 - val_loss: 0.6949 - val_acc: 0.7482\n",
      "Epoch 1241/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6837 - acc: 0.7310 - val_loss: 0.6949 - val_acc: 0.7482\n",
      "Epoch 1242/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6836 - acc: 0.7310 - val_loss: 0.6950 - val_acc: 0.7482\n",
      "Epoch 1243/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6836 - acc: 0.7310 - val_loss: 0.6950 - val_acc: 0.7482\n",
      "Epoch 1244/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6836 - acc: 0.7302 - val_loss: 0.6947 - val_acc: 0.7482\n",
      "Epoch 1245/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6835 - acc: 0.7310 - val_loss: 0.6946 - val_acc: 0.7482\n",
      "Epoch 1246/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6836 - acc: 0.7286 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1247/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6835 - acc: 0.7310 - val_loss: 0.6947 - val_acc: 0.7482\n",
      "Epoch 1248/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6835 - acc: 0.7310 - val_loss: 0.6946 - val_acc: 0.7482\n",
      "Epoch 1249/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6834 - acc: 0.7310 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1250/2000\n",
      "1249/1249 [==============================] - 0s 199us/step - loss: 0.6834 - acc: 0.7294 - val_loss: 0.6947 - val_acc: 0.7482\n",
      "Epoch 1251/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6834 - acc: 0.7310 - val_loss: 0.6947 - val_acc: 0.7482\n",
      "Epoch 1252/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6834 - acc: 0.7302 - val_loss: 0.6947 - val_acc: 0.7482\n",
      "Epoch 1253/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6833 - acc: 0.7310 - val_loss: 0.6947 - val_acc: 0.7482\n",
      "Epoch 1254/2000\n",
      "1249/1249 [==============================] - 0s 193us/step - loss: 0.6833 - acc: 0.7310 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1255/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6832 - acc: 0.7310 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1256/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6832 - acc: 0.7310 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1257/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6831 - acc: 0.7286 - val_loss: 0.6947 - val_acc: 0.7482\n",
      "Epoch 1258/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6831 - acc: 0.7310 - val_loss: 0.6944 - val_acc: 0.7482\n",
      "Epoch 1259/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6830 - acc: 0.7302 - val_loss: 0.6943 - val_acc: 0.7482\n",
      "Epoch 1260/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6830 - acc: 0.7310 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1261/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6832 - acc: 0.7294 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1262/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6830 - acc: 0.7310 - val_loss: 0.6946 - val_acc: 0.7482\n",
      "Epoch 1263/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6830 - acc: 0.7310 - val_loss: 0.6947 - val_acc: 0.7482\n",
      "Epoch 1264/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6829 - acc: 0.7310 - val_loss: 0.6946 - val_acc: 0.7482\n",
      "Epoch 1265/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6832 - acc: 0.7310 - val_loss: 0.6946 - val_acc: 0.7482\n",
      "Epoch 1266/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6830 - acc: 0.7302 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1267/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6829 - acc: 0.7310 - val_loss: 0.6944 - val_acc: 0.7482\n",
      "Epoch 1268/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6829 - acc: 0.7310 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1269/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6827 - acc: 0.7310 - val_loss: 0.6945 - val_acc: 0.7482\n",
      "Epoch 1270/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6827 - acc: 0.7310 - val_loss: 0.6941 - val_acc: 0.7482\n",
      "Epoch 1271/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6826 - acc: 0.7310 - val_loss: 0.6940 - val_acc: 0.7482\n",
      "Epoch 1272/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6826 - acc: 0.7294 - val_loss: 0.6941 - val_acc: 0.7482\n",
      "Epoch 1273/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6826 - acc: 0.7310 - val_loss: 0.6940 - val_acc: 0.7482\n",
      "Epoch 1274/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6826 - acc: 0.7278 - val_loss: 0.6941 - val_acc: 0.7482\n",
      "Epoch 1275/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6826 - acc: 0.7310 - val_loss: 0.6941 - val_acc: 0.7482\n",
      "Epoch 1276/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.6826 - acc: 0.7294 - val_loss: 0.6941 - val_acc: 0.7482\n",
      "Epoch 1277/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6823 - acc: 0.7294 - val_loss: 0.6941 - val_acc: 0.7482\n",
      "Epoch 1278/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6825 - acc: 0.7310 - val_loss: 0.6940 - val_acc: 0.7482\n",
      "Epoch 1279/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6824 - acc: 0.7310 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1280/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6825 - acc: 0.7310 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1281/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6824 - acc: 0.7310 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1282/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6822 - acc: 0.7310 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1283/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6822 - acc: 0.7278 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1284/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6823 - acc: 0.7310 - val_loss: 0.6940 - val_acc: 0.7482\n",
      "Epoch 1285/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6822 - acc: 0.7310 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1286/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6821 - acc: 0.7294 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1287/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6821 - acc: 0.7262 - val_loss: 0.6940 - val_acc: 0.7482\n",
      "Epoch 1288/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6821 - acc: 0.7310 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1289/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6821 - acc: 0.7310 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1290/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6822 - acc: 0.7310 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1291/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6820 - acc: 0.7310 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1292/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6820 - acc: 0.7310 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1293/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6820 - acc: 0.7310 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1294/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6820 - acc: 0.7302 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1295/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.6819 - acc: 0.7294 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1296/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6818 - acc: 0.7310 - val_loss: 0.6936 - val_acc: 0.7482\n",
      "Epoch 1297/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.6818 - acc: 0.7310 - val_loss: 0.6935 - val_acc: 0.7482\n",
      "Epoch 1298/2000\n",
      "1249/1249 [==============================] - 0s 203us/step - loss: 0.6818 - acc: 0.7310 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1299/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6818 - acc: 0.7310 - val_loss: 0.6940 - val_acc: 0.7482\n",
      "Epoch 1300/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6816 - acc: 0.7310 - val_loss: 0.6937 - val_acc: 0.7482\n",
      "Epoch 1301/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6817 - acc: 0.7302 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1302/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6816 - acc: 0.7310 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1303/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6816 - acc: 0.7278 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1304/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6815 - acc: 0.7310 - val_loss: 0.6936 - val_acc: 0.7482\n",
      "Epoch 1305/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6815 - acc: 0.7294 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1306/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6814 - acc: 0.7310 - val_loss: 0.6936 - val_acc: 0.7482\n",
      "Epoch 1307/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6815 - acc: 0.7310 - val_loss: 0.6936 - val_acc: 0.7482\n",
      "Epoch 1308/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6813 - acc: 0.7294 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1309/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6814 - acc: 0.7310 - val_loss: 0.6937 - val_acc: 0.7482\n",
      "Epoch 1310/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6814 - acc: 0.7310 - val_loss: 0.6935 - val_acc: 0.7482\n",
      "Epoch 1311/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6813 - acc: 0.7310 - val_loss: 0.6935 - val_acc: 0.7482\n",
      "Epoch 1312/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6813 - acc: 0.7310 - val_loss: 0.6935 - val_acc: 0.7482\n",
      "Epoch 1313/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6813 - acc: 0.7286 - val_loss: 0.6934 - val_acc: 0.7482\n",
      "Epoch 1314/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6812 - acc: 0.7310 - val_loss: 0.6934 - val_acc: 0.7482\n",
      "Epoch 1315/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.6812 - acc: 0.7310 - val_loss: 0.6933 - val_acc: 0.7482\n",
      "Epoch 1316/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6812 - acc: 0.7278 - val_loss: 0.6933 - val_acc: 0.7482\n",
      "Epoch 1317/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6812 - acc: 0.7302 - val_loss: 0.6934 - val_acc: 0.7482\n",
      "Epoch 1318/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6810 - acc: 0.7310 - val_loss: 0.6933 - val_acc: 0.7482\n",
      "Epoch 1319/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6810 - acc: 0.7286 - val_loss: 0.6936 - val_acc: 0.7482\n",
      "Epoch 1320/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6811 - acc: 0.7310 - val_loss: 0.6936 - val_acc: 0.7482\n",
      "Epoch 1321/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6811 - acc: 0.7318 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1322/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6810 - acc: 0.7310 - val_loss: 0.6938 - val_acc: 0.7482\n",
      "Epoch 1323/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6809 - acc: 0.7310 - val_loss: 0.6937 - val_acc: 0.7482\n",
      "Epoch 1324/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6809 - acc: 0.7310 - val_loss: 0.6939 - val_acc: 0.7482\n",
      "Epoch 1325/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6809 - acc: 0.7310 - val_loss: 0.6937 - val_acc: 0.7482\n",
      "Epoch 1326/2000\n",
      "1249/1249 [==============================] - 0s 202us/step - loss: 0.6808 - acc: 0.7310 - val_loss: 0.6936 - val_acc: 0.7482\n",
      "Epoch 1327/2000\n",
      "1249/1249 [==============================] - 0s 195us/step - loss: 0.6808 - acc: 0.7310 - val_loss: 0.6934 - val_acc: 0.7482\n",
      "Epoch 1328/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6807 - acc: 0.7310 - val_loss: 0.6935 - val_acc: 0.7482\n",
      "Epoch 1329/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6807 - acc: 0.7310 - val_loss: 0.6935 - val_acc: 0.7482\n",
      "Epoch 1330/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6808 - acc: 0.7302 - val_loss: 0.6935 - val_acc: 0.7482\n",
      "Epoch 1331/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6807 - acc: 0.7326 - val_loss: 0.6936 - val_acc: 0.7482\n",
      "Epoch 1332/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6808 - acc: 0.7310 - val_loss: 0.6935 - val_acc: 0.7482\n",
      "Epoch 1333/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6806 - acc: 0.7326 - val_loss: 0.6933 - val_acc: 0.7482\n",
      "Epoch 1334/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6807 - acc: 0.7310 - val_loss: 0.6932 - val_acc: 0.7482\n",
      "Epoch 1335/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6806 - acc: 0.7302 - val_loss: 0.6933 - val_acc: 0.7482\n",
      "Epoch 1336/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6805 - acc: 0.7310 - val_loss: 0.6933 - val_acc: 0.7482\n",
      "Epoch 1337/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6805 - acc: 0.7318 - val_loss: 0.6933 - val_acc: 0.7482\n",
      "Epoch 1338/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6806 - acc: 0.7310 - val_loss: 0.6933 - val_acc: 0.7482\n",
      "Epoch 1339/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6807 - acc: 0.7326 - val_loss: 0.6931 - val_acc: 0.7482\n",
      "Epoch 1340/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6805 - acc: 0.7302 - val_loss: 0.6930 - val_acc: 0.7482\n",
      "Epoch 1341/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6805 - acc: 0.7310 - val_loss: 0.6931 - val_acc: 0.7482\n",
      "Epoch 1342/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6804 - acc: 0.7302 - val_loss: 0.6932 - val_acc: 0.7482\n",
      "Epoch 1343/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6804 - acc: 0.7310 - val_loss: 0.6931 - val_acc: 0.7482\n",
      "Epoch 1344/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6803 - acc: 0.7334 - val_loss: 0.6932 - val_acc: 0.7482\n",
      "Epoch 1345/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6802 - acc: 0.7310 - val_loss: 0.6930 - val_acc: 0.7482\n",
      "Epoch 1346/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6803 - acc: 0.7302 - val_loss: 0.6932 - val_acc: 0.7482\n",
      "Epoch 1347/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6803 - acc: 0.7310 - val_loss: 0.6929 - val_acc: 0.7482\n",
      "Epoch 1348/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6803 - acc: 0.7310 - val_loss: 0.6929 - val_acc: 0.7482\n",
      "Epoch 1349/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6801 - acc: 0.7318 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1350/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6802 - acc: 0.7318 - val_loss: 0.6928 - val_acc: 0.7482\n",
      "Epoch 1351/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6801 - acc: 0.7310 - val_loss: 0.6928 - val_acc: 0.7482\n",
      "Epoch 1352/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6801 - acc: 0.7286 - val_loss: 0.6928 - val_acc: 0.7482\n",
      "Epoch 1353/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6801 - acc: 0.7310 - val_loss: 0.6929 - val_acc: 0.7482\n",
      "Epoch 1354/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6800 - acc: 0.7318 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1355/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6802 - acc: 0.7310 - val_loss: 0.6929 - val_acc: 0.7482\n",
      "Epoch 1356/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6799 - acc: 0.7310 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1357/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6800 - acc: 0.7318 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1358/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6799 - acc: 0.7318 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1359/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6799 - acc: 0.7302 - val_loss: 0.6929 - val_acc: 0.7482\n",
      "Epoch 1360/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6799 - acc: 0.7286 - val_loss: 0.6929 - val_acc: 0.7482\n",
      "Epoch 1361/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6800 - acc: 0.7326 - val_loss: 0.6928 - val_acc: 0.7482\n",
      "Epoch 1362/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6799 - acc: 0.7318 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1363/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6799 - acc: 0.7318 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1364/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6797 - acc: 0.7334 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1365/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6798 - acc: 0.7326 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1366/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6798 - acc: 0.7302 - val_loss: 0.6928 - val_acc: 0.7482\n",
      "Epoch 1367/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6798 - acc: 0.7294 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1368/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6797 - acc: 0.7318 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1369/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6796 - acc: 0.7326 - val_loss: 0.6930 - val_acc: 0.7482\n",
      "Epoch 1370/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6796 - acc: 0.7302 - val_loss: 0.6930 - val_acc: 0.7482\n",
      "Epoch 1371/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6795 - acc: 0.7310 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1372/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6795 - acc: 0.7318 - val_loss: 0.6926 - val_acc: 0.7482\n",
      "Epoch 1373/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6794 - acc: 0.7318 - val_loss: 0.6926 - val_acc: 0.7482\n",
      "Epoch 1374/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6795 - acc: 0.7318 - val_loss: 0.6926 - val_acc: 0.7482\n",
      "Epoch 1375/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6794 - acc: 0.7326 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1376/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6794 - acc: 0.7302 - val_loss: 0.6928 - val_acc: 0.7482\n",
      "Epoch 1377/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6794 - acc: 0.7302 - val_loss: 0.6928 - val_acc: 0.7482\n",
      "Epoch 1378/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6794 - acc: 0.7310 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1379/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6794 - acc: 0.7326 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1380/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6792 - acc: 0.7318 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1381/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6793 - acc: 0.7318 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1382/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6792 - acc: 0.7326 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1383/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6793 - acc: 0.7326 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1384/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6792 - acc: 0.7302 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1385/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6794 - acc: 0.7310 - val_loss: 0.6920 - val_acc: 0.7482\n",
      "Epoch 1386/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6793 - acc: 0.7294 - val_loss: 0.6921 - val_acc: 0.7482\n",
      "Epoch 1387/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6791 - acc: 0.7310 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1388/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6791 - acc: 0.7302 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1389/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6790 - acc: 0.7302 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1390/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6790 - acc: 0.7294 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1391/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6790 - acc: 0.7334 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1392/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6789 - acc: 0.7350 - val_loss: 0.6927 - val_acc: 0.7482\n",
      "Epoch 1393/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6790 - acc: 0.7326 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1394/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6789 - acc: 0.7326 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1395/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6788 - acc: 0.7318 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1396/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6788 - acc: 0.7326 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1397/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6789 - acc: 0.7334 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1398/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6787 - acc: 0.7318 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1399/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6788 - acc: 0.7302 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1400/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6788 - acc: 0.7318 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1401/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6787 - acc: 0.7326 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1402/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6786 - acc: 0.7302 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1403/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6788 - acc: 0.7318 - val_loss: 0.6928 - val_acc: 0.7482\n",
      "Epoch 1404/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6787 - acc: 0.7350 - val_loss: 0.6926 - val_acc: 0.7482\n",
      "Epoch 1405/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6787 - acc: 0.7326 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1406/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6786 - acc: 0.7310 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1407/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6786 - acc: 0.7342 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1408/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6785 - acc: 0.7310 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1409/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6785 - acc: 0.7294 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1410/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6785 - acc: 0.7318 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1411/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6783 - acc: 0.7310 - val_loss: 0.6920 - val_acc: 0.7482\n",
      "Epoch 1412/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6783 - acc: 0.7310 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1413/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6781 - acc: 0.7326 - val_loss: 0.6920 - val_acc: 0.7482\n",
      "Epoch 1414/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6783 - acc: 0.7318 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1415/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6783 - acc: 0.7310 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1416/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6783 - acc: 0.7310 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1417/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6782 - acc: 0.7326 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1418/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6782 - acc: 0.7310 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1419/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6781 - acc: 0.7310 - val_loss: 0.6921 - val_acc: 0.7482\n",
      "Epoch 1420/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6781 - acc: 0.7326 - val_loss: 0.6921 - val_acc: 0.7482\n",
      "Epoch 1421/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6782 - acc: 0.7310 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1422/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6781 - acc: 0.7318 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1423/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6780 - acc: 0.7342 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1424/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6780 - acc: 0.7318 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1425/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6779 - acc: 0.7342 - val_loss: 0.6925 - val_acc: 0.7482\n",
      "Epoch 1426/2000\n",
      "1249/1249 [==============================] - 0s 199us/step - loss: 0.6779 - acc: 0.7310 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1427/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6779 - acc: 0.7318 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1428/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6779 - acc: 0.7342 - val_loss: 0.6924 - val_acc: 0.7482\n",
      "Epoch 1429/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6779 - acc: 0.7318 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1430/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6780 - acc: 0.7326 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1431/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6777 - acc: 0.7310 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1432/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6778 - acc: 0.7318 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1433/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6777 - acc: 0.7318 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1434/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6778 - acc: 0.7342 - val_loss: 0.6922 - val_acc: 0.7482\n",
      "Epoch 1435/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6779 - acc: 0.7294 - val_loss: 0.6923 - val_acc: 0.7482\n",
      "Epoch 1436/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6778 - acc: 0.7342 - val_loss: 0.6919 - val_acc: 0.7482\n",
      "Epoch 1437/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6776 - acc: 0.7342 - val_loss: 0.6920 - val_acc: 0.7482\n",
      "Epoch 1438/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6776 - acc: 0.7318 - val_loss: 0.6919 - val_acc: 0.7482\n",
      "Epoch 1439/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6776 - acc: 0.7310 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1440/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6775 - acc: 0.7310 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1441/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6775 - acc: 0.7334 - val_loss: 0.6920 - val_acc: 0.7482\n",
      "Epoch 1442/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6774 - acc: 0.7310 - val_loss: 0.6920 - val_acc: 0.7482\n",
      "Epoch 1443/2000\n",
      "1249/1249 [==============================] - 0s 194us/step - loss: 0.6776 - acc: 0.7342 - val_loss: 0.6919 - val_acc: 0.7482\n",
      "Epoch 1444/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6774 - acc: 0.7342 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1445/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6773 - acc: 0.7334 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1446/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6774 - acc: 0.7294 - val_loss: 0.6917 - val_acc: 0.7506\n",
      "Epoch 1447/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6773 - acc: 0.7302 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1448/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6773 - acc: 0.7302 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1449/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6772 - acc: 0.7310 - val_loss: 0.6917 - val_acc: 0.7506\n",
      "Epoch 1450/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6773 - acc: 0.7350 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1451/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6773 - acc: 0.7326 - val_loss: 0.6917 - val_acc: 0.7506\n",
      "Epoch 1452/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6773 - acc: 0.7342 - val_loss: 0.6918 - val_acc: 0.7506\n",
      "Epoch 1453/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6774 - acc: 0.7342 - val_loss: 0.6919 - val_acc: 0.7482\n",
      "Epoch 1454/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6772 - acc: 0.7326 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1455/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.6772 - acc: 0.7318 - val_loss: 0.6919 - val_acc: 0.7482\n",
      "Epoch 1456/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6771 - acc: 0.7334 - val_loss: 0.6919 - val_acc: 0.7482\n",
      "Epoch 1457/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6771 - acc: 0.7326 - val_loss: 0.6919 - val_acc: 0.7482\n",
      "Epoch 1458/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6771 - acc: 0.7326 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1459/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6770 - acc: 0.7326 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1460/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6770 - acc: 0.7342 - val_loss: 0.6916 - val_acc: 0.7506\n",
      "Epoch 1461/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6771 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1462/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6769 - acc: 0.7350 - val_loss: 0.6914 - val_acc: 0.7506\n",
      "Epoch 1463/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6768 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1464/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6769 - acc: 0.7334 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1465/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6768 - acc: 0.7326 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1466/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6769 - acc: 0.7342 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1467/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6768 - acc: 0.7334 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1468/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6767 - acc: 0.7342 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1469/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.6767 - acc: 0.7334 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1470/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6769 - acc: 0.7326 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1471/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6767 - acc: 0.7318 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1472/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6767 - acc: 0.7350 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1473/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6765 - acc: 0.7302 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1474/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6768 - acc: 0.7318 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1475/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6766 - acc: 0.7350 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1476/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6766 - acc: 0.7318 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1477/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6766 - acc: 0.7350 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1478/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6765 - acc: 0.7302 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1479/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6765 - acc: 0.7358 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1480/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6765 - acc: 0.7318 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1481/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6766 - acc: 0.7358 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1482/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6764 - acc: 0.7358 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1483/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6763 - acc: 0.7334 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1484/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6763 - acc: 0.7358 - val_loss: 0.6916 - val_acc: 0.7506\n",
      "Epoch 1485/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6764 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.7506\n",
      "Epoch 1486/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6765 - acc: 0.7358 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1487/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6763 - acc: 0.7350 - val_loss: 0.6916 - val_acc: 0.7506\n",
      "Epoch 1488/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6763 - acc: 0.7318 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1489/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6764 - acc: 0.7342 - val_loss: 0.6916 - val_acc: 0.7506\n",
      "Epoch 1490/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6763 - acc: 0.7318 - val_loss: 0.6917 - val_acc: 0.7482\n",
      "Epoch 1491/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6761 - acc: 0.7310 - val_loss: 0.6918 - val_acc: 0.7482\n",
      "Epoch 1492/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6764 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1493/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6763 - acc: 0.7366 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1494/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6762 - acc: 0.7326 - val_loss: 0.6914 - val_acc: 0.7482\n",
      "Epoch 1495/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6761 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.7506\n",
      "Epoch 1496/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6761 - acc: 0.7358 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1497/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6760 - acc: 0.7350 - val_loss: 0.6914 - val_acc: 0.7482\n",
      "Epoch 1498/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6760 - acc: 0.7358 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1499/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6761 - acc: 0.7326 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1500/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6760 - acc: 0.7318 - val_loss: 0.6915 - val_acc: 0.7506\n",
      "Epoch 1501/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6761 - acc: 0.7358 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1502/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6760 - acc: 0.7358 - val_loss: 0.6919 - val_acc: 0.7482\n",
      "Epoch 1503/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6759 - acc: 0.7334 - val_loss: 0.6916 - val_acc: 0.7482\n",
      "Epoch 1504/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6759 - acc: 0.7350 - val_loss: 0.6915 - val_acc: 0.7506\n",
      "Epoch 1505/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6759 - acc: 0.7334 - val_loss: 0.6913 - val_acc: 0.7482\n",
      "Epoch 1506/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6760 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1507/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6759 - acc: 0.7358 - val_loss: 0.6913 - val_acc: 0.7506\n",
      "Epoch 1508/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6759 - acc: 0.7334 - val_loss: 0.6911 - val_acc: 0.7506\n",
      "Epoch 1509/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6758 - acc: 0.7318 - val_loss: 0.6913 - val_acc: 0.7482\n",
      "Epoch 1510/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6757 - acc: 0.7326 - val_loss: 0.6912 - val_acc: 0.7506\n",
      "Epoch 1511/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6757 - acc: 0.7342 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1512/2000\n",
      "1249/1249 [==============================] - 0s 205us/step - loss: 0.6757 - acc: 0.7318 - val_loss: 0.6913 - val_acc: 0.7482\n",
      "Epoch 1513/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6757 - acc: 0.7350 - val_loss: 0.6914 - val_acc: 0.7482\n",
      "Epoch 1514/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6755 - acc: 0.7318 - val_loss: 0.6914 - val_acc: 0.7506\n",
      "Epoch 1515/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6756 - acc: 0.7342 - val_loss: 0.6912 - val_acc: 0.7506\n",
      "Epoch 1516/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6756 - acc: 0.7334 - val_loss: 0.6912 - val_acc: 0.7482\n",
      "Epoch 1517/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6756 - acc: 0.7342 - val_loss: 0.6912 - val_acc: 0.7506\n",
      "Epoch 1518/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6755 - acc: 0.7334 - val_loss: 0.6913 - val_acc: 0.7506\n",
      "Epoch 1519/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6755 - acc: 0.7326 - val_loss: 0.6912 - val_acc: 0.7506\n",
      "Epoch 1520/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6755 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1521/2000\n",
      "1249/1249 [==============================] - 0s 145us/step - loss: 0.6755 - acc: 0.7318 - val_loss: 0.6915 - val_acc: 0.7482\n",
      "Epoch 1522/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6756 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.7506\n",
      "Epoch 1523/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6753 - acc: 0.7326 - val_loss: 0.6913 - val_acc: 0.7506\n",
      "Epoch 1524/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6755 - acc: 0.7318 - val_loss: 0.6914 - val_acc: 0.7506\n",
      "Epoch 1525/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6755 - acc: 0.7350 - val_loss: 0.6912 - val_acc: 0.7506\n",
      "Epoch 1526/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6753 - acc: 0.7358 - val_loss: 0.6911 - val_acc: 0.7506\n",
      "Epoch 1527/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6754 - acc: 0.7310 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1528/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6754 - acc: 0.7358 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1529/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6752 - acc: 0.7350 - val_loss: 0.6912 - val_acc: 0.7482\n",
      "Epoch 1530/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6752 - acc: 0.7342 - val_loss: 0.6908 - val_acc: 0.7506\n",
      "Epoch 1531/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6753 - acc: 0.7350 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1532/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6753 - acc: 0.7342 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1533/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6752 - acc: 0.7326 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1534/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6751 - acc: 0.7318 - val_loss: 0.6912 - val_acc: 0.7482\n",
      "Epoch 1535/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6751 - acc: 0.7334 - val_loss: 0.6913 - val_acc: 0.7482\n",
      "Epoch 1536/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6751 - acc: 0.7342 - val_loss: 0.6912 - val_acc: 0.7506\n",
      "Epoch 1537/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6751 - acc: 0.7334 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1538/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6751 - acc: 0.7350 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1539/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6752 - acc: 0.7342 - val_loss: 0.6911 - val_acc: 0.7506\n",
      "Epoch 1540/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6751 - acc: 0.7358 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1541/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6750 - acc: 0.7358 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1542/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6750 - acc: 0.7334 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1543/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6750 - acc: 0.7342 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1544/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6749 - acc: 0.7350 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1545/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6749 - acc: 0.7318 - val_loss: 0.6911 - val_acc: 0.7482\n",
      "Epoch 1546/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6749 - acc: 0.7358 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1547/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6748 - acc: 0.7358 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1548/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6748 - acc: 0.7326 - val_loss: 0.6910 - val_acc: 0.7482\n",
      "Epoch 1549/2000\n",
      "1249/1249 [==============================] - 0s 202us/step - loss: 0.6750 - acc: 0.7366 - val_loss: 0.6909 - val_acc: 0.7482\n",
      "Epoch 1550/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6748 - acc: 0.7366 - val_loss: 0.6910 - val_acc: 0.7482\n",
      "Epoch 1551/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6748 - acc: 0.7342 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1552/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6746 - acc: 0.7334 - val_loss: 0.6908 - val_acc: 0.7506\n",
      "Epoch 1553/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6748 - acc: 0.7366 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1554/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6747 - acc: 0.7326 - val_loss: 0.6912 - val_acc: 0.7482\n",
      "Epoch 1555/2000\n",
      "1249/1249 [==============================] - 0s 206us/step - loss: 0.6746 - acc: 0.7326 - val_loss: 0.6912 - val_acc: 0.7506\n",
      "Epoch 1556/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6746 - acc: 0.7374 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 1557/2000\n",
      "1249/1249 [==============================] - 0s 202us/step - loss: 0.6748 - acc: 0.7342 - val_loss: 0.6908 - val_acc: 0.7506\n",
      "Epoch 1558/2000\n",
      "1249/1249 [==============================] - 0s 204us/step - loss: 0.6747 - acc: 0.7342 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1559/2000\n",
      "1249/1249 [==============================] - 0s 195us/step - loss: 0.6745 - acc: 0.7342 - val_loss: 0.6908 - val_acc: 0.7506\n",
      "Epoch 1560/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6746 - acc: 0.7350 - val_loss: 0.6908 - val_acc: 0.7506\n",
      "Epoch 1561/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6745 - acc: 0.7326 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1562/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6746 - acc: 0.7326 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1563/2000\n",
      "1249/1249 [==============================] - 0s 190us/step - loss: 0.6744 - acc: 0.7366 - val_loss: 0.6911 - val_acc: 0.7506\n",
      "Epoch 1564/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6745 - acc: 0.7350 - val_loss: 0.6909 - val_acc: 0.7506\n",
      "Epoch 1565/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6744 - acc: 0.7358 - val_loss: 0.6909 - val_acc: 0.7482\n",
      "Epoch 1566/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6743 - acc: 0.7358 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1567/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6746 - acc: 0.7334 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1568/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6743 - acc: 0.7350 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1569/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6743 - acc: 0.7350 - val_loss: 0.6906 - val_acc: 0.7506\n",
      "Epoch 1570/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6744 - acc: 0.7350 - val_loss: 0.6908 - val_acc: 0.7482\n",
      "Epoch 1571/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.6744 - acc: 0.7358 - val_loss: 0.6908 - val_acc: 0.7482\n",
      "Epoch 1572/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6743 - acc: 0.7366 - val_loss: 0.6906 - val_acc: 0.7506\n",
      "Epoch 1573/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6743 - acc: 0.7350 - val_loss: 0.6908 - val_acc: 0.7506\n",
      "Epoch 1574/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6743 - acc: 0.7334 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1575/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6743 - acc: 0.7342 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1576/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6742 - acc: 0.7358 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1577/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6742 - acc: 0.7358 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1578/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6742 - acc: 0.7358 - val_loss: 0.6908 - val_acc: 0.7506\n",
      "Epoch 1579/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6741 - acc: 0.7350 - val_loss: 0.6906 - val_acc: 0.7506\n",
      "Epoch 1580/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6740 - acc: 0.7358 - val_loss: 0.6904 - val_acc: 0.7506\n",
      "Epoch 1581/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6741 - acc: 0.7326 - val_loss: 0.6906 - val_acc: 0.7506\n",
      "Epoch 1582/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6741 - acc: 0.7350 - val_loss: 0.6902 - val_acc: 0.7506\n",
      "Epoch 1583/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6741 - acc: 0.7350 - val_loss: 0.6903 - val_acc: 0.7506\n",
      "Epoch 1584/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6740 - acc: 0.7350 - val_loss: 0.6904 - val_acc: 0.7506\n",
      "Epoch 1585/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6741 - acc: 0.7350 - val_loss: 0.6905 - val_acc: 0.7506\n",
      "Epoch 1586/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6737 - acc: 0.7326 - val_loss: 0.6908 - val_acc: 0.7482\n",
      "Epoch 1587/2000\n",
      "1249/1249 [==============================] - 0s 203us/step - loss: 0.6741 - acc: 0.7342 - val_loss: 0.6904 - val_acc: 0.7506\n",
      "Epoch 1588/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6738 - acc: 0.7342 - val_loss: 0.6904 - val_acc: 0.7506\n",
      "Epoch 1589/2000\n",
      "1249/1249 [==============================] - 0s 202us/step - loss: 0.6740 - acc: 0.7334 - val_loss: 0.6904 - val_acc: 0.7506\n",
      "Epoch 1590/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6740 - acc: 0.7342 - val_loss: 0.6905 - val_acc: 0.7506\n",
      "Epoch 1591/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6739 - acc: 0.7366 - val_loss: 0.6908 - val_acc: 0.7506\n",
      "Epoch 1592/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6737 - acc: 0.7350 - val_loss: 0.6906 - val_acc: 0.7506\n",
      "Epoch 1593/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6738 - acc: 0.7366 - val_loss: 0.6906 - val_acc: 0.7506\n",
      "Epoch 1594/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.6737 - acc: 0.7334 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1595/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6737 - acc: 0.7318 - val_loss: 0.6908 - val_acc: 0.7482\n",
      "Epoch 1596/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6737 - acc: 0.7366 - val_loss: 0.6906 - val_acc: 0.7506\n",
      "Epoch 1597/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6738 - acc: 0.7326 - val_loss: 0.6907 - val_acc: 0.7506\n",
      "Epoch 1598/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6737 - acc: 0.7358 - val_loss: 0.6902 - val_acc: 0.7506\n",
      "Epoch 1599/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6737 - acc: 0.7366 - val_loss: 0.6901 - val_acc: 0.7506\n",
      "Epoch 1600/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6737 - acc: 0.7310 - val_loss: 0.6902 - val_acc: 0.7506\n",
      "Epoch 1601/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6736 - acc: 0.7350 - val_loss: 0.6903 - val_acc: 0.7506\n",
      "Epoch 1602/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6736 - acc: 0.7326 - val_loss: 0.6903 - val_acc: 0.7482\n",
      "Epoch 1603/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6737 - acc: 0.7342 - val_loss: 0.6900 - val_acc: 0.7506\n",
      "Epoch 1604/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6736 - acc: 0.7358 - val_loss: 0.6898 - val_acc: 0.7506\n",
      "Epoch 1605/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6735 - acc: 0.7326 - val_loss: 0.6901 - val_acc: 0.7506\n",
      "Epoch 1606/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6734 - acc: 0.7350 - val_loss: 0.6898 - val_acc: 0.7506\n",
      "Epoch 1607/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6735 - acc: 0.7342 - val_loss: 0.6900 - val_acc: 0.7506\n",
      "Epoch 1608/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6735 - acc: 0.7366 - val_loss: 0.6899 - val_acc: 0.7506\n",
      "Epoch 1609/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6734 - acc: 0.7366 - val_loss: 0.6900 - val_acc: 0.7506\n",
      "Epoch 1610/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6735 - acc: 0.7334 - val_loss: 0.6900 - val_acc: 0.7506\n",
      "Epoch 1611/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6735 - acc: 0.7358 - val_loss: 0.6901 - val_acc: 0.7506\n",
      "Epoch 1612/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6734 - acc: 0.7358 - val_loss: 0.6899 - val_acc: 0.7506\n",
      "Epoch 1613/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6733 - acc: 0.7358 - val_loss: 0.6900 - val_acc: 0.7506\n",
      "Epoch 1614/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6735 - acc: 0.7342 - val_loss: 0.6901 - val_acc: 0.7506\n",
      "Epoch 1615/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6733 - acc: 0.7350 - val_loss: 0.6902 - val_acc: 0.7506\n",
      "Epoch 1616/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6732 - acc: 0.7318 - val_loss: 0.6902 - val_acc: 0.7506\n",
      "Epoch 1617/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6733 - acc: 0.7350 - val_loss: 0.6897 - val_acc: 0.7506\n",
      "Epoch 1618/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6733 - acc: 0.7366 - val_loss: 0.6897 - val_acc: 0.7506\n",
      "Epoch 1619/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6732 - acc: 0.7350 - val_loss: 0.6899 - val_acc: 0.7506\n",
      "Epoch 1620/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6733 - acc: 0.7358 - val_loss: 0.6899 - val_acc: 0.7506\n",
      "Epoch 1621/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6733 - acc: 0.7366 - val_loss: 0.6896 - val_acc: 0.7506\n",
      "Epoch 1622/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6731 - acc: 0.7326 - val_loss: 0.6898 - val_acc: 0.7506\n",
      "Epoch 1623/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6733 - acc: 0.7350 - val_loss: 0.6899 - val_acc: 0.7506\n",
      "Epoch 1624/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6731 - acc: 0.7334 - val_loss: 0.6898 - val_acc: 0.7506\n",
      "Epoch 1625/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6731 - acc: 0.7366 - val_loss: 0.6898 - val_acc: 0.7506\n",
      "Epoch 1626/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6733 - acc: 0.7358 - val_loss: 0.6898 - val_acc: 0.7506\n",
      "Epoch 1627/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6731 - acc: 0.7334 - val_loss: 0.6900 - val_acc: 0.7506\n",
      "Epoch 1628/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6730 - acc: 0.7366 - val_loss: 0.6901 - val_acc: 0.7506\n",
      "Epoch 1629/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6731 - acc: 0.7310 - val_loss: 0.6900 - val_acc: 0.7506\n",
      "Epoch 1630/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6730 - acc: 0.7350 - val_loss: 0.6898 - val_acc: 0.7506\n",
      "Epoch 1631/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6732 - acc: 0.7366 - val_loss: 0.6898 - val_acc: 0.7506\n",
      "Epoch 1632/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6730 - acc: 0.7358 - val_loss: 0.6896 - val_acc: 0.7506\n",
      "Epoch 1633/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6729 - acc: 0.7366 - val_loss: 0.6895 - val_acc: 0.7506\n",
      "Epoch 1634/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6729 - acc: 0.7358 - val_loss: 0.6893 - val_acc: 0.7506\n",
      "Epoch 1635/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6730 - acc: 0.7358 - val_loss: 0.6894 - val_acc: 0.7506\n",
      "Epoch 1636/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6728 - acc: 0.7350 - val_loss: 0.6895 - val_acc: 0.7506\n",
      "Epoch 1637/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6728 - acc: 0.7366 - val_loss: 0.6893 - val_acc: 0.7506\n",
      "Epoch 1638/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6730 - acc: 0.7350 - val_loss: 0.6893 - val_acc: 0.7506\n",
      "Epoch 1639/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6728 - acc: 0.7350 - val_loss: 0.6894 - val_acc: 0.7506\n",
      "Epoch 1640/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6728 - acc: 0.7366 - val_loss: 0.6891 - val_acc: 0.7506\n",
      "Epoch 1641/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6729 - acc: 0.7334 - val_loss: 0.6891 - val_acc: 0.7506\n",
      "Epoch 1642/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6727 - acc: 0.7350 - val_loss: 0.6889 - val_acc: 0.7506\n",
      "Epoch 1643/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6727 - acc: 0.7366 - val_loss: 0.6892 - val_acc: 0.7506\n",
      "Epoch 1644/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6728 - acc: 0.7326 - val_loss: 0.6893 - val_acc: 0.7506\n",
      "Epoch 1645/2000\n",
      "1249/1249 [==============================] - 0s 195us/step - loss: 0.6727 - acc: 0.7366 - val_loss: 0.6891 - val_acc: 0.7506\n",
      "Epoch 1646/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6726 - acc: 0.7342 - val_loss: 0.6891 - val_acc: 0.7506\n",
      "Epoch 1647/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6727 - acc: 0.7366 - val_loss: 0.6891 - val_acc: 0.7506\n",
      "Epoch 1648/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6727 - acc: 0.7366 - val_loss: 0.6890 - val_acc: 0.7506\n",
      "Epoch 1649/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6725 - acc: 0.7366 - val_loss: 0.6889 - val_acc: 0.7506\n",
      "Epoch 1650/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6726 - acc: 0.7350 - val_loss: 0.6888 - val_acc: 0.7506\n",
      "Epoch 1651/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6725 - acc: 0.7366 - val_loss: 0.6887 - val_acc: 0.7506\n",
      "Epoch 1652/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6725 - acc: 0.7342 - val_loss: 0.6888 - val_acc: 0.7506\n",
      "Epoch 1653/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6726 - acc: 0.7342 - val_loss: 0.6890 - val_acc: 0.7506\n",
      "Epoch 1654/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6726 - acc: 0.7366 - val_loss: 0.6889 - val_acc: 0.7506\n",
      "Epoch 1655/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6724 - acc: 0.7358 - val_loss: 0.6888 - val_acc: 0.7506\n",
      "Epoch 1656/2000\n",
      "1249/1249 [==============================] - 0s 151us/step - loss: 0.6727 - acc: 0.7342 - val_loss: 0.6888 - val_acc: 0.7506\n",
      "Epoch 1657/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6725 - acc: 0.7350 - val_loss: 0.6888 - val_acc: 0.7506\n",
      "Epoch 1658/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6725 - acc: 0.7350 - val_loss: 0.6883 - val_acc: 0.7506\n",
      "Epoch 1659/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6724 - acc: 0.7366 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1660/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6726 - acc: 0.7334 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1661/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6725 - acc: 0.7342 - val_loss: 0.6887 - val_acc: 0.7506\n",
      "Epoch 1662/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6726 - acc: 0.7366 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1663/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6724 - acc: 0.7342 - val_loss: 0.6887 - val_acc: 0.7506\n",
      "Epoch 1664/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6723 - acc: 0.7358 - val_loss: 0.6888 - val_acc: 0.7506\n",
      "Epoch 1665/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6723 - acc: 0.7342 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1666/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6723 - acc: 0.7350 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1667/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6726 - acc: 0.7342 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1668/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6723 - acc: 0.7350 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1669/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6724 - acc: 0.7366 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1670/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.6721 - acc: 0.7358 - val_loss: 0.6880 - val_acc: 0.7506\n",
      "Epoch 1671/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6723 - acc: 0.7342 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1672/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6723 - acc: 0.7350 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1673/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6721 - acc: 0.7358 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1674/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6723 - acc: 0.7334 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1675/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6721 - acc: 0.7326 - val_loss: 0.6885 - val_acc: 0.7506\n",
      "Epoch 1676/2000\n",
      "1249/1249 [==============================] - 0s 147us/step - loss: 0.6722 - acc: 0.7366 - val_loss: 0.6887 - val_acc: 0.7506\n",
      "Epoch 1677/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6723 - acc: 0.7366 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1678/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6722 - acc: 0.7342 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1679/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6721 - acc: 0.7366 - val_loss: 0.6887 - val_acc: 0.7506\n",
      "Epoch 1680/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6722 - acc: 0.7350 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1681/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6720 - acc: 0.7366 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1682/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6720 - acc: 0.7334 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1683/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6719 - acc: 0.7358 - val_loss: 0.6885 - val_acc: 0.7506\n",
      "Epoch 1684/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6720 - acc: 0.7358 - val_loss: 0.6885 - val_acc: 0.7506\n",
      "Epoch 1685/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6719 - acc: 0.7358 - val_loss: 0.6882 - val_acc: 0.7506\n",
      "Epoch 1686/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6719 - acc: 0.7350 - val_loss: 0.6883 - val_acc: 0.7506\n",
      "Epoch 1687/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6720 - acc: 0.7350 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1688/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6718 - acc: 0.7342 - val_loss: 0.6886 - val_acc: 0.7506\n",
      "Epoch 1689/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6719 - acc: 0.7366 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1690/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6719 - acc: 0.7366 - val_loss: 0.6882 - val_acc: 0.7506\n",
      "Epoch 1691/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6720 - acc: 0.7358 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1692/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6716 - acc: 0.7334 - val_loss: 0.6883 - val_acc: 0.7506\n",
      "Epoch 1693/2000\n",
      "1249/1249 [==============================] - 0s 147us/step - loss: 0.6719 - acc: 0.7358 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1694/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6717 - acc: 0.7358 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1695/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6718 - acc: 0.7366 - val_loss: 0.6880 - val_acc: 0.7506\n",
      "Epoch 1696/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6719 - acc: 0.7350 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1697/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6719 - acc: 0.7342 - val_loss: 0.6882 - val_acc: 0.7506\n",
      "Epoch 1698/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6717 - acc: 0.7342 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1699/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6716 - acc: 0.7358 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1700/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6714 - acc: 0.7318 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1701/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6717 - acc: 0.7374 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1702/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6718 - acc: 0.7342 - val_loss: 0.6884 - val_acc: 0.7506\n",
      "Epoch 1703/2000\n",
      "1249/1249 [==============================] - 0s 147us/step - loss: 0.6719 - acc: 0.7326 - val_loss: 0.6882 - val_acc: 0.7506\n",
      "Epoch 1704/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6717 - acc: 0.7350 - val_loss: 0.6882 - val_acc: 0.7506\n",
      "Epoch 1705/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6716 - acc: 0.7350 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1706/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6715 - acc: 0.7326 - val_loss: 0.6885 - val_acc: 0.7506\n",
      "Epoch 1707/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6716 - acc: 0.7366 - val_loss: 0.6882 - val_acc: 0.7506\n",
      "Epoch 1708/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6716 - acc: 0.7366 - val_loss: 0.6882 - val_acc: 0.7506\n",
      "Epoch 1709/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6716 - acc: 0.7342 - val_loss: 0.6880 - val_acc: 0.7506\n",
      "Epoch 1710/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6715 - acc: 0.7334 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1711/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6716 - acc: 0.7342 - val_loss: 0.6878 - val_acc: 0.7506\n",
      "Epoch 1712/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6715 - acc: 0.7342 - val_loss: 0.6879 - val_acc: 0.7506\n",
      "Epoch 1713/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6716 - acc: 0.7350 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1714/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6714 - acc: 0.7310 - val_loss: 0.6880 - val_acc: 0.7506\n",
      "Epoch 1715/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6715 - acc: 0.7358 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 1716/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6714 - acc: 0.7366 - val_loss: 0.6879 - val_acc: 0.7506\n",
      "Epoch 1717/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6714 - acc: 0.7342 - val_loss: 0.6879 - val_acc: 0.7506\n",
      "Epoch 1718/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6714 - acc: 0.7326 - val_loss: 0.6878 - val_acc: 0.7506\n",
      "Epoch 1719/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6714 - acc: 0.7350 - val_loss: 0.6880 - val_acc: 0.7506\n",
      "Epoch 1720/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6713 - acc: 0.7350 - val_loss: 0.6878 - val_acc: 0.7506\n",
      "Epoch 1721/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6714 - acc: 0.7366 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1722/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6714 - acc: 0.7358 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1723/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6713 - acc: 0.7366 - val_loss: 0.6876 - val_acc: 0.7506\n",
      "Epoch 1724/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6713 - acc: 0.7366 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1725/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6713 - acc: 0.7366 - val_loss: 0.6876 - val_acc: 0.7506\n",
      "Epoch 1726/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6712 - acc: 0.7350 - val_loss: 0.6876 - val_acc: 0.7506\n",
      "Epoch 1727/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6713 - acc: 0.7318 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1728/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6713 - acc: 0.7326 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1729/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6711 - acc: 0.7366 - val_loss: 0.6874 - val_acc: 0.7506\n",
      "Epoch 1730/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6711 - acc: 0.7342 - val_loss: 0.6874 - val_acc: 0.7506\n",
      "Epoch 1731/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6711 - acc: 0.7366 - val_loss: 0.6873 - val_acc: 0.7506\n",
      "Epoch 1732/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6713 - acc: 0.7366 - val_loss: 0.6874 - val_acc: 0.7506\n",
      "Epoch 1733/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6713 - acc: 0.7358 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1734/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6711 - acc: 0.7358 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1735/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6711 - acc: 0.7358 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1736/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6710 - acc: 0.7342 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1737/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6710 - acc: 0.7366 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1738/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6710 - acc: 0.7366 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1739/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6710 - acc: 0.7366 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1740/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6712 - acc: 0.7366 - val_loss: 0.6876 - val_acc: 0.7506\n",
      "Epoch 1741/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6710 - acc: 0.7326 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1742/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6709 - acc: 0.7342 - val_loss: 0.6878 - val_acc: 0.7506\n",
      "Epoch 1743/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6710 - acc: 0.7366 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1744/2000\n",
      "1249/1249 [==============================] - 0s 195us/step - loss: 0.6709 - acc: 0.7366 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1745/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6709 - acc: 0.7342 - val_loss: 0.6877 - val_acc: 0.7506\n",
      "Epoch 1746/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6707 - acc: 0.7366 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1747/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6709 - acc: 0.7342 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1748/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6708 - acc: 0.7366 - val_loss: 0.6876 - val_acc: 0.7506\n",
      "Epoch 1749/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6708 - acc: 0.7366 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1750/2000\n",
      "1249/1249 [==============================] - 0s 196us/step - loss: 0.6709 - acc: 0.7326 - val_loss: 0.6872 - val_acc: 0.7506\n",
      "Epoch 1751/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6707 - acc: 0.7326 - val_loss: 0.6876 - val_acc: 0.7506\n",
      "Epoch 1752/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6708 - acc: 0.7350 - val_loss: 0.6876 - val_acc: 0.7506\n",
      "Epoch 1753/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6708 - acc: 0.7358 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1754/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6707 - acc: 0.7350 - val_loss: 0.6874 - val_acc: 0.7506\n",
      "Epoch 1755/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6706 - acc: 0.7342 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1756/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6705 - acc: 0.7358 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1757/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6707 - acc: 0.7342 - val_loss: 0.6875 - val_acc: 0.7506\n",
      "Epoch 1758/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6706 - acc: 0.7366 - val_loss: 0.6875 - val_acc: 0.7530\n",
      "Epoch 1759/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6708 - acc: 0.7326 - val_loss: 0.6874 - val_acc: 0.7506\n",
      "Epoch 1760/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6706 - acc: 0.7358 - val_loss: 0.6873 - val_acc: 0.7506\n",
      "Epoch 1761/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6708 - acc: 0.7358 - val_loss: 0.6872 - val_acc: 0.7506\n",
      "Epoch 1762/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6707 - acc: 0.7350 - val_loss: 0.6872 - val_acc: 0.7506\n",
      "Epoch 1763/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6706 - acc: 0.7350 - val_loss: 0.6873 - val_acc: 0.7506\n",
      "Epoch 1764/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6705 - acc: 0.7358 - val_loss: 0.6871 - val_acc: 0.7506\n",
      "Epoch 1765/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6705 - acc: 0.7318 - val_loss: 0.6872 - val_acc: 0.7506\n",
      "Epoch 1766/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6706 - acc: 0.7358 - val_loss: 0.6871 - val_acc: 0.7506\n",
      "Epoch 1767/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6704 - acc: 0.7350 - val_loss: 0.6873 - val_acc: 0.7506\n",
      "Epoch 1768/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.6705 - acc: 0.7366 - val_loss: 0.6873 - val_acc: 0.7506\n",
      "Epoch 1769/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6705 - acc: 0.7358 - val_loss: 0.6872 - val_acc: 0.7506\n",
      "Epoch 1770/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6704 - acc: 0.7350 - val_loss: 0.6872 - val_acc: 0.7506\n",
      "Epoch 1771/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6704 - acc: 0.7366 - val_loss: 0.6873 - val_acc: 0.7506\n",
      "Epoch 1772/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6704 - acc: 0.7374 - val_loss: 0.6874 - val_acc: 0.7506\n",
      "Epoch 1773/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6704 - acc: 0.7350 - val_loss: 0.6874 - val_acc: 0.7506\n",
      "Epoch 1774/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6704 - acc: 0.7358 - val_loss: 0.6870 - val_acc: 0.7506\n",
      "Epoch 1775/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6703 - acc: 0.7326 - val_loss: 0.6872 - val_acc: 0.7506\n",
      "Epoch 1776/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6704 - acc: 0.7342 - val_loss: 0.6870 - val_acc: 0.7506\n",
      "Epoch 1777/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6704 - acc: 0.7366 - val_loss: 0.6868 - val_acc: 0.7506\n",
      "Epoch 1778/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6703 - acc: 0.7358 - val_loss: 0.6867 - val_acc: 0.7506\n",
      "Epoch 1779/2000\n",
      "1249/1249 [==============================] - 0s 200us/step - loss: 0.6703 - acc: 0.7350 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1780/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6704 - acc: 0.7342 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1781/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6703 - acc: 0.7358 - val_loss: 0.6867 - val_acc: 0.7506\n",
      "Epoch 1782/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6704 - acc: 0.7358 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1783/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6703 - acc: 0.7374 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1784/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6701 - acc: 0.7350 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1785/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6701 - acc: 0.7358 - val_loss: 0.6867 - val_acc: 0.7506\n",
      "Epoch 1786/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6702 - acc: 0.7366 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1787/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6703 - acc: 0.7358 - val_loss: 0.6869 - val_acc: 0.7506\n",
      "Epoch 1788/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6701 - acc: 0.7358 - val_loss: 0.6869 - val_acc: 0.7506\n",
      "Epoch 1789/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6703 - acc: 0.7342 - val_loss: 0.6869 - val_acc: 0.7506\n",
      "Epoch 1790/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6704 - acc: 0.7342 - val_loss: 0.6868 - val_acc: 0.7506\n",
      "Epoch 1791/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6701 - acc: 0.7390 - val_loss: 0.6869 - val_acc: 0.7506\n",
      "Epoch 1792/2000\n",
      "1249/1249 [==============================] - 0s 146us/step - loss: 0.6700 - acc: 0.7366 - val_loss: 0.6869 - val_acc: 0.7506\n",
      "Epoch 1793/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6700 - acc: 0.7374 - val_loss: 0.6866 - val_acc: 0.7530\n",
      "Epoch 1794/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6701 - acc: 0.7374 - val_loss: 0.6869 - val_acc: 0.7506\n",
      "Epoch 1795/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6701 - acc: 0.7358 - val_loss: 0.6868 - val_acc: 0.7506\n",
      "Epoch 1796/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6699 - acc: 0.7366 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1797/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6700 - acc: 0.7366 - val_loss: 0.6867 - val_acc: 0.7506\n",
      "Epoch 1798/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6701 - acc: 0.7374 - val_loss: 0.6867 - val_acc: 0.7506\n",
      "Epoch 1799/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6699 - acc: 0.7374 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6700 - acc: 0.7318 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1801/2000\n",
      "1249/1249 [==============================] - 0s 151us/step - loss: 0.6698 - acc: 0.7374 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1802/2000\n",
      "1249/1249 [==============================] - 0s 183us/step - loss: 0.6699 - acc: 0.7374 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1803/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6699 - acc: 0.7374 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1804/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6700 - acc: 0.7358 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1805/2000\n",
      "1249/1249 [==============================] - 0s 150us/step - loss: 0.6700 - acc: 0.7358 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1806/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6699 - acc: 0.7350 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1807/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6698 - acc: 0.7366 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1808/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6697 - acc: 0.7366 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1809/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6698 - acc: 0.7342 - val_loss: 0.6867 - val_acc: 0.7506\n",
      "Epoch 1810/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6698 - acc: 0.7366 - val_loss: 0.6867 - val_acc: 0.7506\n",
      "Epoch 1811/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6697 - acc: 0.7366 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1812/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6697 - acc: 0.7366 - val_loss: 0.6862 - val_acc: 0.7530\n",
      "Epoch 1813/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6698 - acc: 0.7358 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1814/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6696 - acc: 0.7358 - val_loss: 0.6863 - val_acc: 0.7530\n",
      "Epoch 1815/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6695 - acc: 0.7350 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1816/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6697 - acc: 0.7366 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1817/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6697 - acc: 0.7382 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1818/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6696 - acc: 0.7350 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1819/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6695 - acc: 0.7366 - val_loss: 0.6864 - val_acc: 0.7530\n",
      "Epoch 1820/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6697 - acc: 0.7358 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1821/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6697 - acc: 0.7374 - val_loss: 0.6868 - val_acc: 0.7506\n",
      "Epoch 1822/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6695 - acc: 0.7358 - val_loss: 0.6868 - val_acc: 0.7506\n",
      "Epoch 1823/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6696 - acc: 0.7366 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1824/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6696 - acc: 0.7366 - val_loss: 0.6866 - val_acc: 0.7530\n",
      "Epoch 1825/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6694 - acc: 0.7366 - val_loss: 0.6867 - val_acc: 0.7506\n",
      "Epoch 1826/2000\n",
      "1249/1249 [==============================] - 0s 197us/step - loss: 0.6697 - acc: 0.7374 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1827/2000\n",
      "1249/1249 [==============================] - 0s 201us/step - loss: 0.6695 - acc: 0.7374 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1828/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6695 - acc: 0.7366 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1829/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6694 - acc: 0.7350 - val_loss: 0.6866 - val_acc: 0.7506\n",
      "Epoch 1830/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6695 - acc: 0.7374 - val_loss: 0.6864 - val_acc: 0.7506\n",
      "Epoch 1831/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.6694 - acc: 0.7374 - val_loss: 0.6865 - val_acc: 0.7506\n",
      "Epoch 1832/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6694 - acc: 0.7366 - val_loss: 0.6862 - val_acc: 0.7506\n",
      "Epoch 1833/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6694 - acc: 0.7358 - val_loss: 0.6863 - val_acc: 0.7506\n",
      "Epoch 1834/2000\n",
      "1249/1249 [==============================] - 0s 162us/step - loss: 0.6693 - acc: 0.7374 - val_loss: 0.6862 - val_acc: 0.7530\n",
      "Epoch 1835/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6694 - acc: 0.7382 - val_loss: 0.6860 - val_acc: 0.7530\n",
      "Epoch 1836/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6692 - acc: 0.7366 - val_loss: 0.6860 - val_acc: 0.7506\n",
      "Epoch 1837/2000\n",
      "1249/1249 [==============================] - 0s 150us/step - loss: 0.6692 - acc: 0.7374 - val_loss: 0.6859 - val_acc: 0.7530\n",
      "Epoch 1838/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6694 - acc: 0.7382 - val_loss: 0.6858 - val_acc: 0.7530\n",
      "Epoch 1839/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6693 - acc: 0.7382 - val_loss: 0.6859 - val_acc: 0.7506\n",
      "Epoch 1840/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6692 - acc: 0.7398 - val_loss: 0.6863 - val_acc: 0.7506\n",
      "Epoch 1841/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6693 - acc: 0.7374 - val_loss: 0.6861 - val_acc: 0.7506\n",
      "Epoch 1842/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6693 - acc: 0.7374 - val_loss: 0.6861 - val_acc: 0.7506\n",
      "Epoch 1843/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6693 - acc: 0.7374 - val_loss: 0.6861 - val_acc: 0.7506\n",
      "Epoch 1844/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6693 - acc: 0.7374 - val_loss: 0.6861 - val_acc: 0.7506\n",
      "Epoch 1845/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6691 - acc: 0.7358 - val_loss: 0.6862 - val_acc: 0.7506\n",
      "Epoch 1846/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6692 - acc: 0.7366 - val_loss: 0.6861 - val_acc: 0.7506\n",
      "Epoch 1847/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6692 - acc: 0.7366 - val_loss: 0.6860 - val_acc: 0.7506\n",
      "Epoch 1848/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6691 - acc: 0.7358 - val_loss: 0.6860 - val_acc: 0.7506\n",
      "Epoch 1849/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6691 - acc: 0.7350 - val_loss: 0.6860 - val_acc: 0.7506\n",
      "Epoch 1850/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6691 - acc: 0.7374 - val_loss: 0.6858 - val_acc: 0.7506\n",
      "Epoch 1851/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6691 - acc: 0.7366 - val_loss: 0.6859 - val_acc: 0.7530\n",
      "Epoch 1852/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6690 - acc: 0.7374 - val_loss: 0.6861 - val_acc: 0.7506\n",
      "Epoch 1853/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6691 - acc: 0.7366 - val_loss: 0.6859 - val_acc: 0.7506\n",
      "Epoch 1854/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6691 - acc: 0.7358 - val_loss: 0.6860 - val_acc: 0.7506\n",
      "Epoch 1855/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6692 - acc: 0.7366 - val_loss: 0.6859 - val_acc: 0.7530\n",
      "Epoch 1856/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6691 - acc: 0.7382 - val_loss: 0.6858 - val_acc: 0.7506\n",
      "Epoch 1857/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6690 - acc: 0.7366 - val_loss: 0.6858 - val_acc: 0.7506\n",
      "Epoch 1858/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6690 - acc: 0.7374 - val_loss: 0.6858 - val_acc: 0.7506\n",
      "Epoch 1859/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6690 - acc: 0.7374 - val_loss: 0.6857 - val_acc: 0.7506\n",
      "Epoch 1860/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6689 - acc: 0.7358 - val_loss: 0.6857 - val_acc: 0.7506\n",
      "Epoch 1861/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6688 - acc: 0.7366 - val_loss: 0.6855 - val_acc: 0.7530\n",
      "Epoch 1862/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6689 - acc: 0.7382 - val_loss: 0.6854 - val_acc: 0.7530\n",
      "Epoch 1863/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6690 - acc: 0.7382 - val_loss: 0.6855 - val_acc: 0.7506\n",
      "Epoch 1864/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6687 - acc: 0.7374 - val_loss: 0.6858 - val_acc: 0.7506\n",
      "Epoch 1865/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6689 - acc: 0.7366 - val_loss: 0.6857 - val_acc: 0.7506\n",
      "Epoch 1866/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6688 - acc: 0.7390 - val_loss: 0.6856 - val_acc: 0.7506\n",
      "Epoch 1867/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6689 - acc: 0.7382 - val_loss: 0.6858 - val_acc: 0.7506\n",
      "Epoch 1868/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6688 - acc: 0.7382 - val_loss: 0.6856 - val_acc: 0.7506\n",
      "Epoch 1869/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6689 - acc: 0.7382 - val_loss: 0.6856 - val_acc: 0.7506\n",
      "Epoch 1870/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6687 - acc: 0.7390 - val_loss: 0.6854 - val_acc: 0.7530\n",
      "Epoch 1871/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6687 - acc: 0.7390 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1872/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6686 - acc: 0.7382 - val_loss: 0.6855 - val_acc: 0.7506\n",
      "Epoch 1873/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6688 - acc: 0.7374 - val_loss: 0.6855 - val_acc: 0.7506\n",
      "Epoch 1874/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6687 - acc: 0.7366 - val_loss: 0.6852 - val_acc: 0.7506\n",
      "Epoch 1875/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6687 - acc: 0.7382 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1876/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6687 - acc: 0.7382 - val_loss: 0.6855 - val_acc: 0.7530\n",
      "Epoch 1877/2000\n",
      "1249/1249 [==============================] - 0s 151us/step - loss: 0.6688 - acc: 0.7374 - val_loss: 0.6855 - val_acc: 0.7530\n",
      "Epoch 1878/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6686 - acc: 0.7382 - val_loss: 0.6855 - val_acc: 0.7506\n",
      "Epoch 1879/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6688 - acc: 0.7382 - val_loss: 0.6854 - val_acc: 0.7530\n",
      "Epoch 1880/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6686 - acc: 0.7374 - val_loss: 0.6854 - val_acc: 0.7530\n",
      "Epoch 1881/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6686 - acc: 0.7390 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1882/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6687 - acc: 0.7374 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1883/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6686 - acc: 0.7382 - val_loss: 0.6855 - val_acc: 0.7530\n",
      "Epoch 1884/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6686 - acc: 0.7350 - val_loss: 0.6854 - val_acc: 0.7530\n",
      "Epoch 1885/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6685 - acc: 0.7382 - val_loss: 0.6856 - val_acc: 0.7506\n",
      "Epoch 1886/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6684 - acc: 0.7390 - val_loss: 0.6856 - val_acc: 0.7506\n",
      "Epoch 1887/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6683 - acc: 0.7374 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1888/2000\n",
      "1249/1249 [==============================] - 0s 179us/step - loss: 0.6686 - acc: 0.7366 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1889/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6685 - acc: 0.7382 - val_loss: 0.6852 - val_acc: 0.7530\n",
      "Epoch 1890/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6684 - acc: 0.7366 - val_loss: 0.6851 - val_acc: 0.7530\n",
      "Epoch 1891/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6685 - acc: 0.7374 - val_loss: 0.6851 - val_acc: 0.7530\n",
      "Epoch 1892/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6684 - acc: 0.7366 - val_loss: 0.6852 - val_acc: 0.7506\n",
      "Epoch 1893/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6684 - acc: 0.7366 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1894/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6686 - acc: 0.7382 - val_loss: 0.6854 - val_acc: 0.7530\n",
      "Epoch 1895/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6685 - acc: 0.7374 - val_loss: 0.6855 - val_acc: 0.7530\n",
      "Epoch 1896/2000\n",
      "1249/1249 [==============================] - 0s 194us/step - loss: 0.6683 - acc: 0.7374 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1897/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6683 - acc: 0.7366 - val_loss: 0.6852 - val_acc: 0.7506\n",
      "Epoch 1898/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6684 - acc: 0.7366 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1899/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6683 - acc: 0.7374 - val_loss: 0.6853 - val_acc: 0.7530\n",
      "Epoch 1900/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6684 - acc: 0.7366 - val_loss: 0.6851 - val_acc: 0.7506\n",
      "Epoch 1901/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6684 - acc: 0.7382 - val_loss: 0.6851 - val_acc: 0.7506\n",
      "Epoch 1902/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6686 - acc: 0.7374 - val_loss: 0.6851 - val_acc: 0.7506\n",
      "Epoch 1903/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6683 - acc: 0.7390 - val_loss: 0.6849 - val_acc: 0.7506\n",
      "Epoch 1904/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6682 - acc: 0.7390 - val_loss: 0.6848 - val_acc: 0.7506\n",
      "Epoch 1905/2000\n",
      "1249/1249 [==============================] - 0s 169us/step - loss: 0.6681 - acc: 0.7366 - val_loss: 0.6848 - val_acc: 0.7530\n",
      "Epoch 1906/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6684 - acc: 0.7374 - val_loss: 0.6849 - val_acc: 0.7530\n",
      "Epoch 1907/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6682 - acc: 0.7382 - val_loss: 0.6852 - val_acc: 0.7530\n",
      "Epoch 1908/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6682 - acc: 0.7390 - val_loss: 0.6851 - val_acc: 0.7530\n",
      "Epoch 1909/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6682 - acc: 0.7382 - val_loss: 0.6848 - val_acc: 0.7530\n",
      "Epoch 1910/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6682 - acc: 0.7382 - val_loss: 0.6849 - val_acc: 0.7530\n",
      "Epoch 1911/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6682 - acc: 0.7366 - val_loss: 0.6852 - val_acc: 0.7506\n",
      "Epoch 1912/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6682 - acc: 0.7398 - val_loss: 0.6851 - val_acc: 0.7506\n",
      "Epoch 1913/2000\n",
      "1249/1249 [==============================] - 0s 186us/step - loss: 0.6682 - acc: 0.7374 - val_loss: 0.6851 - val_acc: 0.7506\n",
      "Epoch 1914/2000\n",
      "1249/1249 [==============================] - 0s 158us/step - loss: 0.6681 - acc: 0.7358 - val_loss: 0.6851 - val_acc: 0.7506\n",
      "Epoch 1915/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6682 - acc: 0.7382 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1916/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6681 - acc: 0.7358 - val_loss: 0.6845 - val_acc: 0.7506\n",
      "Epoch 1917/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6681 - acc: 0.7382 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1918/2000\n",
      "1249/1249 [==============================] - 0s 173us/step - loss: 0.6683 - acc: 0.7398 - val_loss: 0.6849 - val_acc: 0.7506\n",
      "Epoch 1919/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6681 - acc: 0.7382 - val_loss: 0.6849 - val_acc: 0.7530\n",
      "Epoch 1920/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6681 - acc: 0.7382 - val_loss: 0.6850 - val_acc: 0.7530\n",
      "Epoch 1921/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6680 - acc: 0.7382 - val_loss: 0.6849 - val_acc: 0.7530\n",
      "Epoch 1922/2000\n",
      "1249/1249 [==============================] - 0s 182us/step - loss: 0.6680 - acc: 0.7398 - val_loss: 0.6848 - val_acc: 0.7530\n",
      "Epoch 1923/2000\n",
      "1249/1249 [==============================] - 0s 181us/step - loss: 0.6679 - acc: 0.7374 - val_loss: 0.6848 - val_acc: 0.7530\n",
      "Epoch 1924/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6680 - acc: 0.7366 - val_loss: 0.6850 - val_acc: 0.7530\n",
      "Epoch 1925/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6679 - acc: 0.7406 - val_loss: 0.6850 - val_acc: 0.7530\n",
      "Epoch 1926/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6679 - acc: 0.7366 - val_loss: 0.6849 - val_acc: 0.7506\n",
      "Epoch 1927/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6680 - acc: 0.7374 - val_loss: 0.6845 - val_acc: 0.7530\n",
      "Epoch 1928/2000\n",
      "1249/1249 [==============================] - 0s 185us/step - loss: 0.6680 - acc: 0.7390 - val_loss: 0.6847 - val_acc: 0.7506\n",
      "Epoch 1929/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6682 - acc: 0.7382 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1930/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6679 - acc: 0.7382 - val_loss: 0.6844 - val_acc: 0.7506\n",
      "Epoch 1931/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6681 - acc: 0.7382 - val_loss: 0.6840 - val_acc: 0.7530\n",
      "Epoch 1932/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6679 - acc: 0.7390 - val_loss: 0.6840 - val_acc: 0.7530\n",
      "Epoch 1933/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6677 - acc: 0.7350 - val_loss: 0.6840 - val_acc: 0.7530\n",
      "Epoch 1934/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6679 - acc: 0.7366 - val_loss: 0.6842 - val_acc: 0.7506\n",
      "Epoch 1935/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6680 - acc: 0.7382 - val_loss: 0.6841 - val_acc: 0.7530\n",
      "Epoch 1936/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6678 - acc: 0.7382 - val_loss: 0.6844 - val_acc: 0.7506\n",
      "Epoch 1937/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6681 - acc: 0.7382 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1938/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6679 - acc: 0.7390 - val_loss: 0.6847 - val_acc: 0.7506\n",
      "Epoch 1939/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6678 - acc: 0.7382 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1940/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6677 - acc: 0.7398 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1941/2000\n",
      "1249/1249 [==============================] - 0s 184us/step - loss: 0.6678 - acc: 0.7390 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1942/2000\n",
      "1249/1249 [==============================] - 0s 174us/step - loss: 0.6677 - acc: 0.7398 - val_loss: 0.6845 - val_acc: 0.7530\n",
      "Epoch 1943/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6676 - acc: 0.7366 - val_loss: 0.6847 - val_acc: 0.7506\n",
      "Epoch 1944/2000\n",
      "1249/1249 [==============================] - 0s 187us/step - loss: 0.6678 - acc: 0.7382 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1945/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6677 - acc: 0.7358 - val_loss: 0.6847 - val_acc: 0.7506\n",
      "Epoch 1946/2000\n",
      "1249/1249 [==============================] - 0s 151us/step - loss: 0.6676 - acc: 0.7382 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1947/2000\n",
      "1249/1249 [==============================] - 0s 176us/step - loss: 0.6676 - acc: 0.7382 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1948/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6676 - acc: 0.7406 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1949/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6677 - acc: 0.7398 - val_loss: 0.6845 - val_acc: 0.7530\n",
      "Epoch 1950/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6675 - acc: 0.7382 - val_loss: 0.6846 - val_acc: 0.7506\n",
      "Epoch 1951/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6676 - acc: 0.7390 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1952/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6677 - acc: 0.7390 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1953/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6675 - acc: 0.7382 - val_loss: 0.6850 - val_acc: 0.7506\n",
      "Epoch 1954/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6677 - acc: 0.7390 - val_loss: 0.6848 - val_acc: 0.7530\n",
      "Epoch 1955/2000\n",
      "1249/1249 [==============================] - 0s 177us/step - loss: 0.6676 - acc: 0.7398 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1956/2000\n",
      "1249/1249 [==============================] - 0s 188us/step - loss: 0.6675 - acc: 0.7366 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1957/2000\n",
      "1249/1249 [==============================] - 0s 161us/step - loss: 0.6676 - acc: 0.7382 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1958/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6675 - acc: 0.7398 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1959/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6675 - acc: 0.7390 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1960/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6675 - acc: 0.7390 - val_loss: 0.6845 - val_acc: 0.7506\n",
      "Epoch 1961/2000\n",
      "1249/1249 [==============================] - 0s 165us/step - loss: 0.6674 - acc: 0.7382 - val_loss: 0.6844 - val_acc: 0.7530\n",
      "Epoch 1962/2000\n",
      "1249/1249 [==============================] - 0s 159us/step - loss: 0.6676 - acc: 0.7398 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1963/2000\n",
      "1249/1249 [==============================] - 0s 155us/step - loss: 0.6674 - acc: 0.7390 - val_loss: 0.6846 - val_acc: 0.7530\n",
      "Epoch 1964/2000\n",
      "1249/1249 [==============================] - 0s 152us/step - loss: 0.6674 - acc: 0.7398 - val_loss: 0.6847 - val_acc: 0.7530\n",
      "Epoch 1965/2000\n",
      "1249/1249 [==============================] - 0s 175us/step - loss: 0.6675 - acc: 0.7406 - val_loss: 0.6844 - val_acc: 0.7530\n",
      "Epoch 1966/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6674 - acc: 0.7390 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1967/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6674 - acc: 0.7414 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1968/2000\n",
      "1249/1249 [==============================] - 0s 151us/step - loss: 0.6674 - acc: 0.7390 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1969/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6674 - acc: 0.7390 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1970/2000\n",
      "1249/1249 [==============================] - 0s 156us/step - loss: 0.6674 - acc: 0.7398 - val_loss: 0.6842 - val_acc: 0.7530\n",
      "Epoch 1971/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6674 - acc: 0.7398 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1972/2000\n",
      "1249/1249 [==============================] - 0s 172us/step - loss: 0.6674 - acc: 0.7406 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1973/2000\n",
      "1249/1249 [==============================] - 0s 171us/step - loss: 0.6672 - acc: 0.7414 - val_loss: 0.6844 - val_acc: 0.7530\n",
      "Epoch 1974/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6675 - acc: 0.7382 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1975/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6672 - acc: 0.7398 - val_loss: 0.6841 - val_acc: 0.7530\n",
      "Epoch 1976/2000\n",
      "1249/1249 [==============================] - 0s 167us/step - loss: 0.6678 - acc: 0.7382 - val_loss: 0.6841 - val_acc: 0.7530\n",
      "Epoch 1977/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6673 - acc: 0.7406 - val_loss: 0.6842 - val_acc: 0.7530\n",
      "Epoch 1978/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6672 - acc: 0.7398 - val_loss: 0.6841 - val_acc: 0.7530\n",
      "Epoch 1979/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6673 - acc: 0.7374 - val_loss: 0.6841 - val_acc: 0.7530\n",
      "Epoch 1980/2000\n",
      "1249/1249 [==============================] - 0s 153us/step - loss: 0.6673 - acc: 0.7390 - val_loss: 0.6842 - val_acc: 0.7530\n",
      "Epoch 1981/2000\n",
      "1249/1249 [==============================] - 0s 160us/step - loss: 0.6673 - acc: 0.7398 - val_loss: 0.6841 - val_acc: 0.7530\n",
      "Epoch 1982/2000\n",
      "1249/1249 [==============================] - 0s 170us/step - loss: 0.6674 - acc: 0.7382 - val_loss: 0.6842 - val_acc: 0.7530\n",
      "Epoch 1983/2000\n",
      "1249/1249 [==============================] - 0s 164us/step - loss: 0.6671 - acc: 0.7382 - val_loss: 0.6844 - val_acc: 0.7506\n",
      "Epoch 1984/2000\n",
      "1249/1249 [==============================] - 0s 178us/step - loss: 0.6674 - acc: 0.7390 - val_loss: 0.6842 - val_acc: 0.7530\n",
      "Epoch 1985/2000\n",
      "1249/1249 [==============================] - 0s 168us/step - loss: 0.6672 - acc: 0.7406 - val_loss: 0.6844 - val_acc: 0.7506\n",
      "Epoch 1986/2000\n",
      "1249/1249 [==============================] - 0s 180us/step - loss: 0.6671 - acc: 0.7398 - val_loss: 0.6845 - val_acc: 0.7506\n",
      "Epoch 1987/2000\n",
      "1249/1249 [==============================] - 0s 191us/step - loss: 0.6672 - acc: 0.7390 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1988/2000\n",
      "1249/1249 [==============================] - 0s 193us/step - loss: 0.6673 - acc: 0.7422 - val_loss: 0.6839 - val_acc: 0.7530\n",
      "Epoch 1989/2000\n",
      "1249/1249 [==============================] - 0s 199us/step - loss: 0.6671 - acc: 0.7398 - val_loss: 0.6840 - val_acc: 0.7530\n",
      "Epoch 1990/2000\n",
      "1249/1249 [==============================] - 0s 189us/step - loss: 0.6670 - acc: 0.7390 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1991/2000\n",
      "1249/1249 [==============================] - 0s 202us/step - loss: 0.6672 - acc: 0.7390 - val_loss: 0.6841 - val_acc: 0.7530\n",
      "Epoch 1992/2000\n",
      "1249/1249 [==============================] - 0s 192us/step - loss: 0.6673 - acc: 0.7398 - val_loss: 0.6843 - val_acc: 0.7530\n",
      "Epoch 1993/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6671 - acc: 0.7390 - val_loss: 0.6845 - val_acc: 0.7506\n",
      "Epoch 1994/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6672 - acc: 0.7390 - val_loss: 0.6845 - val_acc: 0.7506\n",
      "Epoch 1995/2000\n",
      "1249/1249 [==============================] - 0s 154us/step - loss: 0.6670 - acc: 0.7398 - val_loss: 0.6846 - val_acc: 0.7506\n",
      "Epoch 1996/2000\n",
      "1249/1249 [==============================] - 0s 146us/step - loss: 0.6670 - acc: 0.7406 - val_loss: 0.6845 - val_acc: 0.7506\n",
      "Epoch 1997/2000\n",
      "1249/1249 [==============================] - 0s 157us/step - loss: 0.6671 - acc: 0.7398 - val_loss: 0.6842 - val_acc: 0.7530\n",
      "Epoch 1998/2000\n",
      "1249/1249 [==============================] - 0s 163us/step - loss: 0.6671 - acc: 0.7390 - val_loss: 0.6845 - val_acc: 0.7530\n",
      "Epoch 1999/2000\n",
      "1249/1249 [==============================] - 0s 149us/step - loss: 0.6669 - acc: 0.7390 - val_loss: 0.6844 - val_acc: 0.7506\n",
      "Epoch 2000/2000\n",
      "1249/1249 [==============================] - 0s 166us/step - loss: 0.6670 - acc: 0.7382 - val_loss: 0.6843 - val_acc: 0.7530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f1208adb00>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels = keras.utils.to_categorical(class_vec_train, num_classes=3)\n",
    "\n",
    "model.fit(x = input_vec_train, y = one_hot_labels,  batch_size=30, epochs=2000, verbose=1, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For you to pass this assignment, you must obtain an accuracy on the validation set greater than 50%. It may be necessary to search for a good architecture by trying several different ones. If you want a challenge, try getting an accuracy greater than 63%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you achieved at least 50% accuracy in the validation set, we are done with training. Now we'll evaluate the performance of your classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/416 [==============================] - 0s 221us/step\n",
      "[0.7436421083716246, 0.7043269266589329]\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels_Test = keras.utils.to_categorical(class_vec_test, num_classes=3)\n",
    "score = model.evaluate(input_vec_test, one_hot_labels_Test, batch_size=10)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the confusion matrix of your predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now trained and evaluated a neural network for this particular classification task. Can you provide a brief explanation as to how you could use it to decide where to travel, if you're interested in capturing the aforementioned Pokemons?\n",
    "\n",
    "**Answer**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is(are) there any other feature(s) from the original dataset (e.g. hour of the day, pressure, wind speed, population density, etc.) which you think would be valuable to add as an input feature to your classifier to improve its performance? \n",
    "\n",
    "**Your answer**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate your hypothesis, plot a histogram of the selected feature(s) for each one of the pokemons we're interested in. For example, if you think pressure and population density are valuable for prediction, plot 6 histograms. 3 of them will be the pressure histograms for each class ('Diglett', 'Seel' and 'Tauros'), and the other 3 will be the population density for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does(do) this(ese) histogram(s) show you? Could it be beneficial to add this(ese) new feature(s) as input? Explain why/why not.\n",
    "\n",
    "**Your answer**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you found useful new features in the last part of this assignment, train a new classifier that uses these featues as well. Did the accuracy on the validation set improve? What's the highest accuracy you can achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
